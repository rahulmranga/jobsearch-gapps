job_id,employer_name,employer_logo,employer_website,employer_company_type,job_publisher,job_employment_type,job_title,job_apply_link,job_apply_is_direct,job_apply_quality_score,job_description,job_is_remote,job_posted_at_timestamp,job_posted_at_datetime_utc,job_city,job_state,job_country,job_latitude,job_longitude,job_benefits,job_google_link,job_offer_expiration_datetime_utc,job_offer_expiration_timestamp,job_required_experience,job_required_skills,job_required_education,job_experience_in_place_of_education,job_min_salary,job_max_salary,job_salary_currency,job_salary_period,job_highlights,job_job_title,job_posting_language,job_onet_soc,job_onet_job_zone,job_occupational_categories,job_naics_code,job_naics_name
HmRFsCRF1UsAAAAAAAAAAA==,TEKsystems,https://www.teksystems.com/-/media/teksystems_com/Images/Logos/TEKsystems_logotype_RGB.png,http://www.teksystems.com,Staffing,TEKsystems Careers,CONTRACTOR,Data Engineer,https://careers.teksystems.com/ca/fr/job/JP-003930154/Data-Engineer,False,0.8267,"We are looking for a Data Engineer to join our team!

Top Skills' Details

1) Experience writing stored procedures to ingest data from a spreadsheet (Excel) or SQL or other data sources

2) Experience summarizing data and building those reporting tables and reviews, Tableaus and PowerBI. Experience building database views to summarize the data and pull the data. They mainly work with SQL databases so that is the main database they can work with but they do work with multiple databases so need to be able to come in and understand each database and the data that is in these databases. Writing queries or packages to query the data and summarize it. Building database views to summarize the data and pull the data correctly

3) Experience looking over the multiple databases they work with, main one being SQL but looking into the databases and the data that is in each database and understanding that well

Day to day:

- Data modeling designs / custom development of data models so the data flows into Tableau and PowerBI correctly

- Building database views to summarize the data and pull the data correctly

- Making enhancements to the dashboards within Tableau and PowerBI

- They will receive requests for another view or metrics to add to the table or the column so need to be able to take those requests and implement them.

- Will be sourcing from Hadoop platform as well and that work will continue to grow so ideally have experience within Hadoop.

- Working with APIs, ingesting data from APIs, writing scripts within this, Shell or Python scripts

About TEKsystems:

We're partners in transformation. We help clients activate ideas and solutions to take advantage of a new world of opportunity. We are a team of 80,000 strong, working with over 6,000 clients, including 80% of the Fortune 500, across North America, Europe and Asia. As an industry leader in Full-Stack Technology Services, Talent Services, and real-world application, we work with progressive leaders to drive change. That's the power of true partnership. TEKsystems is an Allegis Group company.

The company is an equal opportunity employer and will consider all applications without regards to race, sex, age, color, religion, national origin, veteran status, disability, sexual orientation, gender identity, genetic information or any characteristic protected by law.",False,1690392102,2023-07-26T17:21:42.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=HmRFsCRF1UsAAAAAAAAAAA%3D%3D",,,"{'no_experience_required': False, 'required_experience_in_months': None, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': False, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['Experience writing stored procedures to ingest data from a spreadsheet (Excel) or SQL or other data sources', 'Experience summarizing data and building those reporting tables and reviews, Tableaus and PowerBI', 'Experience looking over the multiple databases they work with, main one being SQL but looking into the databases and the data that is in each database and understanding that well', 'Working with APIs, ingesting data from APIs, writing scripts within this, Shell or Python scripts'], 'Responsibilities': ['Experience building database views to summarize the data and pull the data', 'Writing queries or packages to query the data and summarize it', 'Data modeling designs / custom development of data models so the data flows into Tableau and PowerBI correctly', 'Making enhancements to the dashboards within Tableau and PowerBI', 'They will receive requests for another view or metrics to add to the table or the column so need to be able to take those requests and implement them', 'Will be sourcing from Hadoop platform as well and that work will continue to grow so ideally have experience within Hadoop']}",Data engineer,en,15113200,4,['Other'],561311,Employment Placement Agencies
Qsa1ierlUMkAAAAAAAAAAA==,DISYS,https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSsPrzieb2HrugmWoiAtj4wAAw4sYD5BVV8zr69&s=0,http://disys.com,,LinkedIn,CONTRACTOR,Data Engineer,https://www.linkedin.com/jobs/view/data-engineer-at-disys-3673557460,False,0.5856,"Overview:
• The team is looking for a versatile Data Engineer who will provide data and report development services or technical support.
• You will develop, test, and maintain data or report solutions (data warehouse/mart/stores/data lake/reporting/analytics) using tools and programming languages.
• You will also develop data set processes and assist with design and identify ways to improve data reliability, efficiency, and quality.
• As the Data Engineer you will work independently, receive minimal guidance, and have accountability for their work and work of junior members.

Requirements:
• An associate degree, a bachelor's degree in computer science or equivalent courses
• At least 4 years of experience in Data Engineering with SQL, Python
• Experience with relational SQL and NoSQL databases
• Experience in the following Big Data frameworks: File Format (Parquet, AVRO, ORC etc.)
• At least 3 years of experience working with large data sets, streaming, experience working with distributed computing (Map Reduce, Hadoop, Hive, Apache Spark, Apache Kafka etc.)
• At least 2 years of experience with AWS cloud (with focus on Data services)

Desired Skills and Experience

Overview:
• The team is looking for a versatile Data Engineer who will provide data and report development services or technical support.
• You will develop, test, and maintain data or report solutions (data warehouse/mart/stores/data lake/reporting/analytics) using tools and programming languages.
• You will also develop data set processes and assist with design and identify ways to improve data reliability, efficiency, and quality.
• As the Data Engineer you will work independently, receive minimal guidance, and have accountability for their work and work of junior members.

Requirements:
• An associate degree, a bachelor's degree in computer science or equivalent courses
• At least 4 years of experience in Data Engineering with SQL, Python
• Experience with relational SQL and NoSQL databases
• Experience in the following Big Data frameworks: File Format (Parquet, AVRO, ORC etc.)
• At least 3 years of experience working with large data sets, streaming, experience working with distributed computing (Map Reduce, Hadoop, Hive, Apache Spark, Apache Kafka etc.)
• At least 2 years of experience with AWS cloud (with focus on Data services)

Dexian is a leading provider of staffing, IT, and workforce solutions with over 12,000 employees and 70 locations worldwide. As one of the largest IT staffing companies and the 2nd largest minority-owned staffing company in the U.S., Dexian was formed in 2023 through the merger of DISYS and Signature Consultants. Combining the best elements of its core companies, Dexian's platform connects talent, technology, and organizations to produce game-changing results that help everyone achieve their ambitions and goals.

Dexian's brands include Dexian DISYS, Dexian Signature Consultants, Dexian Government Solutions, Dexian Talent Development and Dexian IT Solutions. Visit www.dexian.com to learn more.

Dexian is an Equal Opportunity Employer that recruits and hires qualified candidates without regard to race, religion, sex, sexual orientation, gender identity, age, national origin, ancestry, citizenship, disability, or veteran status.",False,1690461639,2023-07-27T12:40:39.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=Qsa1ierlUMkAAAAAAAAAAA%3D%3D",2023-08-26T12:40:39.000Z,1693053639.0,"{'no_experience_required': False, 'required_experience_in_months': 48, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': True, 'degree_mentioned': True, 'degree_preferred': True, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': [""An associate degree, a bachelor's degree in computer science or equivalent courses"", 'At least 4 years of experience in Data Engineering with SQL, Python', 'Experience with relational SQL and NoSQL databases', 'Experience in the following Big Data frameworks: File Format (Parquet, AVRO, ORC etc.)', 'At least 3 years of experience working with large data sets, streaming, experience working with distributed computing (Map Reduce, Hadoop, Hive, Apache Spark, Apache Kafka etc.)', 'At least 2 years of experience with AWS cloud (with focus on Data services)'], 'Responsibilities': ['The team is looking for a versatile Data Engineer who will provide data and report development services or technical support', 'You will develop, test, and maintain data or report solutions (data warehouse/mart/stores/data lake/reporting/analytics) using tools and programming languages', 'You will also develop data set processes and assist with design and identify ways to improve data reliability, efficiency, and quality', 'As the Data Engineer you will work independently, receive minimal guidance, and have accountability for their work and work of junior members']}",Data engineer,en,15113200,4,,,
oAmKqPWYe9QAAAAAAAAAAA==,Trigger IT LLC,,,,Dice,CONTRACTOR,Data Engineer,https://www.dice.com/job-detail/fbf4ceaa-f4b9-4873-bb34-2c1ed7b97228,True,0.5684,"Hi,

Hope you are doing well!

Job Title: Data Engineer | (Python, Hive, Spark) | Hybrid | Dallas, TX

Location: Dallas, TX( look for Locals or Nearby)

Primary Skills: Tableau, Python, SQL

Description:
• Designs, develops, and implements Hadoop eco-system based applications to support business requirements.
• Follows approved life cycle methodologies, creates design documents, and performs program coding and testing.
• Resolves technical issues through debugging, research, and investigation

Required Qualifications –

Option 1: Bachelor’s degree in Computer Science and 4 years' experience in software engineering or related field.

Option 2: 6 years’ experience in software engineering or related field.

Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related field. 3 years' experience in data engineering, database engineering, business intelligence, or business analytics.

Nice to have soft skills –
• 7+ years of experience with 3+ years of Big data development experience
• Experience in HDFS, Hive, Hive UDF’s, MapReduce, Druid, Spark, Python, Hue, Shell Scripting, Unix.
• Demonstrates expertise in writing complex, highly optimized queries across large data sets
• Retail experience and knowledge of commercial data is a huge plus
• Experience with BI Tool Tableau or Looker is a plus.

THANKS & REGARDS,
Ch.Nikhil Reddy
Direct: +1 )
TRIGGER IT | Getting it Done
IT Services | Consulting-Development-Staffing
5000 Centre Green Way, Suite 500 Cary, NC-27513, United States Web: | Email:",False,1690311787,2023-07-25T19:03:07.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=oAmKqPWYe9QAAAAAAAAAAA%3D%3D",2023-08-25T19:03:07.000Z,1692990187.0,"{'no_experience_required': False, 'required_experience_in_months': 72, 'experience_mentioned': True, 'experience_preferred': True}","['Python', 'Big data', 'Tableau']","{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': True, 'professional_certification_mentioned': False}",False,40.0,45.0,USD,HOUR,"{'Qualifications': [""Option 1: Bachelor’s degree in Computer Science and 4 years' experience in software engineering or related field"", ""Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related field"", ""3 years' experience in data engineering, database engineering, business intelligence, or business analytics"", 'Nice to have soft skills –', '7+ years of experience with 3+ years of Big data development experience', 'Experience in HDFS, Hive, Hive UDF’s, MapReduce, Druid, Spark, Python, Hue, Shell Scripting, Unix', 'Demonstrates expertise in writing complex, highly optimized queries across large data sets', 'Retail experience and knowledge of commercial data is a huge plus'], 'Responsibilities': ['Designs, develops, and implements Hadoop eco-system based applications to support business requirements', 'Follows approved life cycle methodologies, creates design documents, and performs program coding and testing', 'Resolves technical issues through debugging, research, and investigation']}",Data engineer,en,15113200,4,,,
P7IfQYjEDhsAAAAAAAAAAA==,Skiltrek,,,,ZipRecruiter,FULLTIME,data engineer,"https://www.ziprecruiter.com/c/Skiltrek/Job/Data-Engineer/-in-Dallas,TX?jid=80b3c66c3cb0a5ed",True,0.629,"job summary:
Required Qualifications -
• Option 1: Bachelor's degree in Computer Science and 4 years' experience in software engineering or related field.
• Option 2: 6 years' experience in software engineering or related field.
• Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related field. 3 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Nice to have soft skills -
• 7+ years of experience with 3+ years of Big data development experience
• Experience in HDFS, Hive, Hive UDF's, MapReduce, Druid, Spark, Python, Hue, Shell Scripting, Unix.
• Demonstrates expertise in writing complex, highly optimized queries across large data sets
• Retail experience and knowledge of commercial data is a huge plus
• Experience with BI Tool Tableau or Looker is a plus

location: Dallas, Texas
job type: Contract
salary: $62 - 72 per hour
work hours: 8am to 5pm
education: Bachelors

responsibilities:
Designs, develops, and implements Hadoop eco-system based applications to support business requirements.

Follows approved life cycle methodologies, creates design documents, and performs program coding and testing.

Resolves technical issues through debugging, research, and investigation

qualifications:
• Experience level: Experienced
• Minimum 4 years of experience
• Education: Bachelors

skills:
• SQL
• Python
• Tableau
About Us

Skiltrek is an award-winning IT staffing firm and the staffing partner of choice for many leading companies across the US.
At Skiltrek, we promise you the perfect opportunity of building technical excellence, understand business performance and nuances,
be abreast with the latest happenings in technology world and enjoy a satisfying work life balance.
Skiltrek is committed to equal treatment and opportunity in all aspects of recruitment, selection, and employment without regard to gender,
race, religion, national origin, ethnicity, disability, gender identity/expression, sexual orientation, veteran or military status, or any other category protected under the law.
Skiltrek is an equal opportunity employer; committed to a community of inclusion, and an environment free from discrimination, harassment, and retaliation.",False,1690277800,2023-07-25T09:36:40.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=P7IfQYjEDhsAAAAAAAAAAA%3D%3D",2023-08-27T00:00:00.000Z,1693094400.0,"{'no_experience_required': False, 'required_experience_in_months': 72, 'experience_mentioned': True, 'experience_preferred': True}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': True, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': [""Option 1: Bachelor's degree in Computer Science and 4 years' experience in software engineering or related field"", ""Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related field"", ""3 years' experience in data engineering, database engineering, business intelligence, or business analytics"", 'Nice to have soft skills -', '7+ years of experience with 3+ years of Big data development experience', ""Experience in HDFS, Hive, Hive UDF's, MapReduce, Druid, Spark, Python, Hue, Shell Scripting, Unix"", 'Demonstrates expertise in writing complex, highly optimized queries across large data sets', 'Retail experience and knowledge of commercial data is a huge plus', 'Experience level: Experienced', 'Minimum 4 years of experience', 'Education: Bachelors', 'SQL'], 'Responsibilities': ['work hours: 8am to 5pm', 'Designs, develops, and implements Hadoop eco-system based applications to support business requirements', 'Follows approved life cycle methodologies, creates design documents, and performs program coding and testing', 'Resolves technical issues through debugging, research, and investigation'], 'Benefits': ['salary: $62 - 72 per hour']}",Data engineer,en,15113200,4,['15-2041.00: Statisticians'],,
QwDdBZfCBAUAAAAAAAAAAA==,"Softworld, a Kelly Company",,,,WAVY Jobs,FULLTIME,Data Engineer,https://jobs.wavy.com/jobs/data-engineer-dallas-texas/1074871948-2/,False,0.5741,"Job Number: 240856

Data Engineer

Job Description

This role will be part of a team focused on cloud transformation, modernizing analytics platforms and improving agility. The role requires hands-on experience in building and managing analytics solutions in SnowFlake, Provide direction on adoption of Cloud technologies (Snowflake) and industry best practices in the field of Data Engineering architecture and Development.

Primary duties and responsibilities:

- Establish Data Engineering architecture strategy, best practices, standards, and roadmap

- Experience developing ETL Pipeline using Python, Snowflake and IDMC.

- Experience with loading batch data and streaming data via Kafka

- Build Data Flows mapping Source systems and Process flows.

- Assemble large, complex data sets that meet non-functional and functional business requirements

- Mentor team members on best practices, efficient implementations and delivering high quality data products

- Lead onshore and offshore teams

- Perform code reviews and assist developers in optimization and troubleshooting.

- Expertise in Snowflake advanced concepts like setting up resource monitors, RBAC controls, virtual warehouse sizing, query performance tuning, Zero copy clone, time travel and understand how to use these features

- Knowledge in AWS and management technologies such as S3.

- Strong written communication skills

- Is effective and persuasive in both written and oral communication

Must Haves:

- 5-10 years of experience within data engineering

- Python experience

- Snowflake experience (developing ETL pipelines)

- IDMC (intelligent data management cloud) experience

- Knowledge of AWS

Plusses:

- Kafka experience (loading batch and streaming data)
• Hybrid position - 2 days a week on-site at client office in downtown Dallas, TX

Desired Skills and Experience

Data Engineer, Python, IDMC, Snowflake, AWS, Dallas, ETL, ETL Pipeline, Kafka, RBAC controls, S3, ETL, AWS, Snowflake, IDMC, intelligent data management cloud, data engineer, hybrid",False,1690431118,2023-07-27T04:11:58.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=QwDdBZfCBAUAAAAAAAAAAA%3D%3D",,,"{'no_experience_required': False, 'required_experience_in_months': 60, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': False, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['Knowledge in AWS and management technologies such as S3', 'Strong written communication skills', '5-10 years of experience within data engineering', 'Python experience', 'Snowflake experience (developing ETL pipelines)', 'Kafka experience (loading batch and streaming data)', 'Hybrid position - 2 days a week on-site at client office in downtown Dallas, TX', 'Data Engineer, Python, IDMC, Snowflake, AWS, Dallas, ETL, ETL Pipeline, Kafka, RBAC controls, S3, ETL, AWS, Snowflake, IDMC, intelligent data management cloud, data engineer, hybrid'], 'Responsibilities': ['This role will be part of a team focused on cloud transformation, modernizing analytics platforms and improving agility', 'The role requires hands-on experience in building and managing analytics solutions in SnowFlake, Provide direction on adoption of Cloud technologies (Snowflake) and industry best practices in the field of Data Engineering architecture and Development', 'Establish Data Engineering architecture strategy, best practices, standards, and roadmap', 'Experience developing ETL Pipeline using Python, Snowflake and IDMC', 'Experience with loading batch data and streaming data via Kafka', 'Build Data Flows mapping Source systems and Process flows', 'Assemble large, complex data sets that meet non-functional and functional business requirements', 'Mentor team members on best practices, efficient implementations and delivering high quality data products', 'Lead onshore and offshore teams', 'Perform code reviews and assist developers in optimization and troubleshooting', 'Expertise in Snowflake advanced concepts like setting up resource monitors, RBAC controls, virtual warehouse sizing, query performance tuning, Zero copy clone, time travel and understand how to use these features']}",Data engineer,en,15113200,4,,,
v6KgOCdJjGgAAAAAAAAAAA==,Compunnel Inc.,https://images.comparably.com/companies/compunnel-software-group,http://www.compunnel.com,,LinkedIn,FULLTIME,Data Engineer,https://www.linkedin.com/jobs/view/data-engineer-at-compunnel-inc-3677796668,False,0.5598,"Data Engineer (W2 only)

The Expertise You Have
• Bachelor’s degree required and 5+ years of related experience in Data Engineering.
• Solid experience in writing complex SQL queries on Snowflake (AWS) or Oracle and performance optimization for large data volumes.
• Proficiency working with Python specifically as it relates to data processing.
• Proven technical leadership in definition/support of standards and best practices
• Superior Data Modeling skills and experience performing deep data analysis on multiple database platforms
• Deep understanding of data warehousing techniques and methodologies.
• Exposure and/or understanding Client’s enterprise data lake strategy.
• Experience in Linux commands and basic shell scripting.
• Experience in working with devops tools for code migrations.
• Ability to develop ELT/ETL pipelines to move data to and from Snowflake data store using combination of Python and Snowflake SnowSQL.
• Proven track record of working in collaborative teams to deliver high quality data solutions in a multi-developer agile environment following design & coding best practices.
• Excellent communicator to both technical and non-technical data players to ensure common understanding of design to streamline and optimize data enablement.
• Prior experience working in Agile software development environments, with proven ability to convert user stories into delivery work that provides incremental, iterative delivery of business value.
• Financial services experience preferred.",False,1690474929,2023-07-27T16:22:09.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=v6KgOCdJjGgAAAAAAAAAAA%3D%3D",2023-08-26T16:22:09.000Z,1693066929.0,"{'no_experience_required': False, 'required_experience_in_months': 60, 'experience_mentioned': True, 'experience_preferred': True}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': True, 'degree_mentioned': True, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['Bachelor’s degree required and 5+ years of related experience in Data Engineering', 'Solid experience in writing complex SQL queries on Snowflake (AWS) or Oracle and performance optimization for large data volumes', 'Proficiency working with Python specifically as it relates to data processing', 'Proven technical leadership in definition/support of standards and best practices', 'Superior Data Modeling skills and experience performing deep data analysis on multiple database platforms', 'Deep understanding of data warehousing techniques and methodologies', 'Exposure and/or understanding Client’s enterprise data lake strategy', 'Experience in Linux commands and basic shell scripting', 'Experience in working with devops tools for code migrations', 'Ability to develop ELT/ETL pipelines to move data to and from Snowflake data store using combination of Python and Snowflake SnowSQL', 'Proven track record of working in collaborative teams to deliver high quality data solutions in a multi-developer agile environment following design & coding best practices', 'Excellent communicator to both technical and non-technical data players to ensure common understanding of design to streamline and optimize data enablement', 'Prior experience working in Agile software development environments, with proven ability to convert user stories into delivery work that provides incremental, iterative delivery of business value']}",Data engineer,en,15113200,4,,,
gbf_tKAAwsoAAAAAAAAAAA==,Ascendion Inc.,https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcS500weGU8Dx9ZPZosQM_sMearUR_pwAnRmX7Ms&s=0,http://www.collabera.com,,Professional Diversity Network,FULLTIME,Data Engineer,https://www.prodivnet.com/job/data-engineer-dallas-texas-13317454,False,0.5781,"About Ascendion

Ascendion is a full-service digital engineering solutions company. We make and manage software platforms and products that power growth and deliver captivating experiences to consumers and employees. Our engineering, cloud, data, experience design, and talent solution capabilities accelerate transformation and impact for enterprise clients. Headquartered in New Jersey, our workforce of 6,000+ Ascenders delivers solutions from around the globe. Ascendion is built differently to engineer the next. Ascendion | Engineering to elevate life

We have a culture built on opportunity, inclusion, and a spirit of partnership. Come, change the world with us:
• Build the coolest tech for world's leading brands
• Solve complex problems - and learn new skills
• Experience the power of transforming digital engineering for Fortune 500 clients
• Master your craft with leading training programs and hands-on experience

Experience a community of change makers!

Join a culture of high-performing innovators with endless ideas and a passion for tech. Our culture is the fabric of our company, and it is what makes us unique and diverse. The way we share ideas, learning, experiences, successes, and joy allows everyone to be their best at Ascendion.

About the Role: We are looking for an experienced Data Engineer with 6+ years of experience with Snowflake and Informatica cloud. The data engineer should be somewhere between an engineer and an architect.

Job Title: Data Engineer

Location: Dallas, TX(Hybrid)

Education:

Bachelor's degree/University degree or equivalent experience

Responsibilities:

Day-To-Day:
• Manage & deliver solutions by liaising with business users, architects and understanding the business requirements
• Help design and develop technical and business solutions
• Should be able to coordinate & work with offshore developers
• Develop technical solutions which may involve a variety of data development tools, preferably SQL Server or Informatica
• Design, develop, test and support from SQL stored procedures, views, Informatica workflows, Control-M flows or script objects
• Executes unit and system test scripts, analyzes, captures and publishes test results
• Mentors junior staff members in all areas of database engineering. Guide team members in setting expectations and monitor their progress
• Identifies opportunities to create efficiencies in technical work streams as well as in operational procedures of team

Must haves:
• Experience in Informatica cloud, SQL Server
• Snowflake, creating pipes
• SQL & stored procedure development in MS SQL Server or Oracle

Plusses:
• Implementation experience in scripting/coding for automation (Windows Batch, Unix Shell, PowerShell Python or similar scripting languages)
• PowerShell, Python scripting
• Big Data technologies

Salary Range: The salary for this position is between $1,28,900- $1,41,400 annually. Factors which may affect pay within this range may include geography/market, skills, education, experience and other qualifications of the successful candidate.

This position is eligible for commissions in accordance with the terms of the Company's plan. Commissions for this position are estimated to be based on individual performance. Additionally, this role is also eligible for bonus based on achievement of mutually agreed KRAs.

Benefits: The Company offers the following benefits for this position, subject to applicable eligibility requirements: [medical insurance] [dental insurance] [vision insurance] [401(k) retirement plan] [long-term disability insurance] [short-term disability insurance] [personal days accrued each calendar year. The Paid time off benefits meet the paid sick and safe time laws that pertains to the City/ State] [12-15 days (about 2 weeks) of paid vacation time] [6-8 weeks (about 2 months) of paid parental leave after a year of service] [9 paid holidays and 2 floating holidays per calendar year] [Ascendion Learning Management System] [Tuition Reimbursement Program]

Want to change the world? Let us know.

Tell us about your experiences, education, and ambitions. Bring your knowledge, unique viewpoint, and creativity to the table. Let's talk!

PDN-99bc1c43-05af-4728-8e2f-a41a46b908d3",False,1690352408,2023-07-26T06:20:08.000Z,Dallas,TX,US,32.776665,-96.79699,"['health_insurance', 'paid_time_off', 'dental_coverage', 'retirement_savings']","https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=gbf_tKAAwsoAAAAAAAAAAA%3D%3D",2023-10-24T06:20:08.000Z,1698128408.0,"{'no_experience_required': False, 'required_experience_in_months': 72, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['About the Role: We are looking for an experienced Data Engineer with 6+ years of experience with Snowflake and Informatica cloud', 'The data engineer should be somewhere between an engineer and an architect', ""Bachelor's degree/University degree or equivalent experience"", 'Experience in Informatica cloud, SQL Server', 'Snowflake, creating pipes', 'SQL & stored procedure development in MS SQL Server or Oracle', 'Implementation experience in scripting/coding for automation (Windows Batch, Unix Shell, PowerShell Python or similar scripting languages)', 'Bring your knowledge, unique viewpoint, and creativity to the table'], 'Responsibilities': [""Build the coolest tech for world's leading brands"", 'Solve complex problems - and learn new skills', 'Experience the power of transforming digital engineering for Fortune 500 clients', 'Master your craft with leading training programs and hands-on experience', 'Manage & deliver solutions by liaising with business users, architects and understanding the business requirements', 'Help design and develop technical and business solutions', 'Should be able to coordinate & work with offshore developers', 'Design, develop, test and support from SQL stored procedures, views, Informatica workflows, Control-M flows or script objects', 'Executes unit and system test scripts, analyzes, captures and publishes test results', 'Mentors junior staff members in all areas of database engineering', 'Guide team members in setting expectations and monitor their progress', 'Identifies opportunities to create efficiencies in technical work streams as well as in operational procedures of team'], 'Benefits': ['Salary Range: The salary for this position is between $1,28,900- $1,41,400 annually', 'Factors which may affect pay within this range may include geography/market, skills, education, experience and other qualifications of the successful candidate', ""This position is eligible for commissions in accordance with the terms of the Company's plan"", 'Additionally, this role is also eligible for bonus based on achievement of mutually agreed KRAs', 'Benefits: The Company offers the following benefits for this position, subject to applicable eligibility requirements: [medical insurance] [dental insurance] [vision insurance] [401(k) retirement plan] [long-term disability insurance] [short-term disability insurance] [personal days accrued each calendar year', 'The Paid time off benefits meet the paid sick and safe time laws that pertains to the City/ State] [12-15 days (about 2 weeks) of paid vacation time] [6-8 weeks (about 2 months) of paid parental leave after a year of service] [9 paid holidays and 2 floating holidays per calendar year] [Ascendion Learning Management System] [Tuition Reimbursement Program]']}",Data engineer,en,15113200,4,,,
NgXphZWo5UwAAAAAAAAAAA==,Cloud BC Labs,https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTGe7j9FVPJr-tQbbE7BvSD45V4WMr__2bM7Hd-&s=0,,,LinkedIn,FULLTIME,Data engineer,https://www.linkedin.com/jobs/view/data-engineer-at-cloud-bc-labs-3676042142,False,0.5773,"Job Description

Must Have Skills

Databricks, Scala, Python

Cloud BC Labs Inc is a digital transformation organization aimed at creating seamless solutions for clients to effectively manage their business operations. The company specializes in Business and Management Consulting, AI/ML, Data Analytics & Visualization, Cloud Data Warehouse Migration, Snowflake Implementation, Informatica Implementation & Upgrade, Staffing Services and Data Management Solutions",False,1690416391,2023-07-27T00:06:31.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=NgXphZWo5UwAAAAAAAAAAA%3D%3D",2023-08-26T00:06:31.000Z,1693008391.0,"{'no_experience_required': False, 'required_experience_in_months': None, 'experience_mentioned': False, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': True, 'degree_mentioned': False, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,,,,,{},Data engineer,en,15113200,4,,,
ICjkXTgkKKgAAAAAAAAAAA==,Stefanini,https://d1yjjnpx0p53s8.cloudfront.net/styles/logo-thumbnail/s3/0020/4960/brand.gif?itok=3Cs8keFV,http://stefanini.com,Computer Services,Salary.com,CONTRACTOR,Data Engineer,https://www.salary.com/job/stefanini/data-engineer/j202307260256561284218,False,0.5621,"Stefanini is looking for a Data Engineer in Dallas, TX (hybrid role). W2 only. US Citizens only
For quick apply, please reach out to Vishal Sharma- Vishal.sharma@stefanini.com / 248.263.5616

The team is is looking for a versatile Data Engineer who will provide data and report development services or technical support. You will develop, test, and maintain data or report solutions (data warehouse/mart/stores/data lake/reporting/analytics) using tools and programming languages. You will also develop data set processes and assist with design and identify ways to improve data reliability, efficiency, and quality. As the Data Engineer you will work independently, receive minimal guidance, and have accountability for their work and work of junior members.

Responsibilities:
• Design, develop and implement data mining tools and analyses to sift through large amounts of data stored in a data warehouse or data mart to find relationships and patterns
• Be responsible for implementing the systems, processes and logic required to extract, transform, clean, and distribute data across one or more data stores from a wide variety of sources for systems with moderate complexity
• Work under general guidance and clear framework of accountability with substantial autonomy
• Use best practices and knowledge of internal or external business issues to improve products or services
• Solve complex problems; takes a new perspective using existing solutions
• Required Skills:
• An associate degree, a bachelor's degree in computer science or equivalent courses
• At least 4 years of experience in Data Engineering with SQL, Python
• Experience with relational SQL and NoSQL databases
• Experience in the following Big Data frameworks: File Format (Parquet, AVRO, ORC etc.)
• At least 3 years of experience working with large data sets, streaming, experience working with distributed computing (Map Reduce, Hadoop, Hive, Apache Spark, Apache Kafka etc.)
• At least 2 years of experience with AWS cloud (with focus on Data services)
• Experience with Databricks a plus
• Experience with RESTful API development, Familiarity with HTTP and invoking web-APIs
• Working knowledge of data structures, SQL, XML, JSON, Data visualization tools, Version Control Systems, Programming, and Unix/Linux shell scripting
• Able to interpret user requirements and identify additional information needed in user requirements
• Able to see effects of current design with future requirements and see possible coding solutions to meet the requirements
• Detailed understanding of logical and physical data structures
• Highly skilled in tools, evaluates the need for various tools for continuous integration, testing, automation, deployment etc. and discuss with the team
• Highly skilled at designing tests for unfamiliar designs; Evaluates tests for weaknesses and continuously improves them
• Detailed understanding of how to effectively test against multiple tools/software
• Equivalent education and/or experience may be substituted for any of the above requirements
• ***Listed salary ranges may vary based on experience, qualifications, and local market. Also, some positions may include bonuses or other incentives.

Stefanini takes pride in hiring top talent and developing relationships with our future employees. Our talent acquisition teams will never make an offer of employment without having a phone conversation with you. Those face-to-face conversations will involve a description of the job for which you have applied. We also speak with you about the process including interviews and job offers.

About the Company:
Stefanini

Stefanini is a global IT services company with over 24,000 employees across 77 offices in 40 countries across the Americas, Europe, Africa, Australia, and Asia. Since 1987, Stefanini has been providing offshore, onshore and nearshore IT services, including application development and outsourcing services, IT infrastructure outsourcing (help desk support and desktop services), systems integration, consulting and strategic staffing to Fortune 1000 enterprises around the world.

With a base of over 500 active clients, including more than 300 multinationals, Stefanini maintains a strong presence in industries such as financial services, manufacturing, telecommunications, chemical, services, technology, public sector, and utilities. Clients benefit from Stefanini's financial stability, sustained year-over-year growth, and zero net debt. The corporate global headquarters is located in Sao Paulo, Brazil with European headquarters in Brussels and North American headquarters in metropolitan Detroit.

Company Size:
10,000 employees or more

Industry:
Banking

Founded:
1987

Website:
http://www.stefanini.com",False,1690416000,2023-07-27T00:00:00.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=ICjkXTgkKKgAAAAAAAAAAA%3D%3D",2023-08-24T00:00:00.000Z,1692835200.0,"{'no_experience_required': False, 'required_experience_in_months': 48, 'experience_mentioned': True, 'experience_preferred': True}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': True, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': [""An associate degree, a bachelor's degree in computer science or equivalent courses"", 'At least 4 years of experience in Data Engineering with SQL, Python', 'Experience with relational SQL and NoSQL databases', 'Experience in the following Big Data frameworks: File Format (Parquet, AVRO, ORC etc.)', 'At least 3 years of experience working with large data sets, streaming, experience working with distributed computing (Map Reduce, Hadoop, Hive, Apache Spark, Apache Kafka etc.)', 'At least 2 years of experience with AWS cloud (with focus on Data services)', 'Equivalent education and/or experience may be substituted for any of the above requirements'], 'Responsibilities': ['The team is is looking for a versatile Data Engineer who will provide data and report development services or technical support', 'You will develop, test, and maintain data or report solutions (data warehouse/mart/stores/data lake/reporting/analytics) using tools and programming languages', 'You will also develop data set processes and assist with design and identify ways to improve data reliability, efficiency, and quality', 'As the Data Engineer you will work independently, receive minimal guidance, and have accountability for their work and work of junior members', 'Design, develop and implement data mining tools and analyses to sift through large amounts of data stored in a data warehouse or data mart to find relationships and patterns', 'Be responsible for implementing the systems, processes and logic required to extract, transform, clean, and distribute data across one or more data stores from a wide variety of sources for systems with moderate complexity', 'Work under general guidance and clear framework of accountability with substantial autonomy', 'Use best practices and knowledge of internal or external business issues to improve products or services', 'Solve complex problems; takes a new perspective using existing solutions', 'Able to interpret user requirements and identify additional information needed in user requirements', 'Able to see effects of current design with future requirements and see possible coding solutions to meet the requirements', 'Detailed understanding of logical and physical data structures', 'and discuss with the team', 'Highly skilled at designing tests for unfamiliar designs; Evaluates tests for weaknesses and continuously improves them'], 'Benefits': ['Also, some positions may include bonuses or other incentives']}",Data engineer,en,15113200,4,,541512,Computer Systems Design Services
HCShKDrrNT8AAAAAAAAAAA==,Disney Media & Entertainment Distribution,https://upload.wikimedia.org/wikipedia/commons/thumb/c/cc/Disney_Media_and_Entertainment_Distribution_logo.svg/1200px-Disney_Media_and_Entertainment_Distribution_logo.svg.png,,,JobServe,FULLTIME,Lead Data Engineer,https://www.jobserve.com/us/en/extjob/LEAD-DATA-ENGINEER-in-Dallas-Texas-USA-9B3F79DD177BEEF34C/,False,0.5575,"Job Overview

Our Data and Analytics team for Disney Streaming Services (DSS), a segment under the Disney Entertainment & ESPN Technology (DE&ET) is looking for a Lead Data Engineer. Data is essential for all our decision-making needs whether it's related to product design, measuring advertising effectiveness, helping users discover new content or building new businesses in emerging markets. This data is deeply valuable and gives us insights into how we can continue improving our service for our users, advertisers and our content partners. Our Engagement and Retention Data Engineering team is seeking a highly motivated Data Engineer with a strong technical background and passionate about diving deeper into Big Data to develop state of the art Data Solutions. What You'll Do
• Contribute to the design and growth of our Data Products and Data Warehouses around Engagement and Retention Analytics and Data Science
• Design and develop scalable data warehousing solutions, building ETL pipelines in Big Data environments (cloud, on-prem, hybrid)
• Our tech stack includes Hadoop, AWS, Snowflake, Spark and Airflow and languages include Python, Scala
• Help architect data solutions/frameworks and define data models for the underlying data warehouse and data marts
• Collaborate with Data Product Managers, Data Architects and Data Engineers to design, implement, and deliver successful data solutions
• Maintain detailed documentation of your work and changes to support data quality and data governance
• Ensure high operational efficiency and quality of your solutions to meet SLAs and support commitment to our customers (Data Science, Data Analytics teams)
• Be an active participant and advocate of agile/scrum practice to ensure health and process improvements for your team Key Qualifications
• At least 7 years of data engineering experience developing large data pipelines
• Strong SQL skills and ability to create queries to extract data and build performant datasets
• Hands-on experience with distributed systems such as Spark, Hadoop (HDFS, Hive, Presto, PySpark) to query and process data
• Strong programming skills in Python
• Experience with at least one major MPP or cloud database technology (Snowflake, Redshift, Big Query)
• Solid experience with data integration toolsets (ie Airflow) and writing and maintaining Data Pipelines
• Strong in Data Modeling techniques and Data Warehousing standard methodologies and practices
• Familiar with Scrum and Agile methodologies
• You are a problem solver with strong attention to detail and excellent analytical and communication skills
• Nice to have experience with Cloud technologies like AWS (S3, EMR, EC2) Required Education
• Bachelor's or Master's Degree in Computer Science, Information Systems or related field Additional Information

The hiring range for this position in California is $149,240 - $200,200 per year. The base pay actually offered will take into account internal equity and also may vary depending on the candidate's geographic region, job-related knowledge, skills, and experience among other factors. A bonus and/or long-term incentive units may be provided as part of the compensation package, in addition to the full range of medical, financial, and/or other benefits, dependent on the level and position offered.",False,1690416120,2023-07-27T00:02:00.000Z,Dallas,TX,US,32.776665,-96.79699,['health_insurance'],"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=0&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=HCShKDrrNT8AAAAAAAAAAA%3D%3D",2023-08-26T00:02:00.000Z,1693008120.0,"{'no_experience_required': False, 'required_experience_in_months': 84, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': True, 'professional_certification_mentioned': False}",False,149240.0,200200.0,USD,YEAR,"{'Qualifications': ['At least 7 years of data engineering experience developing large data pipelines', 'Strong SQL skills and ability to create queries to extract data and build performant datasets', 'Hands-on experience with distributed systems such as Spark, Hadoop (HDFS, Hive, Presto, PySpark) to query and process data', 'Strong programming skills in Python', 'Experience with at least one major MPP or cloud database technology (Snowflake, Redshift, Big Query)', 'Solid experience with data integration toolsets (ie Airflow) and writing and maintaining Data Pipelines', 'Strong in Data Modeling techniques and Data Warehousing standard methodologies and practices', 'Familiar with Scrum and Agile methodologies', 'You are a problem solver with strong attention to detail and excellent analytical and communication skills', 'Nice to have experience with Cloud technologies like AWS (S3, EMR, EC2) Required Education', ""Bachelor's or Master's Degree in Computer Science, Information Systems or related field Additional Information""], 'Responsibilities': ['Contribute to the design and growth of our Data Products and Data Warehouses around Engagement and Retention Analytics and Data Science', 'Design and develop scalable data warehousing solutions, building ETL pipelines in Big Data environments (cloud, on-prem, hybrid)', 'Our tech stack includes Hadoop, AWS, Snowflake, Spark and Airflow and languages include Python, Scala', 'Help architect data solutions/frameworks and define data models for the underlying data warehouse and data marts', 'Collaborate with Data Product Managers, Data Architects and Data Engineers to design, implement, and deliver successful data solutions', 'Maintain detailed documentation of your work and changes to support data quality and data governance', 'Ensure high operational efficiency and quality of your solutions to meet SLAs and support commitment to our customers (Data Science, Data Analytics teams)', 'Be an active participant and advocate of agile/scrum practice to ensure health and process improvements for your team Key Qualifications'], 'Benefits': [""The base pay actually offered will take into account internal equity and also may vary depending on the candidate's geographic region, job-related knowledge, skills, and experience among other factors"", 'A bonus and/or long-term incentive units may be provided as part of the compensation package, in addition to the full range of medical, financial, and/or other benefits, dependent on the level and position offered']}",Data engineer,en,15113200,4,,,
aV5T0382CTgAAAAAAAAAAA==,"Stark Dev, LLC",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT5BSMIt7m2uiId_3142LNElhU-kvf9h48rIEOM&s=0,,,Trabajo.org,FULLTIME,"Sr. Azure Data Engineer/Dallas,TX/ W2",https://us.trabajo.org/job-1275-20230724-aa3f02cd58ce867110e1b6bcb7663628,False,0.3783,"This position is open for *United States Citizens/ GC/GC EAD/H4 EAD/TN VISA HOLDERS.*
• CONTRACT with the candidate directly with an extension option after initial 6 months of employment.*

Job Title

Data Devops engineer

SKILLS:

Azure DevOps

CI/CD pipeline

Azure SQL

Azure Synapse

ETL

With your expertise in SQL Server databases, Azure SQL databases, ETL processes, automation, and hybrid cloud architectures, you will play a pivotal role in our organization's technical progress. As a Senior Data/DevOps Engineer, your primary responsibility will be providing robust and reliable database administration support for a diverse range of environments, including on-prem SQL Servers and Azure SQL Databases. Alongside the hands-on technical work, we are looking for a professional who can drive process enhancements, implement automation to improve efficiency, and manage the entire life cycle of ETL solutions for both internal and external systems. This position requires a strong data analytics mindset to design, develop, and maintain our data analytics solutions.

Job Type: Contract

Pay: From $65.00 per hour

Compensation package:
• Hourly pay

Experience level:
• 4 years
• 5 years

Schedule:
• Monday to Friday

Ability to commute/relocate:
• Dallas, TX: Reliably commute or planning to relocate before starting work (Required)

Experience:
• CI/CD: 3 years (Required)
• Azure DevOps: 4 years (Required)
• Azure SQL: 4 years (Required)
• Azure Synapse: 3 years (Required)

Work Location: In person",False,1690175599,2023-07-24T05:13:19.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=90&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=aV5T0382CTgAAAAAAAAAAA%3D%3D",2023-07-31T00:00:00.000Z,1690761600.0,"{'no_experience_required': False, 'required_experience_in_months': None, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': False, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['5 years', 'Dallas, TX: Reliably commute or planning to relocate before starting work (Required)', 'CI/CD: 3 years (Required)', 'Azure DevOps: 4 years (Required)', 'Azure Synapse: 3 years (Required)'], 'Benefits': ['CONTRACT with the candidate directly with an extension option after initial 6 months of employment.*', 'Pay: From $65.00 per hour', 'Compensation package:', 'Monday to Friday']}",,en,15113200,4,,,
uTkg0mApiRgAAAAAAAAAAA==,Alto Pharmacy,,,,ZipRecruiter,FULLTIME,Senior Data Engineer,"https://www.ziprecruiter.com/c/Alto-Pharmacy/Job/Senior-Data-Engineer/-in-Dallas,TX?jid=a78db4a3205d1126",True,0.6175,"Alto is America's leading digital pharmacy, transforming a $500 billion industry. Founded in 2015, Alto's better pharmacy model is centered on the critical role of pharmacists as the final link in a person's health journey. Alto combines expert pharmacist care with purpose-built technology to deliver a more convenient and affordable experience for those who need medication. To date, Alto has fulfilled more than three million prescriptions, expanded to twelve markets, and built a mobile app experience that makes it easier than ever to manage medications and chat with a pharmacist. As Alto continues its rapid growth, it remains customer obsessed, with an industry-leading NPS score of 86.

About the Role

The Alto Data Engineering team is responsible for several key business areas:
• ETL, data visualization, and metadata platforms (fivetran, snowflake, dbt, looker, datahub) that power business analytics and decision making
• ML platform (kubeflow) powering the models that automate and optimize pharmacy operations
• Data integrations with healthcare networks, drug manufacturers, and other partnerships

Our goal is to make high quality data accessible to everyone at Alto to accelerate decision making and improve our products. We're looking for an experienced, customer minded engineer with a strong sense of ownership to join our team.

Accelerate Your Career as You
• Build a world class self service data platform that makes it easy to quickly answer business questions, trace lineage, and monitor data accuracy and latency
• Scale out our machine learning platform and collaborate with our Data Science team to integrate ML/AI applications with our pharmacy operations platform
• Identify core problems we can solve for our customer teams and build products that can support and scale data at Alto

A Bit About You

Minimum Qualifications:
• 7+ years of production data engineering experience
• Strong technical skills in python, SQL, and data modeling
• Experience with data warehouses, E(LT/TL) tools, and cloud services
• Strong sense of ownership over your work
• Comfortable working at startup pace and focus

Preferred Qualifications:
• Demonstrated experience improving data governance, accuracy, and latency
• Familiarity defining and implementing security and data access policies
• Experience and opinions on how to best leverage our core technologies
• AWS expertise

Additional Physical Job Requirements
• Read English, comprehend, and follow simple oral and written instructions. The worker is required to have close visual acuity to perform an activity such as: preparing and analyzing data and figures; transcribing; viewing a computer terminal; extensive reading. Assessing the accuracy, neatness and thoroughness of the work assigned.
• Communicating with others to exchange information. Expressing or exchanging ideas by means of the spoken word; those activities where detailed or important spoken instructions must be conveyed to other workers accurately, loudly, or quickly.
• Perceiving the nature of sounds at normal speaking levels with or without correction, and having the ability to receive detailed information through oral communication, and making fine discriminations in sound.
• Frequent repeating motions required to operate a computer that may include the wrists, hands and/or fingers.
• Sedentary work: Sitting most of the time, exerting up to 10 pounds of force occasionally and/or a negligible amount of force frequently or constantly to lift, carry, push, pull or otherwise move objects, including the human body. Walking & standing are required occasionally.

Salary and Benefits

Salary Range: $159,000 - $199,000

Commission Eligible: No

Equity Eligible: Yes

Travel: No

Benefits: Full-time: Medical, Dental, Vision, 401(k), Group Life, AD&D, Employer paid STD/LTD, generous PTO and parental leave.

#LI-Remote

Alto Pharmacy is an Equal Opportunity Employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, gender, sexual orientation, national origin, genetic information, age, disability, veteran status, or any other legally protected basis.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records. We are an E-Verify company.",True,1689934451,2023-07-21T10:14:11.000Z,Dallas,TX,US,32.776665,-96.79699,"['retirement_savings', 'dental_coverage', 'paid_time_off', 'health_insurance']","https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=90&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=uTkg0mApiRgAAAAAAAAAAA%3D%3D",2023-08-26T00:00:00.000Z,1693008000.0,"{'no_experience_required': False, 'required_experience_in_months': 84, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': False, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['7+ years of production data engineering experience', 'Strong technical skills in python, SQL, and data modeling', 'Experience with data warehouses, E(LT/TL) tools, and cloud services', 'Strong sense of ownership over your work', 'Comfortable working at startup pace and focus', 'Read English, comprehend, and follow simple oral and written instructions', 'The worker is required to have close visual acuity to perform an activity such as: preparing and analyzing data and figures; transcribing; viewing a computer terminal; extensive reading', 'Sedentary work: Sitting most of the time, exerting up to 10 pounds of force occasionally and/or a negligible amount of force frequently or constantly to lift, carry, push, pull or otherwise move objects, including the human body', 'Walking & standing are required occasionally'], 'Responsibilities': ['ETL, data visualization, and metadata platforms (fivetran, snowflake, dbt, looker, datahub) that power business analytics and decision making', 'ML platform (kubeflow) powering the models that automate and optimize pharmacy operations', 'Data integrations with healthcare networks, drug manufacturers, and other partnerships', 'Assessing the accuracy, neatness and thoroughness of the work assigned', 'Communicating with others to exchange information', 'Perceiving the nature of sounds at normal speaking levels with or without correction, and having the ability to receive detailed information through oral communication, and making fine discriminations in sound', 'Frequent repeating motions required to operate a computer that may include the wrists, hands and/or fingers'], 'Benefits': ['Salary and Benefits', 'Salary Range: $159,000 - $199,000', 'Commission Eligible: No', 'Benefits: Full-time: Medical, Dental, Vision, 401(k), Group Life, AD&D, Employer paid STD/LTD, generous PTO and parental leave']}",Data engineer,en,15113200,4,['15-1199.06: Database Architects'],,
eMdLLHNlwWsAAAAAAAAAAA==,Jobot,https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRNwo2ypQevbabADKl8PjDknSLh_Ru7W8jKoYoG&s=0,,,Dice.com,FULLTIME,Azure Data Engineer,https://www.dice.com/job-detail/1fd6150a-43b5-46d8-8217-ee965a24970a,False,0.6698,"Great collaborative company that is focused on utilizing and investing in the latest and greatest technology!

This Jobot Job is hosted by: Jasmine Robinson
Are you a fit? Easy Apply now by clicking the ""Apply Now"" button and sending us your resume.
Salary: $125,000 - $150,000 per year

A bit about us:

We focus on simplifying business transformation. We apply thought leadership and innovation to bring our customer's digital agenda to reality. We partner with customers in their journey from vision to adoption, and across the plethora of technology options available today.

Why join us?

We offer a flexible work schedule, collaborative environment, and ability to work with the latest and greatest technology!

Job Details

We are seeking an experienced Senior Data Engineer who will work with clients and members of the consulting team on the architecture, design, and development of highly scalable data integration and data engineering processes. The Senior Consultant must have a strong understanding and experience with data & analytics solution architecture, including data warehousing, data lakes, ETL/ELT workload patterns, and related BI & analytics systems.

Additional responsibilities of this role will include the following:

Deliver consulting projects/work on-time, on-budget, and in a way that accomplishes client goals
Develop and implement technical best practices for data ingestion, data quality, data cleansing, and other data integration/ETL/Engineering-related activities
Understand and experience maintaining a multi-terabyte enterprise data warehouse with accompanying incremental data pipelines
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and modern cloud technologies.
Conduct or participate in meetings with owners of key system components to fully understand current data and systems environments
Resolve source data issues and refine transformation rules
Analyze source system data to assess transformation logic and data quality through data profiling
Leverage data quality processes to assist with data cleansing requirements
Work with technical and business representatives to determine strategies for handling data anomalies that are identified
Design ETL processes and develop source-to-target data mappings, integration workflows, and load processes
Develop, test, integrate, and deploy data pipelines using a variety of tools and external programming/scripting languages as necessary
Provide technical documentation and other artifacts for data pipelines, ingestion, integration or other data solutions
Identify problems, develop ideas and propose solutions within differing situations requiring analytical, evaluative or constructive thinking in daily work
Apply creative thinking to identify possible reporting solution alternatives
Other duties assigned as needed
Requirements and Qualifications

3+ years hands-on experience with one or more of these data integration/ETL tools:
Azure Data Factory
Databricks/Spark
Experience building on-prem data warehousing solutions
Experience with designing and developing ETL's, Data Marts, Star Schema's
Experience with building data warehousing solutions in Azure
Moving data from on-prem to cloud
Designing a data warehouse solution using Synapse or Azure SQL DB
Experience building pipelines using Synapse or Azure Data Factory to ingest data from various sources
Understanding of integration run times available in Azure
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases
Knowledge of scripting languages like Python, Scala.
Microsoft Azure Cloud platform certifications (nice to have)
Must be able to travel to client locations based on project needs

This position is contract-to-hire. You will be eligible for full-time benefits during the contract period.

Interested in hearing more? Easy Apply now by clicking the ""Apply Now"" button.",False,1689423709,2023-07-15T12:21:49.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=90&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=eMdLLHNlwWsAAAAAAAAAAA%3D%3D",2023-08-27T12:23:25.000Z,1693139005.0,"{'no_experience_required': False, 'required_experience_in_months': 36, 'experience_mentioned': True, 'experience_preferred': False}","['Design', 'Transformation', 'Business transformation', 'Data cleansing', 'Data warehouse', 'Technical writing', 'ELT', 'Reporting', 'Scripting', 'Budget', 'Cloud computing', 'Extract', 'transform', 'load', 'Innovation', 'Database', 'Extraction', 'Data', 'Microsoft Windows Azure', 'Data profiling', 'Business intelligence', 'Star schema', 'Relational databases', 'Jasmine', 'Workflow', 'SQL', 'Data marts', 'Software development', 'Analytical skill', 'Scala', 'Creativity', 'Apache Spark', 'SQL Azure', 'FOCUS', 'Thought leadership', 'Data quality', 'Data integration', 'Data engineering', 'Solution architecture', 'Analytics', 'Python']","{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': False, 'degree_preferred': False, 'professional_certification_mentioned': True}",False,125000.0,150000.0,USD,YEAR,"{'Qualifications': ['We are seeking an experienced Senior Data Engineer who will work with clients and members of the consulting team on the architecture, design, and development of highly scalable data integration and data engineering processes', 'The Senior Consultant must have a strong understanding and experience with data & analytics solution architecture, including data warehousing, data lakes, ETL/ELT workload patterns, and related BI & analytics systems', '3+ years hands-on experience with one or more of these data integration/ETL tools:', 'Experience building on-prem data warehousing solutions', ""Experience with designing and developing ETL's, Data Marts, Star Schema's"", 'Moving data from on-prem to cloud', 'Designing a data warehouse solution using Synapse or Azure SQL DB', 'Experience building pipelines using Synapse or Azure Data Factory to ingest data from various sources', 'Understanding of integration run times available in Azure', 'Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases', 'Knowledge of scripting languages like Python, Scala', 'Microsoft Azure Cloud platform certifications (nice to have)', 'Must be able to travel to client locations based on project needs'], 'Responsibilities': ['Deliver consulting projects/work on-time, on-budget, and in a way that accomplishes client goals', 'Develop and implement technical best practices for data ingestion, data quality, data cleansing, and other data integration/ETL/Engineering-related activities', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and modern cloud technologies', 'Conduct or participate in meetings with owners of key system components to fully understand current data and systems environments', 'Resolve source data issues and refine transformation rules', 'Analyze source system data to assess transformation logic and data quality through data profiling', 'Leverage data quality processes to assist with data cleansing requirements', 'Work with technical and business representatives to determine strategies for handling data anomalies that are identified', 'Design ETL processes and develop source-to-target data mappings, integration workflows, and load processes', 'Develop, test, integrate, and deploy data pipelines using a variety of tools and external programming/scripting languages as necessary', 'Provide technical documentation and other artifacts for data pipelines, ingestion, integration or other data solutions', 'Identify problems, develop ideas and propose solutions within differing situations requiring analytical, evaluative or constructive thinking in daily work', 'Apply creative thinking to identify possible reporting solution alternatives', 'Other duties assigned as needed'], 'Benefits': ['Salary: $125,000 - $150,000 per year', 'You will be eligible for full-time benefits during the contract period']}",Data engineer,en,15113200,4,,,
g9Rv4Q-2xh0AAAAAAAAAAA==,"V-Soft Consulting Group, Inc.",https://www.vsoftconsulting.com/wp-content/uploads/2018/09/VSoft-Logo.png,http://www.vsoftconsulting.com,,LinkedIn,FULLTIME,AWS Data Engineer,https://www.linkedin.com/jobs/view/aws-data-engineer-at-v-soft-consulting-group-inc-3673779665,False,0.5829,"Job Title: AWS Data Engineer

Location: HYBRID

Boston, MA; Raleigh, NC or Westlake, TX (Need Locals)

Top skills:

Must-Haves (Concepts & Tools):
• AWS cloud—KMS, S3, Glue, Lambda etc.
• Deployed data pipelines
• Java, Python or PySpark hands on development experience

Nice-to-Haves (Concepts & Tools):
• Prior ETL migration experience from on prem. To cloud
• Exposure to even driven streaming

Thanks,

Mounika,

mvajja@vsoftconsulting.com",False,1690213278,2023-07-24T15:41:18.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=90&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=g9Rv4Q-2xh0AAAAAAAAAAA%3D%3D",2023-08-23T15:41:18.000Z,1692805278.0,"{'no_experience_required': False, 'required_experience_in_months': None, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': True, 'degree_mentioned': False, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['Java, Python or PySpark hands on development experience'], 'Responsibilities': ['AWS cloud—KMS, S3, Glue, Lambda etc', 'Deployed data pipelines', 'Exposure to even driven streaming']}",Data engineer,en,15113200,4,,,
Bd66No41SbcAAAAAAAAAAA==,NTT DATA Services,https://www.nttdata.com/jp/ja/-/media/nttdatajapan/images/news/release/2022/082500/082500-01.png?la=ja-jp&hash=5325A3858BA7CD912B3FA5B285C60638647319CC,http://www.nttdata.com,,Built In,FULLTIME,"Senior Data Engineer (Python(Expert)/Cloud/AWS/GCP) (Dallas, TX)",https://builtin.com/job/data/senior-data-engineer-pythonexpertcloudawsgcp/1933468,False,0.5966,"Req ID: 247008

NTT DATA Services strives to hire exceptional, innovative and passionate individuals who want to grow with us. If you want to be part of an inclusive, adaptable, and forward-thinking organization, apply now.

We are currently seeking a Senior Data Engineer (Python(Expert)/Cloud/AWS/GCP) to join our team in Dallas, Texas (US-TX), United States (US).

Job Duties and Responsibilities:
• Understand client requirements and understand case studies or current implementation for Predictive models, able to understand business domain needs and implement data pipelines & predictive models, Experience in Agile projects, work with multiple stakeholders like business, project team and deployment teams, ability to work independently and switch technical skills based on the project needs.
• Detail oriented self-starter capable of working independently.

Experience in ETL and ETL cloud services like AWS Data Pipeline Product Details, AWS Glue
• Experience with private or public cloud technology.
• Excellent written and verbal communication skills with ability to document and design proposals.
• Expert in writing software packaging and deploying into a fully automated environment.
• Experience in Service Now.

Basic Qualifications:
• 5+ years of Release or Automation or Software Engineering experience, or equivalent.
• 5+ years Linux experience.
• 5+ years programming experience with Java or Python and scripting
• 3+ years of experience in DevSecOps toolchains/automation to achieve CICD, Blue-Green deployments, feature toggles (Git, Jenkins, uDeploy).
• 3+ years with Agile Scrum (Daily Standup, Sprint Planning and Sprint Retrospective meetings) and Kanban.
• CADM-Cloud Apps-AWS (Amazon)- 3-5 years
• Data and Intelligence-ETL-Architecture-ETL Tools - 3-5 years

#INDFSINS

#INDAPPS

About NTT DATA Services

NTT DATA Services is a recognized leader in IT and business services, including cloud, data and applications, headquartered in Texas. As part of NTT DATA, a $30 billion trusted global innovator with a combined global reach of over 80 countries, we help clients transform through business and technology consulting, industry and digital solutions, applications development and management, managed edge-to-cloud infrastructure services, BPO, systems integration and global data centers. We are committed to our clients' long-term success. Visit nttdata.com or LinkedIn to learn more.

NTT DATA Services is an equal opportunity employer and considers all applicants without regarding to race, color, religion, citizenship, national origin, ancestry, age, sex, sexual orientation, gender identity, genetic information, physical or mental disability, veteran or marital status, or any other characteristic protected by law. We are committed to creating a diverse and inclusive environment for all employees. If you need assistance or an accommodation due to a disability, please inform your recruiter so that we may connect you with the appropriate team.",False,1690049211,2023-07-22T18:06:51.000Z,Plano,TX,US,33.019844,-96.69888,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=90&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=Bd66No41SbcAAAAAAAAAAA%3D%3D",,,"{'no_experience_required': False, 'required_experience_in_months': 60, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': True, 'degree_mentioned': False, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['Experience in ETL and ETL cloud services like AWS Data Pipeline Product Details, AWS Glue', 'Experience with private or public cloud technology', 'Excellent written and verbal communication skills with ability to document and design proposals', 'Expert in writing software packaging and deploying into a fully automated environment', 'Experience in Service Now', '5+ years of Release or Automation or Software Engineering experience, or equivalent', '5+ years Linux experience', '5+ years programming experience with Java or Python and scripting', '3+ years of experience in DevSecOps toolchains/automation to achieve CICD, Blue-Green deployments, feature toggles (Git, Jenkins, uDeploy)', '3+ years with Agile Scrum (Daily Standup, Sprint Planning and Sprint Retrospective meetings) and Kanban', 'CADM-Cloud Apps-AWS (Amazon)- 3-5 years', 'Data and Intelligence-ETL-Architecture-ETL Tools - 3-5 years'], 'Responsibilities': ['Understand client requirements and understand case studies or current implementation for Predictive models, able to understand business domain needs and implement data pipelines & predictive models, Experience in Agile projects, work with multiple stakeholders like business, project team and deployment teams, ability to work independently and switch technical skills based on the project needs', 'Detail oriented self-starter capable of working independently']}",Data engineer,en,15113200,4,,,
NTqfpUM9qagAAAAAAAAAAA==,ringcentral,https://www.ringcentral.com/content/dam/rc-www/en_us/images/content/whyringcentral/pressimages/2022/img-1.png,http://www.ringcentral.com,Information,Salary.com,FULLTIME,Data Engineer (Full Time; Multiple Openings,https://www.salary.com/job/ringcentral/data-engineer-full-time-multiple-openings/j202305260616257193727,False,0.6457,"Say hello to possibilities. It’s not everyday that you consider starting a new career. We’re RingCentral, and we’re happy that someone as talented as you is considering this role. First, a little about us, we’re the $2 billion global leader in cloud-based communications and collaboration software. We are fundamentally changing the nature of human interaction—giving people the freedom to connect powerfully and personally from anywhere, at any time, on any device. This is where you and your skills come in. We’re currently looking for: Responsible for building and maintaining solutions around the various RingCentral distributed database technologies. To succeed in this role you must have experience in: Develop and enhance RingCentral’s distributed databases and data infrastructure; Develop high-quality, high-performance distributed systems in Python, SQL and Java. Build robust, reliable, automated data pipelines using Kafka and Spark streaming. Develop upon and integrate with other services within the RingCentral application and development stacks. Work closely with other teams to understand and mitigate issues and improve performance. Work closely with RingCentral’s operations teams to help develop and optimize solutions. Work with large data volumes, including processing, transforming and transporting large-scale data using big data stacks. Design, build and launch new data models in production. Design, build and launch new data extraction, transformation and loading processes in production. Desired Qualifications: U.S. Master’s degree or foreign equivalent in Computer Science, Information Systems or a related field. Experience with Hadoop, HDFS, Hive, HBase, Python, SQL, Kafka, Spark, MapReduce, Hive SQL, and Linux is required Exerience with Programming Languages: C/C , Java, C, Python, Unix is required. Experience with Databases: MongoDB, ElasticSearch, Vertica, Amazon Redshift, Oracle is required. What we offer: Comprehensive medical, dental, vision, disability, life insurance Health Savings Account (HSA), Flexible Spending Account (FSAs) and Commuter benefits 401K match and ESPP Flexible vacation Wellness programs including 1:1 coaching and meditation guidance Paid parental and pregnancy leave and new parent gift boxes Family-forming benefits (IVF, Preservation, Adoption etc.) Emergency backup care (Child/Adult/Pets) Parental support for children with developmental and learning disabilities Pet insurance Employee Assistance Program (EAP) with counseling sessions available 24/7 Free legal services that provide legal advice, document creation and estate planning Employee bonus referral program Student loan refinancing assistance Employee perks and discounts program RingCentral’s IT team ensures company data is accessible, secure, and optimized in ways that provide maximum competitive advantage. We are constantly discovering, developing and deploying innovations that power productivity and drive better decisions for our customers. Our IT professionals are talented, ambitious, out-of-the-box thinkers who love to learn on the job—planning, deploying and maintaining state-of-the-art technology to deliver flawless performance 24/7/365. RingCentral’s work culture is the backbone of our success. And don’t just take our word for it: we are recognized as a Best Place to Work by Glassdoor, the Top Work Culture by Comparably and hold local BPTW awards in every major location. Bottom line: We are committed to hiring and retaining great people because we know you power our success. RingCentral offers on-site, remote and hybrid work options optimized for the ways we work and live now. About RingCentral RingCentral, Inc. (NYSE: RNG) is a leading provider of business cloud communications and contact center solutions based on its powerful Message Video Phone™  (MVP™) global platform. More flexible and cost effective than legacy on-premises PBX and video conferencing systems that it replaces, RingCentral® empowers modern mobile and distributed workforces to communicate, collaborate, and connect via any mode, any device, and any location. RingCentral is headquartered in Belmont, California, and has offices around the world. RingCentral is an equal opportunity employer that truly values diversity. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. If you are hired in Dallas, Texas, the compensation range for this position is $153, 000 for full-time employees, in addition to eligibility for variable pay, equity, and benefits. Benefits may include, but are not limited to, health and wellness, 401k, ESPP, vacation, parental leave, and more! The salary may vary depending on your location, skills, and experience. RingCentral, Inc. (NYSE: RNG) is a leading provider of global enterprise cloud communications, collaboration, and contact center solutions. More flexible and cost-effective than legacy on-premises systems, the RingCentral platform empowers employees to Work as OneTM from any location, on any device, and via any mode to better serve customers, improving business efficiency and customer satisfaction. The company provides unified voice, video meetings, team messaging, digital customer engagement, and integrated contact center solutions for enterprises globally. RingCentral’s open platform integrates with leading business apps and enables customers to easily customize business workflows. RingCentral is headquartered in Belmont, California, and has offices around the world. RingCentral is an EEO/AA employer.",False,1685145600,2023-05-27T00:00:00.000Z,,TX,US,32.707874,-96.92091,"['health_insurance', 'paid_time_off', 'dental_coverage', 'retirement_savings']","https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=90&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=NTqfpUM9qagAAAAAAAAAAA%3D%3D",2023-11-26T00:00:00.000Z,1700956800.0,"{'no_experience_required': False, 'required_experience_in_months': None, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,,,,,{},Data engineer,en,15113200,4,,511210,Software Publishers
fgEVfs0XL3QAAAAAAAAAAA==,"RIT Solutions, Inc.",https://upload.wikimedia.org/wikipedia/commons/4/49/Rochester_Institute_of_Technology_Seal_%282018%29.svg,http://www.rit.edu,Education,Lensa,FULLTIME,Data Engineer,https://lensa.com/data-engineer-jobs/dallas/jd/d8a402729fcfee1b3630e62a8405127f,False,0.4732,"Job Description

Duration: 6+ month
Visa: Only GC/USC -will need GC copy /citizenship proof
Must have a valid LinkedIn profile
Must be local and go onsite 2-3 days/week - Charlotte NC, Dallas TX, Chandler AZ, Newark, NJ
Must haves-

Terraform -5+ years

Azure -4+ years

Data Lake- 4+ years

Data Architecture -2+ years
• * We are seeking Cloud DB Platform Engineers with Cloud and Data Engineering experience.

Need some of the following skills:
Terraform or Kubernetes, Azure/GCP, DevOps Engineering, ETL , Client/AI, Data lake, Data architecture",False,1689276160,2023-07-13T19:22:40.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=90&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=fgEVfs0XL3QAAAAAAAAAAA%3D%3D",2023-08-12T19:22:40.000Z,1691868160.0,"{'no_experience_required': False, 'required_experience_in_months': None, 'experience_mentioned': True, 'experience_preferred': False}","['Reading Comprehension', 'Active Listening', 'Writing', 'Speaking', 'Critical Thinking', 'Active Learning', 'Monitoring', 'Social Perceptiveness', 'Coordination', 'Complex Problem Solving', 'Programming', 'Judgment and Decision Making', 'Systems Analysis', 'Systems Evaluation']","{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': False, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['Visa: Only GC/USC -will need GC copy /citizenship proof', 'Must have a valid LinkedIn profile', 'Must be local and go onsite 2-3 days/week - Charlotte NC, Dallas TX, Chandler AZ, Newark, NJ', 'Terraform -5+ years', 'Azure -4+ years', 'Data Lake- 4+ years', 'Data Architecture -2+ years', 'We are seeking Cloud DB Platform Engineers with Cloud and Data Engineering experience', 'Terraform or Kubernetes, Azure/GCP, DevOps Engineering, ETL , Client/AI, Data lake, Data architecture']}",Data engineer,en,15113200,4,['15-1199.06 Database Architects'],61,Education
uGwOKTzWK8YAAAAAAAAAAA==,"Evergreen Residential Holdings, LLC",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTzXy9DKoUcVC1d9HG1Ia4RfWx6MNgGfVUdEl1r&s=0,,,Glassdoor,FULLTIME,Sr. Data Engineer,"https://www.glassdoor.com/job-listing/sr-data-engineer-evergreen-residential-JV_IC1139977_KO0,16_KE17,38.htm?jl=1008718815422",True,0.5623,"We are Evergreen Residential, a high growth early-stage institutional investment platform in the single-family residential sector. Our team is collaborative, open-minded and curious. Transparency is a core value, we speak our minds, are responsible for our actions and celebrate our wins. We are serious about the business without taking ourselves too seriously. We look for people who thrive in an entrepreneurial and fast paced environment. If you are self-motivated and mission driven with a 'can do' mindset and see solutions where others may see problems, come and grow with us!

We offer a flexible, empowering culture, competitive compensation and benefits, and potential for career growth through working closely with, and learning from, our experienced leadership team.

This is not a consulting position. Applicants must be authorized to work for any employer in the U.S. We are unable to sponsor or take over sponsorship of an employment Visa at this time for this position.

This position will be (Full-time/Permanent employment) based in our downtown Dallas offices, and we will consider a hybrid work schedule.

As a technical/engineering expert, you also pride yourself on being able to quickly build strong business relationships both internally and externally e.g., with the leadership team, current and potential investors. With a passion for keeping current with advancements of the field, you deploy technology and data resources to provide innovative solutions to business needs. You will design and support data warehouse systems, perform data extraction and ensure data accuracy, enabling real-time insights from both internal and market data that will drive revenue growth and capital efficiency. This position plays a critical role in working with our analytics and reporting specialists to help Evergreen Residential make the best investment decisions.

The Role: Priorities can often change in a fast-paced environment like ours. Initial focus is to work with external data purchased, and to harvest internal data and work within Snowflake warehouse for use in our 3rd party property mgt system and BI reporting tool. Overall ensure there is one source of truth.

The role includes, but is not limited to, the following responsibilities:
• Designing and implementing data pipelines to extract, transform, and load data from various sources into a centralized data repository
• Developing and maintaining data processing and storage infrastructure
• Establish productive relationships and effective communications with Company leadership to understand business drivers and align on required outcomes
• Collaborating with data analysts to ensure that data is readily available for analysis and modeling
• Optimizing database performance and troubleshooting issues as they arise
• Implementing data security and access controls to protect sensitive data
• Highlight key trends derived from data analysis and be a resource for improving data proficiency throughout the organization
• Staying up-to-date with emerging trends and technologies in data engineering
• Leverage historical data and predictive models to identify key historical factors that impact critical KPIs, and recommend actions to drive future performance
• Ensure scientific method and research are key drivers of the product roadmap

What You Will Bring to the Table:
• Bachelor's Degree in a relevant field required
• Min 5 years of experience in data engineering or a related field
• Proficiency in one or more programming languages such as Python, Java, or Scala
• Experience with data processing and storage technologies such as Hadoop, Spark, Kafka, Snowflake, and NoSQL databases
• Experience in real estate investment and/or rental sector highly desirable
• Prior experience managing a team of direct reports within the Data Science, Data Engineering, Analytics space in the SFR or Multifamily industry
• Significant Experience building, motivating, and retaining a high- performing, flexible and collaborative data and analytics function
• Proven hands-on technical background in data science, business intelligence or data engineering with demonstrated strategic impact at an executive level
• A strong problem solver with experience building technical strategy and understanding technical tradeoffs and risk
• Collaborative team player, you are truly a ""do-er"", happy to be a hands-on problem-solver to move the data program forward
• Excellent communication skills – verbal and written

About Evergreen Residential

Founded in 2021, Evergreen Residential is a full-service SFR platform leveraging proven operational practices and the latest technological advances to optimize investor returns and achieve positive outcomes for our residents and the communities in which we operate. We offer a full suite of services, including Investment Management, Asset Origination, and Advisory Services. The firm is headquartered in Dallas with offices in New York City.

The leadership team has extensive experience dating back to the early institutionalization of SFR and unrivaled depth of experience in the complete asset life cycle. We are built to withstand changing market conditions, and our business produces resilient, predictable cash flows and margins. We are committed to charting new paths and using data to achieve best-in-class results. Our business is evergreen.

Beyond financial returns, the Company is committed to measurable impact objectives. We believe that inclusive and equitable management, environmentally sustainable long-term strategies, and resident-focused policies are good business - for our residents, our investors, and our team. We are committed to using environmentally sustainable practices and empowering our residents to improve their financial health.

Our cornerstone values - Accountability, Transparency and Partnership - are built on a foundation of Integrity and provide the roadmap for our daily actions, interactions and decisions.

Equal Opportunities and Other Employment Statements

We are deeply committed to building a workplace and community where inclusion is not only valued, but prioritized. We take pride in being an equal opportunity employer and seek to create a welcoming environment based on mutual respect, and to recruit, develop and retain the most talented people from a diverse candidate pool. All employment decisions shall be made without regard to race, color, religion, gender, gender identity or expression, family status, marital status, sexual orientation, national origin, genetics, neuro-diversity, disability, age, or veteran status, or any other basis as protected by federal, state, or local law.",False,1687392000,2023-06-22T00:00:00.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=90&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=uGwOKTzWK8YAAAAAAAAAAA%3D%3D",,,"{'no_experience_required': False, 'required_experience_in_months': 60, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': True, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': [""Bachelor's Degree in a relevant field required"", 'Min 5 years of experience in data engineering or a related field', 'Proficiency in one or more programming languages such as Python, Java, or Scala', 'Experience with data processing and storage technologies such as Hadoop, Spark, Kafka, Snowflake, and NoSQL databases', 'Prior experience managing a team of direct reports within the Data Science, Data Engineering, Analytics space in the SFR or Multifamily industry', 'Significant Experience building, motivating, and retaining a high- performing, flexible and collaborative data and analytics function', 'Proven hands-on technical background in data science, business intelligence or data engineering with demonstrated strategic impact at an executive level', 'A strong problem solver with experience building technical strategy and understanding technical tradeoffs and risk', 'Collaborative team player, you are truly a ""do-er"", happy to be a hands-on problem-solver to move the data program forward', 'Excellent communication skills – verbal and written'], 'Responsibilities': ['You will design and support data warehouse systems, perform data extraction and ensure data accuracy, enabling real-time insights from both internal and market data that will drive revenue growth and capital efficiency', 'Initial focus is to work with external data purchased, and to harvest internal data and work within Snowflake warehouse for use in our 3rd party property mgt system and BI reporting tool', 'Overall ensure there is one source of truth', 'Designing and implementing data pipelines to extract, transform, and load data from various sources into a centralized data repository', 'Developing and maintaining data processing and storage infrastructure', 'Establish productive relationships and effective communications with Company leadership to understand business drivers and align on required outcomes', 'Collaborating with data analysts to ensure that data is readily available for analysis and modeling', 'Optimizing database performance and troubleshooting issues as they arise', 'Implementing data security and access controls to protect sensitive data', 'Highlight key trends derived from data analysis and be a resource for improving data proficiency throughout the organization', 'Staying up-to-date with emerging trends and technologies in data engineering', 'Leverage historical data and predictive models to identify key historical factors that impact critical KPIs, and recommend actions to drive future performance', 'Ensure scientific method and research are key drivers of the product roadmap']}",Data engineer,en,15113200,4,,,
VoQSDjkz-2QAAAAAAAAAAA==,LTIMindtree,https://www.ltimindtree.com/wp-content/uploads/2022/10/LTIMindtree_Linear_2-1-LT-Blue-1-1.png,http://www.lntinfotech.com,Computer Services,LTIMindtree,FULLTIME,Senior Specialist - Data Engineering,https://careers.ltimindtree.com/job/Dallas-Senior-Specialist-Data-Engineering-TX-75201/956028601/,False,0.7696,"A little about us...

LTIMindtree is a global technology consulting and digital solutions company that enables enterprises across industries to reimagine business models, accelerate innovation, and maximize growth by harnessing digital technologies. As a digital transformation partner to more than 750 clients, LTIMindtree brings extensive domain and technology expertise to help drive superior competitive differentiation, customer experiences, and business outcomes in a converging world. Powered by nearly 90,000 talented and entrepreneurial professionals across more than 30 countries, LTIMindtree — a Larsen & Toubro Group company — combines the industry-acclaimed strengths of erstwhile Larsen and Toubro Infotech and Mindtree in solving the most complex business challenges and delivering transformation at scale. For more information, please visit www.ltimindtree.com

Job Title : Data Engineer (MSBI – SSIS)

Job Location : Remote / Dallas, TX

Required Experience : 06 - 12 Years

Job Description:
• We are looking for an experienced Data Engineer (MSBI-SSIS) to join our team.
• The ideal candidate is highly skilled in MSBI-SSIS and has experience in dealing with large-scale data extraction and manipulation.
• The Data Engineer will be responsible for designing and developing SSIS packages to extract and manipulate data from multiple sources.
• The Engineer will also be responsible for managing and troubleshooting data flows, ensuring the data is correct and within the required formats.

Responsibilities:
• Design, develop, and maintain ETL packages using MSBI-SSIS.
• Develop data dictionary for the data sources and target systems.
• Analyze data requirements and develop solutions to meet them.
• Troubleshoot and debug data integration issues.
• Proficient in creating jobs, packages, and stored procedures in MSBI-SSIS.
• Design and develop data models to support the data analysis process.
• Ensure data consistency, integrity, and security.
• Develop and maintain data related documentation.
• Develop and maintain SSIS packages for data integration and migration.
• Develop and maintain SSRS reports.
• Perform data profiling and data cleansing.
• Monitor performance and optimize ETL processes.
• Prepare data for reporting and analysis.
• Work with BI teams to ensure data accuracy.
• Assist with other data related tasks as needed.

Requirements:
• Bachelor’s degree in Computer Science or related field.
• 6+ years of experience in MSBI-SSIS development.
• Expertise in data integration and data manipulation.
• Experience with SQL databases and query optimization.
• Knowledge of data warehousing concepts and ETL design patterns.
• Knowledge of data profiling and data cleansing.
• Experience with SSRS reporting.
• Excellent problem-solving, communication, and analytical skills.
• Ability to work independently and in a team environment.

How will you grow:
• Role-based Training programs
• Continuing Education Programs (CEP) to enhance your knowledge, skills, and attitude as a professional
• We encourage you to acquire various beneficial international certifications, with costs s reimbursed
• Our role-based workshop helps us groom future leaders for LTI

What's in it for you:
• Excellent benefits plan: medical, dental, vision, life, FSA, & PTO
• Roll over vacation days
• Commuter benefits
• Excellent growth and advancement opportunities
• Certification reimbursement
• Rewards and recognition programs
• Innovative and collaborative company culture

LTIMindtree is an equal opportunity employer that is committed to diversity in the workplace. Our employment decisions are made without regard to race, color, creed, religion, sex (including pregnancy, childbirth or related medical conditions), gender identity or expression, national origin, ancestry, age, family-care status, veteran status, marital status, civil union status, domestic partnership status, military service, handicap or disability or history of handicap or disability, genetic information, atypical hereditary cellular or blood trait, union affiliation, affectional or sexual orientation or preference, or any other characteristic protected by applicable federal, state, or local law, except where such considerations are bona fide occupational qualifications permitted by law.",False,1688947200,2023-07-10T00:00:00.000Z,Dallas,TX,US,32.776665,-96.79699,"['paid_time_off', 'dental_coverage', 'retirement_savings', 'health_insurance']","https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=90&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=VoQSDjkz-2QAAAAAAAAAAA%3D%3D",,,"{'no_experience_required': False, 'required_experience_in_months': 72, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': True, 'professional_certification_mentioned': True}",False,,,,,"{'Qualifications': ['Required Experience : 06 - 12 Years', 'The ideal candidate is highly skilled in MSBI-SSIS and has experience in dealing with large-scale data extraction and manipulation', 'Bachelor’s degree in Computer Science or related field', '6+ years of experience in MSBI-SSIS development', 'Expertise in data integration and data manipulation', 'Experience with SQL databases and query optimization', 'Knowledge of data warehousing concepts and ETL design patterns', 'Knowledge of data profiling and data cleansing', 'Experience with SSRS reporting', 'Excellent problem-solving, communication, and analytical skills', 'Ability to work independently and in a team environment'], 'Responsibilities': ['The Data Engineer will be responsible for designing and developing SSIS packages to extract and manipulate data from multiple sources', 'The Engineer will also be responsible for managing and troubleshooting data flows, ensuring the data is correct and within the required formats', 'Design, develop, and maintain ETL packages using MSBI-SSIS', 'Develop data dictionary for the data sources and target systems', 'Analyze data requirements and develop solutions to meet them', 'Troubleshoot and debug data integration issues', 'Proficient in creating jobs, packages, and stored procedures in MSBI-SSIS', 'Design and develop data models to support the data analysis process', 'Ensure data consistency, integrity, and security', 'Develop and maintain data related documentation', 'Develop and maintain SSIS packages for data integration and migration', 'Develop and maintain SSRS reports', 'Perform data profiling and data cleansing', 'Monitor performance and optimize ETL processes', 'Prepare data for reporting and analysis', 'Work with BI teams to ensure data accuracy', 'Assist with other data related tasks as needed'], 'Benefits': ['Role-based Training programs', 'Continuing Education Programs (CEP) to enhance your knowledge, skills, and attitude as a professional', 'We encourage you to acquire various beneficial international certifications, with costs s reimbursed', 'Excellent benefits plan: medical, dental, vision, life, FSA, & PTO', 'Roll over vacation days', 'Commuter benefits', 'Excellent growth and advancement opportunities', 'Rewards and recognition programs', 'Innovative and collaborative company culture']}",Senior specialist,en,15113200,4,,541511,Custom Computer Programming Services
K392nkfmd28AAAAAAAAAAA==,Alcority,,http://www.alcority.com,,ZipRecruiter,FULLTIME,Data Engineering Manager,"https://www.ziprecruiter.com/c/Alcority/Job/Data-Engineering-Manager/-in-Dallas,TX?jid=36ea57b473f139e6",True,0.7286,"Job Summary:

Alcority, a global professional services firm, is looking for an experienced Data Engineering Manager. The Data Engineering Manager, reporting to the Data Solutions Architect, expand and lead our data engineering team. As a strategic partner to a number of investments and operating companies around the world, Alcority is responsible for delivering technology solutions that help our partners create a competitive advantage. The ideal candidate will have strong leadership skills, technical expertise in data engineering, and excellent communication skills. The Data Engineering Manager will be responsible for overseeing the development and maintenance of our data engineering architecture, data pipelines, and data platforms, and must have experience in managing data engineering teams and working with the latest cloud based and Informatica SaaS technologies. He/she will have a passion for data with a keen interest to not only understand the technical components, but also understand the business context and impact of technical solutions that are provided.

The candidate can prioritize competing requirements, strategize development, guide in developing scalable solutions, and leverage AI for development.

Key Responsibilities:
• Lead and manage the internal Data Engineering Team, including hiring, training, coaching/mentoring, and performance management.
• Develop resource plans to determine the right mix of internal and external resources; engage and manage 3rd party consultants/contractors as needed.
• Develop and maintain the data engineering architecture and design to support the company's business objectives and strategy.
• Develop and maintain data pipelines and data platforms using cloud-based technologies such as Informatica Data Management Cloud and Azure Data Factory ensuring data quality and reliability.
• Work collaboratively with cross-functional teams and businesses including product management, data science, and analytics teams, to deliver data solutions that meet business needs.
• Develop and maintain standards, policies, and procedures for data engineering best practices.
• Develop and maintain documentation for data engineering processes and procedures.
• Implement and manage best SDLC practices including agile CI/CD, automation.
• Manage budgets, timelines, and resources for data engineering projects.
• Clearly understand priority under pressure, strategize, guide, and develop scalable solutions.
• Have knowledge to leveraging AI for development, using machine learning and other AI technologies to improve data quality, automate processes, and enhance the data engineering pipeline.

Requirements:
• Bachelor's degree in computer science, Information Technology, or a related field
• At least 10 years of experience in data engineering, with at least 5 years in a leadership role managing teams that have spanned across multiple international Time zones.
• Strong technical skills in data engineering, including experience with data architecture, data pipelines, data platforms, and data integration tools, with a focus on cloud-based technologies such as Informatica Cloud, Azure Data Factory with a Strong mindset on Building the softwares as Scalable micro services or micro components.
• Experience with Informatica SaaS and other relevant cloud-based technologies such as Snowflake, Databricks, and Apache Kafka
• Strong leadership skills, with experience in managing large data sets and engineering teams. Should be a master in delegating, guiding, and completing.
• Excellent communication and interpersonal skills, with the ability to work effectively with cross-functional teams.
• Strong problem-solving and analytical skills
• Ability to clearly understand priority under pressure, strategize, guide, and develop scalable solutions.
• Experience leveraging AI for development, using machine learning and other AI technologies to improve data quality, automate processes, and enhance the data engineering pipeline.
• Ability to work under pressure and navigate multiple priorities in a fast-paced environment.
• Experience with Agile development methodologies is a plus. (Eg: Devops, Jira or GitHub)

It is impossible to list every requirement for, or responsibility of, any position. Similarly, we cannot identify all the skills a position may require since job responsibilities and the Company's needs may change over time. Therefore, the above job description is not comprehensive or exhaustive. The Company reserves the right to adjust, add to or eliminate any aspect of the above description. The Company also retains the right to require all employees to undertake additional or different job responsibilities when necessary to meet business needs.

Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future.

Benefits & Perks:
• Time Off: 20 days of PTO for full-time employees and 12 company holidays.
• Summer Fridays: July 4th through Labor Day, the office is completely closed/offline every other Friday.
• Company Paid Benefits: Life insurance, Short-term disability, Long-term disability, Paid parental leave, Employee Assistance Program, and medical insurance in our high deductible health plan.
• Optional Employee Paid Benefits:Medical insurance in our EPO plan, Dental benefits, and Vision benefits. We also offer Health Savings Accounts, Flexible Spending Accounts, Supplemental Life insurance, and more.
• 401(k): Eligible after 60 days. Discretionary company match of 50% up to the first 6% of contributions.

EQUAL OPPORTUNITY EMPLOYER

ALCORITY IS AN EQUAL EMPLOYMENT OPPORTUNITY EMPLOYER. THE COMPANY'S POLICY IS NOT TO DISCRIMINATE AGAINST ANY APPLICANT OR EMPLOYEE BASED ON RACE, COLOR, RELIGION, NATIONAL ORIGIN, GENDER, AGE, SEXUAL ORIENTATION, GENDER IDENTITY OR EXPRESSION, MARITAL STATUS, MENTAL OR PHYSICAL DISABILITY, AND GENETIC INFORMATION, OR ANY OTHER BASIS PROTECTED BY APPLICABLE LAW. THE FIRM ALSO PROHIBITS HARASSMENT OF APPLICANTS OR EMPLOYEES BASED ON ANY OF THESE PROTECTED CATEGORIES.",False,1690271308,2023-07-25T07:48:28.000Z,Dallas,TX,US,32.776665,-96.79699,"['retirement_savings', 'paid_time_off', 'dental_coverage', 'health_insurance']","https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=90&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=K392nkfmd28AAAAAAAAAAA%3D%3D",2023-08-24T00:00:00.000Z,1692835200.0,"{'no_experience_required': False, 'required_experience_in_months': 120, 'experience_mentioned': True, 'experience_preferred': True}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': True, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': [""Bachelor's degree in computer science, Information Technology, or a related field"", 'At least 10 years of experience in data engineering, with at least 5 years in a leadership role managing teams that have spanned across multiple international Time zones', 'Strong technical skills in data engineering, including experience with data architecture, data pipelines, data platforms, and data integration tools, with a focus on cloud-based technologies such as Informatica Cloud, Azure Data Factory with a Strong mindset on Building the softwares as Scalable micro services or micro components', 'Experience with Informatica SaaS and other relevant cloud-based technologies such as Snowflake, Databricks, and Apache Kafka', 'Strong leadership skills, with experience in managing large data sets and engineering teams', 'Should be a master in delegating, guiding, and completing', 'Excellent communication and interpersonal skills, with the ability to work effectively with cross-functional teams', 'Strong problem-solving and analytical skills', 'Ability to clearly understand priority under pressure, strategize, guide, and develop scalable solutions', 'Experience leveraging AI for development, using machine learning and other AI technologies to improve data quality, automate processes, and enhance the data engineering pipeline', 'Ability to work under pressure and navigate multiple priorities in a fast-paced environment', '(Eg: Devops, Jira or GitHub)', 'Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future'], 'Responsibilities': ['The Data Engineering Manager will be responsible for overseeing the development and maintenance of our data engineering architecture, data pipelines, and data platforms, and must have experience in managing data engineering teams and working with the latest cloud based and Informatica SaaS technologies', 'He/she will have a passion for data with a keen interest to not only understand the technical components, but also understand the business context and impact of technical solutions that are provided', 'The candidate can prioritize competing requirements, strategize development, guide in developing scalable solutions, and leverage AI for development', 'Lead and manage the internal Data Engineering Team, including hiring, training, coaching/mentoring, and performance management', 'Develop resource plans to determine the right mix of internal and external resources; engage and manage 3rd party consultants/contractors as needed', ""Develop and maintain the data engineering architecture and design to support the company's business objectives and strategy"", 'Develop and maintain data pipelines and data platforms using cloud-based technologies such as Informatica Data Management Cloud and Azure Data Factory ensuring data quality and reliability', 'Work collaboratively with cross-functional teams and businesses including product management, data science, and analytics teams, to deliver data solutions that meet business needs', 'Develop and maintain standards, policies, and procedures for data engineering best practices', 'Develop and maintain documentation for data engineering processes and procedures', 'Implement and manage best SDLC practices including agile CI/CD, automation', 'Manage budgets, timelines, and resources for data engineering projects', 'Clearly understand priority under pressure, strategize, guide, and develop scalable solutions', 'Have knowledge to leveraging AI for development, using machine learning and other AI technologies to improve data quality, automate processes, and enhance the data engineering pipeline'], 'Benefits': ['Time Off: 20 days of PTO for full-time employees and 12 company holidays', 'Summer Fridays: July 4th through Labor Day, the office is completely closed/offline every other Friday', 'Company Paid Benefits: Life insurance, Short-term disability, Long-term disability, Paid parental leave, Employee Assistance Program, and medical insurance in our high deductible health plan', 'Optional Employee Paid Benefits:Medical insurance in our EPO plan, Dental benefits, and Vision benefits', 'We also offer Health Savings Accounts, Flexible Spending Accounts, Supplemental Life insurance, and more', '401(k): Eligible after 60 days', 'Discretionary company match of 50% up to the first 6% of contributions']}",Engineering manager,en,11302100,4,['15-1141.00: Database Administrators'],,
xWoztRVZBtcAAAAAAAAAAA==,Disney Media & Entertainment Distribution,https://upload.wikimedia.org/wikipedia/commons/thumb/c/cc/Disney_Media_and_Entertainment_Distribution_logo.svg/1200px-Disney_Media_and_Entertainment_Distribution_logo.svg.png,,,MyArklaMiss Jobs,FULLTIME,Lead Data Engineer,https://jobs.myarklamiss.com/jobs/lead-data-engineer-dallas-texas/1074864542-2/,False,0.5492,"Job Overview

Our Data and Analytics team for Disney Streaming Services (DSS), a segment under the Disney Entertainment & ESPN Technology (DE&ET) is looking for a Lead Data Engineer. Data is essential for all our decision-making needs whether it's related to product design, measuring advertising effectiveness, helping users discover new content or building new businesses in emerging markets. This data is deeply valuable and gives us insights into how we can continue improving our service for our users, advertisers and our content partners. Our Engagement and Retention Data Engineering team is seeking a highly motivated Data Engineer with a strong technical background and passionate about diving deeper into Big Data to develop state of the art Data Solutions.

What You'll Do
• Contribute to the design and growth of our Data Products and Data Warehouses around Engagement and Retention Analytics and Data Science
• Design and develop scalable data warehousing solutions, building ETL pipelines in Big Data environments (cloud, on-prem, hybrid)
• Our tech stack includes Hadoop, AWS, Snowflake, Spark and Airflow and languages include Python, Scala
• Help architect data solutions/frameworks and define data models for the underlying data warehouse and data marts
• Collaborate with Data Product Managers, Data Architects and Data Engineers to design, implement, and deliver successful data solutions
• Maintain detailed documentation of your work and changes to support data quality and data governance
• Ensure high operational efficiency and quality of your solutions to meet SLAs and support commitment to our customers (Data Science, Data Analytics teams)
• Be an active participant and advocate of agile/scrum practice to ensure health and process improvements for your team
Key Qualifications
• At least 7 years of data engineering experience developing large data pipelines
• Strong SQL skills and ability to create queries to extract data and build performant datasets
• Hands-on experience with distributed systems such as Spark, Hadoop (HDFS, Hive, Presto, PySpark) to query and process data
• Strong programming skills in Python
• Experience with at least one major MPP or cloud database technology (Snowflake, Redshift, Big Query)
• Solid experience with data integration toolsets (i.e Airflow) and writing and maintaining Data Pipelines
• Strong in Data Modeling techniques and Data Warehousing standard methodologies and practices
• Familiar with Scrum and Agile methodologies
• You are a problem solver with strong attention to detail and excellent analytical and communication skills
• Nice to have experience with Cloud technologies like AWS (S3, EMR, EC2)
Required Education
• Bachelor's or Master's Degree in Computer Science, Information Systems or related field
Additional Information

The hiring range for this position in California is $149,240 - $200,200 per year. The base pay actually offered will take into account internal equity and also may vary depending on the candidate's geographic region, job-related knowledge, skills, and experience among other factors. A bonus and/or long-term incentive units may be provided as part of the compensation package, in addition to the full range of medical, financial, and/or other benefits, dependent on the level and position offered.",False,1690429495,2023-07-27T03:44:55.000Z,Dallas,TX,US,32.776665,-96.79699,['health_insurance'],"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=10&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=xWoztRVZBtcAAAAAAAAAAA%3D%3D",,,"{'no_experience_required': False, 'required_experience_in_months': 84, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': True, 'professional_certification_mentioned': False}",False,149240.0,200200.0,USD,YEAR,"{'Qualifications': ['At least 7 years of data engineering experience developing large data pipelines', 'Strong SQL skills and ability to create queries to extract data and build performant datasets', 'Hands-on experience with distributed systems such as Spark, Hadoop (HDFS, Hive, Presto, PySpark) to query and process data', 'Strong programming skills in Python', 'Experience with at least one major MPP or cloud database technology (Snowflake, Redshift, Big Query)', 'Solid experience with data integration toolsets (i.e Airflow) and writing and maintaining Data Pipelines', 'Strong in Data Modeling techniques and Data Warehousing standard methodologies and practices', 'Familiar with Scrum and Agile methodologies', 'You are a problem solver with strong attention to detail and excellent analytical and communication skills', 'Nice to have experience with Cloud technologies like AWS (S3, EMR, EC2)', ""Bachelor's or Master's Degree in Computer Science, Information Systems or related field""], 'Responsibilities': ['Contribute to the design and growth of our Data Products and Data Warehouses around Engagement and Retention Analytics and Data Science', 'Design and develop scalable data warehousing solutions, building ETL pipelines in Big Data environments (cloud, on-prem, hybrid)', 'Our tech stack includes Hadoop, AWS, Snowflake, Spark and Airflow and languages include Python, Scala', 'Help architect data solutions/frameworks and define data models for the underlying data warehouse and data marts', 'Collaborate with Data Product Managers, Data Architects and Data Engineers to design, implement, and deliver successful data solutions', 'Maintain detailed documentation of your work and changes to support data quality and data governance', 'Ensure high operational efficiency and quality of your solutions to meet SLAs and support commitment to our customers (Data Science, Data Analytics teams)', 'Be an active participant and advocate of agile/scrum practice to ensure health and process improvements for your team'], 'Benefits': [""The base pay actually offered will take into account internal equity and also may vary depending on the candidate's geographic region, job-related knowledge, skills, and experience among other factors"", 'A bonus and/or long-term incentive units may be provided as part of the compensation package, in addition to the full range of medical, financial, and/or other benefits, dependent on the level and position offered']}",Data engineer,en,15113200,4,,,
ailo5hpdYyEAAAAAAAAAAA==,Fidelity Investments,https://1000logos.net/wp-content/uploads/2017/11/Fidelity-Logo.png,http://www.fidelity.com,Finance,Fidelity Investments,FULLTIME,Data Engineer,https://jobiak.fidelity.com/jobdetails/dallas-tx-data-engineer-64be49cf4d21b70a8cf28959,False,0.5711,"Job Description:

Fidelity Investments Workplace Solutions (WS) organization is looking for an Principal Data Engineer. This person will be playing a key role in designing and crafting a modern Data and Information Delivery and Analytics platform in the cloud to support Equity Compensation products for the Global markets. This person will be working closely with architects and engineers and business SMEs to build and release solutions that help customers get the information they need fast and intuitively.

The Expertise and Skills You Bring
• Bachelor’s Degree or equivalent in a technology related field (e.g. Computer Science, Engineering, etc.) required
• 10+ years of hands-on experience in Data engineering, data warehousing and analytics technologies
• Proven ability with modern Object-Oriented Programming Languages (Python, Scala, Java)
• Advanced skills in data intensive application development, data integration, and data pipeline design patterns on a distributed platform
• Strong knowledge of designing data engineering solutions and platforms
• Working experience with Relational Databases like Oracle
• Experience with business intelligence and analytics tools such as OBIEE, PowerBI or Tableau
• Strong working knowledge of cloud native data warehousing and data lake solutions using Snowflake, Redshift etc.
• Experience building scalable patterns for data consumption from cloud based data-lakes.
• Advanced experience with PL/SQL and complex queries
• Solid understanding of Cloud Computing and DevOps concepts including CI/CD pipelines
• Significant experience with ELT data integration and data movement design patterns
• Working experience of NoSQL and BigData technologies such as e.g. Hadoop, HBase, MongoDB, Cassandra, etc.
• Ability and passion for leading tech teams and mentor junior engineers
• Your ability to collaborate with other technical and business minds in the organization
• Ability to learn and experiment with new technologies and patterns
• Your penchant for modern test driven and automation driven software development methodologies
• Expertise in converting technology goals into achievable initiatives and Epics and stories
• Experience in executing projects in an Agile environment

The Team

You will be part of the technology team in Stock Plan Services business unit that administers equity compensation programs on behalf of public and private companies offering various compensations programs such as: Employee Stock Purchase Plans, Restricted Stock Awards/Units, Stock Option Plans, Stock Appreciation Rights and Performance based Awards. Currently SPS services approx. 3M participants employed by over 500 clients and spread out in 150 countries. The business is looking to further expand in the international equity compensation markets and servicing. As part of that we are modernizing our legacy reporting and business intelligence platform to provide data and analytics in real-time running in the cloud.

Please see below for the salary range for work locations in Colorado only:
N/A

Please see below for the salary range for work locations in New York City, Westchester County, NY and Jersey City, NJ only:
N/A

Please see below for the salary range for work locations in California only:
N/A

Please see below for the salary range for work locations in Washington only:
N/A

Certifications:

Company Overview

Fidelity Investments is a privately held company with a mission to strengthen the financial well-being of our clients. We help people invest and plan for their future. We assist companies and non-profit organizations in delivering benefits to their employees. And we provide institutions and independent advisors with investment and technology solutions to help invest their own clients’ money.

Join Us

At Fidelity, you’ll find endless opportunities to build a meaningful career that positively impacts peoples’ lives, including yours. You can take advantage of flexible benefits that support you through every stage of your career, empowering you to thrive at work and at home. Honored with a Glassdoor Employees’ Choice Award, we have been recognized by our employees as a Best Place to Work in 2023. And you don’t need a finance background to succeed at Fidelity—we offer a range of opportunities for learning so you can build the career you’ve always imagined.

At Fidelity, our goal is for most people to work flexibly in a way that balances both personal and business needs with time onsite and offsite through what we’re calling “Dynamic Working”. Most associates will have a hybrid schedule with a requirement to work onsite at a Fidelity work location for at least one week, 5 consecutive days, every four weeks. These requirements are subject to change.

We invite you to Find Your Fidelity at fidelitycareers.com.

Fidelity Investments is an equal opportunity employer. We believe that the most effective way to attract, develop and retain a diverse workforce is to build an enduring culture of inclusion and belonging.

Fidelity will reasonably accommodate applicants with disabilities who need adjustments to participate in the application or interview process. To initiate a request for an accommodation, contact the HR Accommodation Team by sending an email to accommodations @fmr.com, or by calling 800-835-5099, prompt 2, option 3.

At Fidelity, we value honesty, integrity, and the safety of our associates and customers within a heavily regulated industry. Certain roles may require candidates to go through a preliminary credit check during the screening process. Candidates who are presented with a Fidelity offer will need to go through a background investigation and may be asked to provide additional documentation as requested. This investigation includes but is not limited to a criminal, civil litigations and regulatory review, employment, education, and credit review (role dependent). These investigations will account for 7 years or more of history, depending on the role. Where permitted by federal or state law, Fidelity will also conduct a pre-employment drug screen, which will review for the following substances: Amphetamines, THC (marijuana), cocaine, opiates, phencyclidine.",False,1690329600,2023-07-26T00:00:00.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=10&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=ailo5hpdYyEAAAAAAAAAAA%3D%3D",2023-08-23T00:00:00.000Z,1692748800.0,"{'no_experience_required': False, 'required_experience_in_months': 120, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': False, 'professional_certification_mentioned': True}",False,,,,,"{'Qualifications': ['Bachelor’s Degree or equivalent in a technology related field (e.g. Computer Science, Engineering, etc.) required', '10+ years of hands-on experience in Data engineering, data warehousing and analytics technologies', 'Proven ability with modern Object-Oriented Programming Languages (Python, Scala, Java)', 'Advanced skills in data intensive application development, data integration, and data pipeline design patterns on a distributed platform', 'Strong knowledge of designing data engineering solutions and platforms', 'Working experience with Relational Databases like Oracle', 'Experience with business intelligence and analytics tools such as OBIEE, PowerBI or Tableau', 'Strong working knowledge of cloud native data warehousing and data lake solutions using Snowflake, Redshift etc', 'Experience building scalable patterns for data consumption from cloud based data-lakes', 'Advanced experience with PL/SQL and complex queries', 'Solid understanding of Cloud Computing and DevOps concepts including CI/CD pipelines', 'Significant experience with ELT data integration and data movement design patterns', 'Working experience of NoSQL and BigData technologies such as e.g. Hadoop, HBase, MongoDB, Cassandra, etc', 'Ability and passion for leading tech teams and mentor junior engineers', 'Your ability to collaborate with other technical and business minds in the organization', 'Ability to learn and experiment with new technologies and patterns', 'Your penchant for modern test driven and automation driven software development methodologies', 'Expertise in converting technology goals into achievable initiatives and Epics and stories', 'Experience in executing projects in an Agile environment'], 'Responsibilities': ['This person will be playing a key role in designing and crafting a modern Data and Information Delivery and Analytics platform in the cloud to support Equity Compensation products for the Global markets', 'This person will be working closely with architects and engineers and business SMEs to build and release solutions that help customers get the information they need fast and intuitively'], 'Benefits': ['You can take advantage of flexible benefits that support you through every stage of your career, empowering you to thrive at work and at home']}",Data engineer,en,15113200,4,['15-1132.00 -- Software Developers  Applications'],523920,Portfolio Management
LuuL5FOvfNkAAAAAAAAAAA==,AT&T,https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSFKAkrzoWdCGuLo1gJMq5U0N2cfsey1Z7ztAI0&s=0,,,Career Cast Diversity - CareerCast.com,FULLTIME,Principal-Big Data Engineer,https://diversity.careercast.com/jobs/principal-big-data-engineer-dallas-tx-75219-135026790-d,False,0.5555,"JOB LOCATION: 208 S. Akard Street, Dallas, TX 75202 [and various unanticipated locations throughout the U.S.; may work from home]

DUTIES: Interpret the requirements of various big data analytic use cases and scenarios, and drive the design and implementation of specific data models to ultimately help drive better business decisions through insights from a combination of external and AT&T's data assets. Develop necessary enablers and data platform in the big data lake environment and has the responsibility of maintaining its integrity during the life cycle phases. Define data requirements, gather and mine large scale of structured and unstructured data, and validate data by running various data tools in the big data environment. Support the standardization, customization and ad-hoc data analysis, and develop the mechanisms in ingest, analyze, validate, normalize and clean data. Implement statistical data quality procedures on new data sources, and apply rigorous iterative data analytics. Support data scientists in data sourcing and preparation to visualize data and synthesize insights of commercial value. Work with big data policy and security teams and legal to create data policy and develop interfaces and retention models which requires synthesizing or anonymizing data. Develop and maintain data engineering best practices and contribute to insights on data analytics and visualization concepts, methods and techniques. Technical design to ingest data into Palantir Foundry platform on Azure. Participate in creating ingestion strategy and technology patterns. Provide technical direction (architecture and design) for projects ingesting data into Palantir Foundry. Conduct design, architecture and code reviews. Engage with the vendor to meet AT&T requirements and deliverables. Create tasks for Data Replication and Data Synchronization. Utilize Oracle, Teradata, Vertica, Azure DataLake, Databricks and Snowflake. Utilize Hbase and Hbase Shell. Develop UNIX shell scripts. Develop database load scripts: VSQL for Vertica. Utilize BTEQ, Mload, Fastload and fast export scripts for Teradata. Utilize SnowSQL for Snowflake and PySpark for Databricks. Develop schedules using workload scheduling tools: TWS.

REQUIREMENTS: Requires a Masters Degree, or foreign equivalent degree, in Electrical and Electronic Engineering, Computer Science, or Computer Engineering and three (3) years of experience in the job offered or three (3) years of experience in a related occupation creating tasks for Data Replication and Data Synchronization; utilizing Oracle, Teradata, Vertica, Azure DataLake, Databricks, Snowflake and Palantir Foundry; utilizing Hbase and Hbase Shell; developing UNIX shell scripts; developing database load scripts: VSQL for Vertica; utilizing BTEQ, Mload, Fastload and fast export scripts for Teradata; utilizing SnowSQL for Snowflake and PySpark for Databricks; and developing schedules using workload scheduling tools: TWS.

Our Principal-Big Data Engineers earn between $158,200 - $254,300 yearly. Not to mention all the other amazing rewards that working at AT&T offers.

Joining our team comes with amazing perks and benefits:

Medical/Dental/Vision coverage

401(k) plan

Tuition reimbursement program

Paid Time Off and Holidays (based on date of hire, at least 23 days of vacation each year and 9 company-designated holidays)

Paid Parental Leave

Paid Caregiver Leave

Additional sick leave beyond what state and local law require may be available but is unprotected

Adoption Reimbursement

Disability Benefits (short term and long term)

Life and Accidental Death Insurance

Supplemental benefit programs: critical illness/accident hospital indemnity/group legal

Employee Assistance Programs (EAP)

Extensive employee wellness programs

Employee discounts up to 50% off on eligible AT&T mobility plans and accessories, AT&T internet (and fiber where available) and AT&T phone

AT&T is an Affirmative Action/Equal Opportunity Employer, and we are committed to hiring a diverse and talented workforce. EOE/AA/M/F/D/V
• np*
AT&T will consider for employment qualified applicants in a manner consistent with the requirements of federal, state and local laws

We expect employees to be honest, trustworthy, and operate with integrity. Discrimination and all unlawful harassment (including sexual harassment) in employment is not tolerated. We encourage success based on our individual merits and abilities without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, disability, marital status, citizenship status, military status, protected veteran status or employment status",False,1689897600,2023-07-21T00:00:00.000Z,Dallas,TX,US,32.776665,-96.79699,"['retirement_savings', 'dental_coverage', 'health_insurance', 'paid_time_off']","https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=10&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=LuuL5FOvfNkAAAAAAAAAAA%3D%3D",2023-08-20T00:00:00.000Z,1692489600.0,"{'no_experience_required': False, 'required_experience_in_months': 36, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['REQUIREMENTS: Requires a Masters Degree, or foreign equivalent degree, in Electrical and Electronic Engineering, Computer Science, or Computer Engineering and three (3) years of experience in the job offered or three (3) years of experience in a related occupation creating tasks for Data Replication and Data Synchronization; utilizing Oracle, Teradata, Vertica, Azure DataLake, Databricks, Snowflake and Palantir Foundry; utilizing Hbase and Hbase Shell; developing UNIX shell scripts; developing database load scripts: VSQL for Vertica; utilizing BTEQ, Mload, Fastload and fast export scripts for Teradata; utilizing SnowSQL for Snowflake and PySpark for Databricks; and developing schedules using workload scheduling tools: TWS'], 'Responsibilities': [""DUTIES: Interpret the requirements of various big data analytic use cases and scenarios, and drive the design and implementation of specific data models to ultimately help drive better business decisions through insights from a combination of external and AT&T's data assets"", 'Develop necessary enablers and data platform in the big data lake environment and has the responsibility of maintaining its integrity during the life cycle phases', 'Define data requirements, gather and mine large scale of structured and unstructured data, and validate data by running various data tools in the big data environment', 'Support the standardization, customization and ad-hoc data analysis, and develop the mechanisms in ingest, analyze, validate, normalize and clean data', 'Implement statistical data quality procedures on new data sources, and apply rigorous iterative data analytics', 'Support data scientists in data sourcing and preparation to visualize data and synthesize insights of commercial value', 'Work with big data policy and security teams and legal to create data policy and develop interfaces and retention models which requires synthesizing or anonymizing data', 'Develop and maintain data engineering best practices and contribute to insights on data analytics and visualization concepts, methods and techniques', 'Technical design to ingest data into Palantir Foundry platform on Azure', 'Participate in creating ingestion strategy and technology patterns', 'Provide technical direction (architecture and design) for projects ingesting data into Palantir Foundry', 'Conduct design, architecture and code reviews', 'Engage with the vendor to meet AT&T requirements and deliverables', 'Create tasks for Data Replication and Data Synchronization', 'Develop database load scripts: VSQL for Vertica', 'Utilize BTEQ, Mload, Fastload and fast export scripts for Teradata', 'Utilize SnowSQL for Snowflake and PySpark for Databricks', 'Develop schedules using workload scheduling tools: TWS'], 'Benefits': ['Our Principal-Big Data Engineers earn between $158,200 - $254,300 yearly', 'Medical/Dental/Vision coverage', '401(k) plan', 'Tuition reimbursement program', 'Paid Time Off and Holidays (based on date of hire, at least 23 days of vacation each year and 9 company-designated holidays)', 'Paid Parental Leave', 'Paid Caregiver Leave', 'Additional sick leave beyond what state and local law require may be available but is unprotected', 'Adoption Reimbursement', 'Disability Benefits (short term and long term)', 'Life and Accidental Death Insurance', 'Supplemental benefit programs: critical illness/accident hospital indemnity/group legal', 'Extensive employee wellness programs', 'Employee discounts up to 50% off on eligible AT&T mobility plans and accessories, AT&T internet (and fiber where available) and AT&T phone']}",Data engineer,en,15113200,4,['Telecommunications'],,
epgFodzuXh8AAAAAAAAAAA==,"PRIMUS Global Services, Inc",,http://www.primusglobal.com,,Indeed,CONTRACTOR,"Software Developer/Data Engineer – Apache Spark, SQL, Kafka Connect – Dallas, TX (Hybrid) 44700",https://www.indeed.com/viewjob?jk=f14fb7a2b85d5796,True,0.5816,"We have an immediate long-term opportunity with one of our prime clients for a position of Software Developer/Data Engineer to work in Dallas, TX on a hybrid basis.

As a Software Developer/Data Engineer, you will be responsible for developing and implementing data engineering solutions, with a focus on utilizing Apache Spark, GCP (Google Cloud Platform), Azure, Databricks (batch processing), SQL, Kafka Connect (Java), and data structures in Java.

Requirements:

Proven experience as a Software Developer/Data Engineer with expertise in Apache Spark, GCP, Azure, Databricks, SQL, Kafka Connect (Java), and Java data structures. Strong knowledge of data engineering concepts, data integration, and data processing. Experience with ETL development and data pipelines. Familiarity with cloud platforms like GCP and Azure for data storage and processing.
• *ALL successful candidates for this position are required to work directly for PRIMUS. No agencies please**

For immediate consideration, please contact:

Pavan
PRIMUS Global Services
Direct: 972-798-2661
Desk: 972-753-6500 Ext: 203
Email: jobs@primusglobal.com",False,1690497100,2023-07-27T22:31:40.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=10&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=epgFodzuXh8AAAAAAAAAAA%3D%3D",,,"{'no_experience_required': False, 'required_experience_in_months': None, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': False, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['Proven experience as a Software Developer/Data Engineer with expertise in Apache Spark, GCP, Azure, Databricks, SQL, Kafka Connect (Java), and Java data structures', 'Strong knowledge of data engineering concepts, data integration, and data processing', 'Experience with ETL development and data pipelines', 'Familiarity with cloud platforms like GCP and Azure for data storage and processing', '*ALL successful candidates for this position are required to work directly for PRIMUS'], 'Responsibilities': ['As a Software Developer/Data Engineer, you will be responsible for developing and implementing data engineering solutions, with a focus on utilizing Apache Spark, GCP (Google Cloud Platform), Azure, Databricks (batch processing), SQL, Kafka Connect (Java), and data structures in Java']}",Engineer,en,15113200,4,,,
A2IULA4j8_8AAAAAAAAAAA==,Rangam Consultants Inc.,"https://res.cloudinary.com/crunchbase-production/image/upload/c_lpad,h_256,w_256,f_auto,q_auto:eco,dpr_1/hum73a6yro6ex9u5d2ch",http://rangam.com,,Rangam,CONTRACTOR,Data Engineer,https://rangam.com/jobs/jobdetails/110586/data-engineer-dallas-tx-us,False,0.6779,"Data Engineer-Contract to hire intention

Data Engineering with SQL, Python
Experience in the following Big Data frameworks: File Format (Parquet, AVRO, ORC etc.)
At least 3 years of experience working with large data sets, streaming, experience working with distributed computing (Map Reduce, Hadoop, Hive, Apache Spark, Apache Kafka etc.)
At least 2 years of experience with AWS cloud (with focus on Data services)

U.S. citizenship required
• The team is is looking for a versatile Data Engineer who will provide data and report development services or technical support.
• You will develop, test, and maintain data or report solutions (data warehouse/mart/stores/data lake/reporting/analytics) using tools and programming languages.
• You will also develop data set processes and assist with design and identify ways to improve data reliability, efficiency, and quality.

As the Data Engineer you will work independently, receive minimal guidance, and have accountability for their work and work of junior members.
• An associate degree, a bachelor’s degree in computer science or equivalent courses
• At least 4 years of experience in Data Engineering with SQL, Python
• Experience with relational SQL and NoSQL databases
• Experience in the following Big Data frameworks: File Format (Parquet, AVRO, ORC etc.)
• At least 3 years of experience working with large data sets, streaming, experience working with distributed computing (Map Reduce, Hadoop, Hive, Apache Spark, Apache Kafka etc.)
• At least 2 years of experience with AWS cloud (with focus on Data services)
• Experience with Databricks a plus
• Experience with RESTful API development, Familiarity with HTTP and invoking web-APIs
• Working knowledge of data structures, SQL, XML, JSON, Data visualization tools, Version Control Systems, Programming, and Unix/Linux shell scripting
• Able to interpret user requirements and identify additional information needed in user requirements
• Able to see effects of current design with future requirements and see possible coding solutions to meet the requirements
• Detailed understanding of logical and physical data structures
• Highly skilled in tools, evaluates the need for various tools for continuous integration, testing, automation, deployment etc. and discuss with the team
• Highly skilled at designing tests for unfamiliar designs; Evaluates tests for weaknesses and continuously improves them
• Detailed understanding of how to effectively test against multiple tools/software
• Equivalent education and/or experience may be substituted for any of the above requirements

Responsibilities:
• Design, develop and implement data mining tools and analyses to sift through large amounts of data stored in a data warehouse or data mart to find relationships and patterns
• Be responsible for implementing the systems, processes and logic required to extract, transform, clean, and distribute data across one or more data stores from a wide variety of sources for systems with moderate complexity
• Work under general guidance and clear framework of accountability with substantial autonomy
• Use best practices and knowledge of internal or external business issues to improve products or services
• Solve complex problems; takes a new perspective using existing solutions",False,1690296823,2023-07-25T14:53:43.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=10&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=A2IULA4j8_8AAAAAAAAAAA%3D%3D",2024-08-27T00:00:00.000Z,1724716800.0,"{'no_experience_required': False, 'required_experience_in_months': 48, 'experience_mentioned': True, 'experience_preferred': True}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': True, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['Experience in the following Big Data frameworks: File Format (Parquet, AVRO, ORC etc.)', 'At least 3 years of experience working with large data sets, streaming, experience working with distributed computing (Map Reduce, Hadoop, Hive, Apache Spark, Apache Kafka etc.)', 'At least 2 years of experience with AWS cloud (with focus on Data services)', 'U.S. citizenship required', 'The team is is looking for a versatile Data Engineer who will provide data and report development services or technical support', 'An associate degree, a bachelor’s degree in computer science or equivalent courses', 'At least 4 years of experience in Data Engineering with SQL, Python', 'Experience with relational SQL and NoSQL databases', 'Experience with RESTful API development, Familiarity with HTTP and invoking web-APIs', 'Working knowledge of data structures, SQL, XML, JSON, Data visualization tools, Version Control Systems, Programming, and Unix/Linux shell scripting', 'Highly skilled in tools, evaluates the need for various tools for continuous integration, testing, automation, deployment etc', 'Equivalent education and/or experience may be substituted for any of the above requirements'], 'Responsibilities': ['As the Data Engineer you will work independently, receive minimal guidance, and have accountability for their work and work of junior members', 'Able to interpret user requirements and identify additional information needed in user requirements', 'Design, develop and implement data mining tools and analyses to sift through large amounts of data stored in a data warehouse or data mart to find relationships and patterns', 'Be responsible for implementing the systems, processes and logic required to extract, transform, clean, and distribute data across one or more data stores from a wide variety of sources for systems with moderate complexity', 'Work under general guidance and clear framework of accountability with substantial autonomy', 'Use best practices and knowledge of internal or external business issues to improve products or services', 'Solve complex problems; takes a new perspective using existing solutions']}",Data engineer,en,15113200,4,,,
iGjbaz-JoBcAAAAAAAAAAA==,Randstad US,https://static.rusacdn.com/images/schema.org/hiringOrganization/randstadlogo.png,http://www.randstadusa.com,Staffing,Nexxt,CONTRACTOR,data engineer,https://www.nexxt.com/jobs/data-engineer-dallas-tx-2557826868-job.html?aff=2ED44C72-8FD2-4B5D-BC54-2F623E88BE26,False,0.4909,"data engineer.
• dallas , texas
• posted today

job details

summary
• $62 - $72 per hour
• contract
• bachelor degree
• category computer and mathematical occupations
• reference1020356

job details

job summary

Required Qualifications -
• Option 1: Bachelor's degree in Computer Science and 4 years' experience in software engineering or related field.
• Option 2: 6 years' experience in software engineering or related field.
• Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related field. 3 years' experience in data engineering, database engineering, business intelligence, or business analytics.

Nice to have soft skills -
• 7+ years of experience with 3+ years of Big data development experience
• Experience in HDFS, Hive, Hive UDF's, MapReduce, Druid, Spark, Python, Hue, Shell Scripting, Unix.
• Demonstrates expertise in writing complex, highly optimized queries across large data sets
• Retail experience and knowledge of commercial data is a huge plus
• Experience with BI Tool Tableau or Looker is a plus

location: Dallas, Texas

job type: Contract

salary: $62 - 72 per hour

work hours: 8am to 5pm

education: Bachelors

responsibilities

Designs, develops, and implements Hadoop eco-system based applications to support business requirements.

Follows approved life cycle methodologies, creates design documents, and performs program coding and testing.

Resolves technical issues through debugging, research, and investigation

qualifications
• Experience level: Experienced
• Minimum 4 years of experience
• Education: Bachelors

skills
• SQL
• Python
• TableauEqual Opportunity Employer: Race, Color, Religion, Sex, Sexual Orientation, Gender Identity, National Origin, Age, Genetic Information, Disability, Protected Veteran Status, or any other legally protected group ~~~ Randstad, we welcome people of all abilities and want to ensure that our hiring and interview process meets the needs of all applicants. If you require a reasonable accommodation to make your application or interview experience a great one, please contact ~~~ offered to a successful candidate will be based on several factors including the candidate's education, work experience, work location, specific job duties, certifications, etc. In addition, Randstad offers a comprehensive benefits package, including health, an incentive and recognition program, and 401K contribution (all benefits are based on eligibility).For certain assignments, Covid-19 vaccination and/or testing may be required by Randstad's client or applicable federal mandate, subject to approved medical or religious accommodations. Carefully review the job posting for details on vaccine/testing requirements or ask your Randstad representative for more information.",False,1690304753,2023-07-25T17:05:53.000Z,Dallas,TX,US,32.776665,-96.79699,"['health_insurance', 'dental_coverage', 'retirement_savings']","https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=10&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=iGjbaz-JoBcAAAAAAAAAAA%3D%3D",,,"{'no_experience_required': False, 'required_experience_in_months': 72, 'experience_mentioned': True, 'experience_preferred': True}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': True, 'professional_certification_mentioned': True}",False,,,,,"{'Qualifications': [""Option 1: Bachelor's degree in Computer Science and 4 years' experience in software engineering or related field"", ""Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related field"", ""3 years' experience in data engineering, database engineering, business intelligence, or business analytics"", 'Nice to have soft skills -', '7+ years of experience with 3+ years of Big data development experience', ""Experience in HDFS, Hive, Hive UDF's, MapReduce, Druid, Spark, Python, Hue, Shell Scripting, Unix"", 'Demonstrates expertise in writing complex, highly optimized queries across large data sets', 'Retail experience and knowledge of commercial data is a huge plus', 'Experience level: Experienced', 'Minimum 4 years of experience', 'Education: Bachelors', 'SQL', 'TableauEqual Opportunity Employer: Race, Color, Religion, Sex, Sexual Orientation, Gender Identity, National Origin, Age, Genetic Information, Disability, Protected Veteran Status, or any other legally protected group ~~~ Randstad, we welcome people of all abilities and want to ensure that our hiring and interview process meets the needs of all applicants'], 'Responsibilities': ['work hours: 8am to 5pm', 'Designs, develops, and implements Hadoop eco-system based applications to support business requirements', 'Follows approved life cycle methodologies, creates design documents, and performs program coding and testing', 'Resolves technical issues through debugging, research, and investigation'], 'Benefits': ['salary: $62 - 72 per hour', 'In addition, Randstad offers a comprehensive benefits package, including health, an incentive and recognition program, and 401K contribution (all benefits are based on eligibility)']}",Data engineer,en,15113200,4,,561311,Employment Placement Agencies
jAYPkmjSPLIAAAAAAAAAAA==,LTIMindtree,https://www.ltimindtree.com/wp-content/uploads/2022/10/LTIMindtree_Linear_2-1-LT-Blue-1-1.png,http://www.lntinfotech.com,Computer Services,ZipRecruiter,FULLTIME,Associate Principal -Data Engineering,"https://www.ziprecruiter.com/c/LTIMindtree/Job/Associate-Principal-Data-Engineering/-in-Dallas,TX?jid=244b1ab0515b9704",False,0.6232,"Technical Skills:

Designs, implements, and documents data architecture and data modeling solutions, which include the use of relational, dimensional

Responsible for the development of the conceptual, logical, and physical data models

Implementation of RDBMS, operational data store (ODS), data marts, and data lakes on target platforms

Define and govern data modeling and design standards, tools, best practices, and related development for enterprise data models

Hands-on modeling, design, configuration, installation, performance tuning,

Experience in Data Vault modeling approach

Extensive knowledge of Snowflake.

Good knowledge of metadata management, data modeling, and related tools (Erwin or ER Studio or others) required

Work closely with the database engineers to create optimal physical data models of datasets

Leadership Skills & Stakeholder Management:

Work very closely with customer stakeholders to understand their needs and make recommendations.

Interact with SMEs (business) and Architect to validate whether the data model is aligned with the technology suggested for the project.

Relay the information gained from onshore to the team and offshore for seamless collaboration and desired outcome.",False,1690467480,2023-07-27T14:18:00.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=10&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=jAYPkmjSPLIAAAAAAAAAAA%3D%3D",2023-08-26T00:00:00.000Z,1693008000.0,"{'no_experience_required': False, 'required_experience_in_months': None, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': False, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['Experience in Data Vault modeling approach', 'Extensive knowledge of Snowflake', 'Good knowledge of metadata management, data modeling, and related tools (Erwin or ER Studio or others) required'], 'Responsibilities': ['Responsible for the development of the conceptual, logical, and physical data models', 'Implementation of RDBMS, operational data store (ODS), data marts, and data lakes on target platforms', 'Define and govern data modeling and design standards, tools, best practices, and related development for enterprise data models', 'Hands-on modeling, design, configuration, installation, performance tuning,', 'Interact with SMEs (business) and Architect to validate whether the data model is aligned with the technology suggested for the project', 'Relay the information gained from onshore to the team and offshore for seamless collaboration and desired outcome']}",Principal,en,11903200,5,['15-1199.06: Database Architects'],541511,Custom Computer Programming Services
_HaktzqqbQEAAAAAAAAAAA==,Incedo Inc.,https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQr1KKB1pa3bQ_NeHM2VwFtfQfSY4V_KClcRf2w&s=0,http://www.incedoinc.com,,LinkedIn,FULLTIME,Data Engineer,https://www.linkedin.com/jobs/view/data-engineer-at-incedo-inc-3675626919,False,0.7006,"Job Description: Data Engineer (Python and GCP)

Location: Alpharetta, GA and Dallas, TX

Incedo is a US-based consulting, analytics, and technology services company. We help our clients achieve competitive advantage through End-to-End Digital Transformation and work across Financial Services, Telecom, Life Science & Healthcare, and Product Engineering sectors.

Incedo Software Solution Architect/Solution Lead play a critical role in developing solutions for client engagements. They are detail-driven with a strong technical background in their domain and excellent problem-solving skills. An ideal candidate will have experience in coding large-scale, responsive web sites with an aim towards performance and progressive enhancement. Incedo teams are cross-functional and may be geographically distributed across the US and India.

Join our team and help develop software to monitor and manage next-generation one of the telecom networks. We are looking to fill out a Software Engineer position requiring solid knowledge of software engineering and architectural best practices.

You will work on the Big Data platform at the one of the telecom networks scale (hundreds of terabytes of data per day). You will design and develop solutions for Big Data challenges, working with applications deployed on-premise and in the Google Cloud.

Qualified candidates should have solid coding experience and be eager and willing to learn. You will be asked to prove your skills during the technical interview.

Required qualifications:

Technical lead with data science experience who can also support the team from an architectural standpoint.

• - GCP

• - Python

• - Feature Engineering

• - Model Selection/Deployments

• - Solution Architect Experience

• B.S. in Computer Science or related field, with 10 years’ work experience.

Good to have:

• Hands-on experience working in Unix/Linux ecosystem

• Experience with developing or maintaining ETL pipelines in a Big Data Hadoop environment.

• Experience in setting up and maintaining CI/CD infrastructure.

• Experience with test automation.

Sudha Ray

Direct: (856) 679 0433 | Email:sudha.ray@incedoinc.com",False,1690319689,2023-07-25T21:14:49.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=10&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=_HaktzqqbQEAAAAAAAAAAA%3D%3D",2023-08-24T21:14:48.000Z,1692911688.0,"{'no_experience_required': False, 'required_experience_in_months': 120, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': True, 'degree_mentioned': True, 'degree_preferred': True, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['An ideal candidate will have experience in coding large-scale, responsive web sites with an aim towards performance and progressive enhancement', 'We are looking to fill out a Software Engineer position requiring solid knowledge of software engineering and architectural best practices', 'Qualified candidates should have solid coding experience and be eager and willing to learn', 'You will be asked to prove your skills during the technical interview', 'Technical lead with data science experience who can also support the team from an architectural standpoint', '- GCP', '- Solution Architect Experience', 'B.S. in Computer Science or related field, with 10 years’ work experience', 'Hands-on experience working in Unix/Linux ecosystem', 'Experience with developing or maintaining ETL pipelines in a Big Data Hadoop environment', 'Experience in setting up and maintaining CI/CD infrastructure', 'Experience with test automation'], 'Responsibilities': ['Incedo Software Solution Architect/Solution Lead play a critical role in developing solutions for client engagements', 'You will work on the Big Data platform at the one of the telecom networks scale (hundreds of terabytes of data per day)', 'You will design and develop solutions for Big Data challenges, working with applications deployed on-premise and in the Google Cloud']}",Data engineer,en,15113200,4,,,
4YnqmBaYvqMAAAAAAAAAAA==,Walmart,https://upload.wikimedia.org/wikipedia/commons/thumb/c/ca/Walmart_logo.svg/2560px-Walmart_logo.svg.png,https://www.walmart.com,Retail,Walmart Careers,FULLTIME,(USA) Senior Data Engineer - Data Ventures,https://careers.walmart.com/us/jobs/WD1562366-usa-senior-data-engineer-data-ventures,False,0.7968,"Position Summary...

What you'll do...

Do you have boundless energy and passion for engineering data used to solve dynamic problems that will shape the future of retail? With the sheer scale of Walmart’s environment comes the biggest of big data sets. As a Walmart Data Engineer, you will dig into our mammoth scale of data to help unleash the power of retail data science by imagining, developing, and maintaining data pipelines that our Data Scientists and Analysts can rely on. You will be responsible for contributing to an orchestration layer of complex data transformations, refining raw data from source into targeted, valuable data assets for consumption in a governed way. You will partner with Data Scientists, Analysts, other engineers, and business stakeholders to solve complex and exciting challenges so that we can build out capabilities that evolve the retail business model while making a positive impact on our customers’ lives.

What you'll do:
• Data Strategy: Understands, articulates, and applies principles of the defined strategy to routine business problems that involve a single function.
• Data Transformation and Integration: Extracts data from identified databases. Creates data pipelines and transform data to a structure that is relevant to the problem by selecting appropriate techniques. Develops knowledge of current analytics trends.
• Data Source Identification: Supports the understanding of the priority order of requirements and service level agreements. Helps identify the most suitable source for data that is fit for purpose. Performs initial data quality checks on extracted data.
• Data Modeling: Analyses complex data elements, systems, data flows, dependencies, and relationships to contribute to conceptual, physical, and logical data models. Develops the Logical Data Model and Physical Data Models including data warehouse and data mart designs. Defines relational tables, primary and foreign keys, and stored procedures to create a data model structure. Evaluates existing data models and physical databases for variances and discrepancies. Develops efficient data flows. Analyses data-related system integration challenges and proposes appropriate solutions.
• Code Development and Testing: Writes code to develop the required solution and application features by determining the appropriate programming language and leveraging business, technical and data requirements. Creates test cases to review and validate the proposed solution design. Creates proofs of concept. Tests the code using the appropriate testing approach. Deploys software to production servers. Contributes code documentation, maintains playbook, and provides timely progress updates.
• Problem Formulation: Translates business problems within one's discipline to data related or mathematical solutions. Identifies what methods (for example, analytics, big data analytics, automation) would provide a solution for the problem. Shares use cases and gives examples to demonstrate how the method would solve the business problem.
• Applied Business Acumen: Provides recommendations to business stakeholders to solve complex business issues. Develops business cases for projects with a projected return on investment or cost savings. Translates business requirements into projects, activities, and tasks and aligns to overall business strategy. Serves as an interpreter and conduit to connect business needs with tangible solutions and results. Recommends new processes and ways of working.
• Data Governance: Establishes, modifies, and documents data governance projects and recommendations. Implements data governance practices in partnership with business stakeholders and peers. Interprets company and regulatory policies on data. Educates others on data governance processes, practices, policies, and guidelines. Provides recommendations on needed updates or inputs into data governance policies, practices, or guidelines.
• Demonstrates up-to-date expertise and applies this to the development, execution, and improvement of action plans by providing expert advice and guidance to others. Supporting and aligning efforts to meet customer and business needs and building commitment for perspectives and rationales.
• Provides and supports the implementation of business solutions by building relationships and partnerships with key stakeholders. Identifying business needs, determining, and carrying out necessary processes and practices.
• Promotes and supports company policies, procedures, mission, values, and standards of ethics and integrity by training and providing direction to others in their use and application, ensuring compliance with them.
• Ensures business needs are being met by evaluating the ongoing effectiveness of current plans, programs, and initiatives. Applying suggestions for improving efficiency and cost effectiveness; and participating in and supporting community outreach events.
• Creates training documentation and trains end-users on data modeling. Oversees the tasks of less experienced programmers and stipulates system troubleshooting supports.
• Drives the execution of multiple business plans and projects by identifying customer and operational needs. Developing and communicating business plans and priorities, removing barriers and obstacles that impact performance. Providing resources, identifying performance standards, measuring progress, and adjusting performance accordingly. Developing contingency plans and demonstrating adaptability and supporting continuous learning.

What you'll bring:
• You have consistently high standards, your passion for quality is inherent in everything.
• Well versed with Hadoop, Spark, Cloud, Python/Scala and Java, Streaming, Kafka, Backend, J2EE.
• You evangelize an extremely high standard of code quality, system reliability, and performance.
• You have a proven track record coding with at least one programming language (e.g., Scala, Python)
• You’re experienced in one of cloud computing platforms (e.g., GCP, Azure)
• You’re skilled in data modeling & data migration protocols.
• Experience with GCP, Data warehousing, BI preferred
• Experience with the integration tools like Automic, Airflow

About Walmart Global Tech
Imagine working in an environment where one line of code can make life easier for hundreds of millions of people. That’s what we do at Walmart Global Tech. We’re a team of software engineers, data scientists, cybersecurity expert's and service professionals within the world’s leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.

Flexible, hybrid work:
We use a hybrid way of working that is primarily in office coupled with virtual when not onsite. Our campuses serve as a hub to enhance collaboration, bring us together for purpose and deliver on business needs. This approach helps us make quicker decisions, remove location barriers across our global team and be more flexible in our personal lives.

Benefits:
Benefits: Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more.

Equal Opportunity Employer:
Walmart, Inc. is an Equal Opportunity Employer – By Choice. We believe we are best equipped to help our associates, customers, and the communities we serve live better when we really know them. That means understanding, respecting, and valuing diversity- unique styles, experiences, identities, ideas and opinions – while being inclusive of all people.

The above information has been designed to indicate the general nature and level of work performed in the role. It is not designed to contain or be interpreted as a comprehensive inventory of all responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process.

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelor’s degree in Computer Science and 3 years' experience in software engineering or related field. Option 2: 5 years’ experience in
software engineering or related field. Option 3: Master's degree in Computer Science and 1 year’s experience in software engineering or related
field.
2 years' experience in data engineering, database engineering, business intelligence, or business analytics.

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Master’s degree in Computer Science, Computer Engineering, Computer Information Systems, Software Engineering, or related area and 1 year's experience in software engineering or related area.

Primary Location...
603 MUNGER AVE STE 400, DALLAS, TX 75202, United States of America",False,1690156800,2023-07-24T00:00:00.000Z,Dallas,TX,US,32.776665,-96.79699,"['health_insurance', 'retirement_savings', 'paid_time_off']","https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=10&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=4YnqmBaYvqMAAAAAAAAAAA%3D%3D",,,"{'no_experience_required': False, 'required_experience_in_months': 60, 'experience_mentioned': True, 'experience_preferred': True}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': True, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['You have consistently high standards, your passion for quality is inherent in everything', 'Well versed with Hadoop, Spark, Cloud, Python/Scala and Java, Streaming, Kafka, Backend, J2EE', 'You evangelize an extremely high standard of code quality, system reliability, and performance', 'You have a proven track record coding with at least one programming language (e.g., Scala, Python)', 'You’re experienced in one of cloud computing platforms (e.g., GCP, Azure)', 'You’re skilled in data modeling & data migration protocols', 'Experience with the integration tools like Automic, Airflow', ""Option 1: Bachelor’s degree in Computer Science and 3 years' experience in software engineering or related field"", 'Option 2: 5 years’ experience in', ""2 years' experience in data engineering, database engineering, business intelligence, or business analytics"", ""Master’s degree in Computer Science, Computer Engineering, Computer Information Systems, Software Engineering, or related area and 1 year's experience in software engineering or related area""], 'Responsibilities': ['You will be responsible for contributing to an orchestration layer of complex data transformations, refining raw data from source into targeted, valuable data assets for consumption in a governed way.\u202fYou will partner with Data Scientists, Analysts, other engineers, and business stakeholders to solve complex and exciting challenges so that we can build out capabilities that evolve the retail business model while making a positive impact on our customers’ lives', 'Data Strategy: Understands, articulates, and applies principles of the defined strategy to routine business problems that involve a single function', 'Data Transformation and Integration: Extracts data from identified databases', 'Creates data pipelines and transform data to a structure that is relevant to the problem by selecting appropriate techniques', 'Develops knowledge of current analytics trends', 'Data Source Identification: Supports the understanding of the priority order of requirements and service level agreements', 'Helps identify the most suitable source for data that is fit for purpose', 'Performs initial data quality checks on extracted data', 'Data Modeling: Analyses complex data elements, systems, data flows, dependencies, and relationships to contribute to conceptual, physical, and logical data models', 'Develops the Logical Data Model and Physical Data Models including data warehouse and data mart designs', 'Defines relational tables, primary and foreign keys, and stored procedures to create a data model structure', 'Evaluates existing data models and physical databases for variances and discrepancies', 'Develops efficient data flows', 'Analyses data-related system integration challenges and proposes appropriate solutions', 'Code Development and Testing: Writes code to develop the required solution and application features by determining the appropriate programming language and leveraging business, technical and data requirements', 'Creates test cases to review and validate the proposed solution design', 'Creates proofs of concept', 'Tests the code using the appropriate testing approach', 'Deploys software to production servers', 'Contributes code documentation, maintains playbook, and provides timely progress updates', ""Problem Formulation: Translates business problems within one's discipline to data related or mathematical solutions"", 'Identifies what methods (for example, analytics, big data analytics, automation) would provide a solution for the problem', 'Shares use cases and gives examples to demonstrate how the method would solve the business problem', 'Applied Business Acumen: Provides recommendations to business stakeholders to solve complex business issues', 'Develops business cases for projects with a projected return on investment or cost savings', 'Translates business requirements into projects, activities, and tasks and aligns to overall business strategy', 'Serves as an interpreter and conduit to connect business needs with tangible solutions and results', 'Recommends new processes and ways of working', 'Data Governance: Establishes, modifies, and documents data governance projects and recommendations', 'Implements data governance practices in partnership with business stakeholders and peers', 'Interprets company and regulatory policies on data', 'Educates others on data governance processes, practices, policies, and guidelines', 'Provides recommendations on needed updates or inputs into data governance policies, practices, or guidelines', 'Demonstrates up-to-date expertise and applies this to the development, execution, and improvement of action plans by providing expert advice and guidance to others', 'Supporting and aligning efforts to meet customer and business needs and building commitment for perspectives and rationales', 'Provides and supports the implementation of business solutions by building relationships and partnerships with key stakeholders', 'Identifying business needs, determining, and carrying out necessary processes and practices', 'Promotes and supports company policies, procedures, mission, values, and standards of ethics and integrity by training and providing direction to others in their use and application, ensuring compliance with them', 'Ensures business needs are being met by evaluating the ongoing effectiveness of current plans, programs, and initiatives', 'Applying suggestions for improving efficiency and cost effectiveness; and participating in and supporting community outreach events', 'Creates training documentation and trains end-users on data modeling', 'Oversees the tasks of less experienced programmers and stipulates system troubleshooting supports', 'Drives the execution of multiple business plans and projects by identifying customer and operational needs', 'Developing and communicating business plans and priorities, removing barriers and obstacles that impact performance', 'Providing resources, identifying performance standards, measuring progress, and adjusting performance accordingly', 'Developing contingency plans and demonstrating adaptability and supporting continuous learning'], 'Benefits': ['Benefits: Beyond our great compensation package, you can receive incentive awards for your performance', 'Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more']}",,en,15113200,4,,452990,All Other General Merchandise Stores
Awvrb4W-sPUAAAAAAAAAAA==,Randstad USA,,,,Monster,FULLTIME,Data Engineer,https://www.monster.com/job-openings/data-engineer-dallas-tx--53f94751-4d3a-4f39-9305-392e3510b4b8?mstr_dist=true,True,0.5581,"job summary:

Randstad Technologies has an active need with one of our long-standing end customer, a leading Financial company located in the heart of Dallas. This will be a twelve month long contract with the intent to convert to full time. Our client is looking to add a Data Engineer to support their organization.

location: DALLAS, Texas
job type: Contract
salary: $50 - 55 per hour
work hours: 8am to 5pm
education: Associates

responsibilities:

Responsibilities

- Design, develop and implement data mining tools and analyses to sift through large amounts of data stored in a data warehouse or data mart to find relationships and patterns

- Be responsible for implementing the systems, processes and logic required to extract, transform, clean, and distribute data across one or more data stores from a wide variety of sources for systems with moderate complexity

- Work under general guidance and clear framework of accountability with substantial autonomy

- Use best practices and knowledge of internal or external business issues to improve products or services

- Solve complex problems; takes a new perspective using existing solutions

qualifications:
• Experience level: Experienced
• Minimum 4 years of experience
• Education: Associates

skills:
• data engineer
• SQL (4 years of experience is required)
• Python (4 years of experience is required)
• Big Data
• AWS
• RESTful API
• UNIX
• Linux
• Data Warehouse

Equal Opportunity Employer: Race, Color, Religion, Sex, Sexual Orientation, Gender Identity, National Origin, Age, Genetic Information, Disability, Protected Veteran Status, or any other legally protected group status.

At Randstad, we welcome people of all abilities and want to ensure that our hiring and interview process meets the needs of all applicants. If you require a reasonable accommodation to make your application or interview experience a great one, please contact HRsupport@randstadusa.com.

Pay offered to a successful candidate will be based on several factors including the candidate's education, work experience, work location, specific job duties, certifications, etc. In addition, Randstad offers a comprehensive benefits package, including health, an incentive and recognition program, and 401K contribution (all benefits are based on eligibility).

For certain assignments, Covid-19 vaccination and/or testing may be required by Randstad's client or applicable federal mandate, subject to approved medical or religious accommodations. Carefully review the job posting for details on vaccine/testing requirements or ask your Randstad representative for more information.

About the Company:
Randstad USA

Randstad was founded in 1960 by Frits Goldschmeding. We've never let go of his passion or the values that he established. By staying true to those fundamentals, we've expanded to represent more than 90 percent of the HR services market.

We provide outsourcing, staffing, consulting and workforce solutions within the areas of engineering, accounting and finance, healthcare, human resources, IT, legal, life sciences, manufacturing and logistics, office and administration and sales and marketing. We can’t wait to tell you all about it.

Our mission is to be a world leader in matching demand for, and supply of, labor and HR services. We believe in the value of work as a unifying force that shapes society for the better. We live by the core values established early in our company's history: to know, serve and trust, striving for perfection and simultaneous promotion of all interests.

Company Size:
10,000 employees or more

Industry:
Staffing/Employment Agencies

Founded:
1960

Website:
https://www.randstadusa.com/",False,1690329600,2023-07-26T00:00:00.000Z,Dallas,TX,US,32.776665,-96.79699,"['health_insurance', 'retirement_savings', 'dental_coverage']","https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=10&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=Awvrb4W-sPUAAAAAAAAAAA%3D%3D",,,"{'no_experience_required': False, 'required_experience_in_months': 48, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': False, 'degree_preferred': False, 'professional_certification_mentioned': True}",False,,,,,"{'Qualifications': ['Experience level: Experienced', 'Minimum 4 years of experience', 'Education: Associates', 'data engineer', 'SQL (4 years of experience is required)', 'Big Data', 'AWS', 'UNIX', 'Linux', 'Data Warehouse'], 'Responsibilities': ['Design, develop and implement data mining tools and analyses to sift through large amounts of data stored in a data warehouse or data mart to find relationships and patterns', 'Be responsible for implementing the systems, processes and logic required to extract, transform, clean, and distribute data across one or more data stores from a wide variety of sources for systems with moderate complexity', 'Work under general guidance and clear framework of accountability with substantial autonomy', 'Use best practices and knowledge of internal or external business issues to improve products or services', 'Solve complex problems; takes a new perspective using existing solutions'], 'Benefits': ['salary: $50 - 55 per hour', ""Pay offered to a successful candidate will be based on several factors including the candidate's education, work experience, work location, specific job duties, certifications, etc"", 'In addition, Randstad offers a comprehensive benefits package, including health, an incentive and recognition program, and 401K contribution (all benefits are based on eligibility)']}",Data engineer,en,15113200,4,,,
eAOHe-qYmRwAAAAAAAAAAA==,Costco Wholesale,https://upload.wikimedia.org/wikipedia/commons/thumb/5/59/Costco_Wholesale_logo_2010-10-26.svg/1280px-Costco_Wholesale_logo_2010-10-26.svg.png,https://www.costco.com,,Glassdoor,FULLTIME,Data Engineer - Data Science & Analytics,"https://www.glassdoor.com/job-listing/data-engineer-data-science-and-analytics-costco-wholesale-JV_IC1139977_KO0,40_KE41,57.htm?jl=1008427328488",False,0.5467,"This is an environment unlike anything in the high-tech world and the secret of Costco’s success is its culture. The value Costco puts on its employees is well documented in articles from a variety of publishers including Bloomberg and Forbes. Our employees and our members come FIRST. Costco is well known for its generosity and community service and has won many awards for its philanthropy. The company joins with its employees to take an active role in volunteering by sponsoring many opportunities to help others. In 2021, Costco contributed over $58 million to organizations such as United Way and Children's Miracle Network Hospitals.

Costco IT is responsible for the technical future of Costco Wholesale, the third largest retailer in the world with wholesale operations in fourteen countries. Despite our size and explosive international expansion, we continue to provide a family, employee centric atmosphere in which our employees thrive and succeed. As proof, Costco ranks seventh in Forbes “World’s Best Employers”.

The Data Engineer - Data Analytics is responsible for the end to end data pipelines to power analytics and data services. This role is focused on data engineering to build and deliver automated data pipelines from a plethora of internal and external data sources. The Data Engineer will partner with product owners, engineering and data platform teams to design, build, test, and automate data pipelines that are relied upon across the company as the single source of truth.

If you want to be a part of one of the worldwide BEST companies “to work for”, simply apply and let your career be reimagined.

ROLE
• Develops and operationalizes data pipelines to make data available for consumption (BI, Advanced analytics, Services).
• Works with data architects and data/BI engineers to design data pipelines and recommends ongoing optimization of data storage, data ingestion, data quality, and orchestration.
• Designs, develops, and implements ETL/ELT processes using IICS (informatica cloud).
• Uses Azure services such as Azure SQL DW (Synapse), ADLS, Azure Event Hub, Azure Data Factory to improve and speed up delivery of our data products and services.
• Implements big data and NoSQL solutions by developing scalable data processing platforms to drive high-value insights to the organization.
• Identifies, designs, and implements internal process improvements: automating manual processes, optimizing data delivery.
• Identifies ways to improve data reliability, efficiency, and quality of data management.
• Communicates technical concepts to non-technical audiences both written and verbal.
• Performs peer reviews for other data engineer’s work.

REQUIRED
• 5+ years’ experience engineering and operationalizing data pipelines with large and complex datasets.
• 5+ years’ of hands on experience with Informatica PowerCenter.
• 2+ years’ of hands on experience with Informatica IICS.
• 3+ years’ experience working with Cloud technologies; such as ADLS, Azure Databricks, Spark, Azure Synapse, Cosmos DB, and other big data technologies.
• 5+ years’ experience with Data Modeling, ETL, and Data Warehousing.
• 2+ years’ hands on experience implementing data integration techniques such as event / message based integration (Kafka, Azure Event Hub), ETL.
• 3+ years’ hands on experience with Git / Azure DevOps
• Extensive experience working with various data sources; SQL,Oracle database, flat files (csv, delimited), Web API, XML.
• Advanced SQL skills; Understanding of relational databases, business data, and the ability to write complex SQL queries against a variety of data sources.
• Strong understanding of database storage concepts; Data Lake, Relational Databases, NoSQL, Graph, Data Warehousing.
• Able to work in a fast-paced agile development environment.

Recommended
• Microsoft Azure/similar certifications.
• Experience delivering data solutions through agile software development methodologies.
• Exposure to the retail industry.
• Excellent verbal and written communication skills.
• Experience working with SAP integration tools including BODS.
• Experience with UC4 Job Scheduler.
• BA/BS in Computer Science, Engineering, or equivalent software/services experience.

Required Documents
• Cover Letter
• Resume
• Last two performance reviews
• Attendance records for current year (Do not include absences covered by paid sick/personal time, FMLA or other protected absences.)

California applicants, please click here to review the Costco Applicant Privacy Notice.

Apart from any religious or disability considerations, open availability is needed to meet the needs of the business. If hired, you will be required to provide proof of authorization to work in the United States. Applicants and employees for this position will not be sponsored for work authorization, including, but not limited to H1-B visas.

Pay Ranges:

Level 2 - $100,000 - $135,000,

Level 3 - $125,000 - $165,000

Level 4 - $155,000 - $195,000, Bonus and Restricted Stock Unit (RSU) eligible

We offer a comprehensive package of benefits including paid time off, health benefits — medical/dental/vision/hearing aid/pharmacy/behavioral health/employee assistance, health care reimbursement account, dependent care assistance plan, commuter benefits, short-term disability and long-term disability insurance, AD&D insurance, life insurance, 401(k), stock purchase plan, SmartDollar financial wellness program, to eligible employees.

Costco is committed to a diverse and inclusive workplace. Costco is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or any other legally protected status. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request to IT-Recruiting@costco.com

If hired, you will be required to provide proof of authorization to work in the United States.",False,1690156800,2023-07-24T00:00:00.000Z,Dallas,TX,US,32.776665,-96.79699,"['health_insurance', 'dental_coverage', 'paid_time_off', 'retirement_savings']","https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=20&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=eAOHe-qYmRwAAAAAAAAAAA%3D%3D",,,"{'no_experience_required': False, 'required_experience_in_months': 60, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': True, 'professional_certification_mentioned': True}",False,100000.0,135000.0,USD,YEAR,"{'Qualifications': ['5+ years’ experience engineering and operationalizing data pipelines with large and complex datasets', '5+ years’ of hands on experience with Informatica PowerCenter', '2+ years’ of hands on experience with Informatica IICS', '3+ years’ experience working with Cloud technologies; such as ADLS, Azure Databricks, Spark, Azure Synapse, Cosmos DB, and other big data technologies', '5+ years’ experience with Data Modeling, ETL, and Data Warehousing', '2+ years’ hands on experience implementing data integration techniques such as event / message based integration (Kafka, Azure Event Hub), ETL', '3+ years’ hands on experience with Git / Azure DevOps', 'Extensive experience working with various data sources; SQL,Oracle database, flat files (csv, delimited), Web API, XML', 'Advanced SQL skills; Understanding of relational databases, business data, and the ability to write complex SQL queries against a variety of data sources', 'Strong understanding of database storage concepts; Data Lake, Relational Databases, NoSQL, Graph, Data Warehousing', 'Able to work in a fast-paced agile development environment', 'Microsoft Azure/similar certifications', 'Experience delivering data solutions through agile software development methodologies', 'Exposure to the retail industry', 'Excellent verbal and written communication skills', 'Experience working with SAP integration tools including BODS', 'Experience with UC4 Job Scheduler', 'BA/BS in Computer Science, Engineering, or equivalent software/services experience', 'Last two performance reviews', 'Attendance records for current year (Do not include absences covered by paid sick/personal time, FMLA or other protected absences.)', 'If hired, you will be required to provide proof of authorization to work in the United States'], 'Responsibilities': ['This role is focused on data engineering to build and deliver automated data pipelines from a plethora of internal and external data sources', 'The Data Engineer will partner with product owners, engineering and data platform teams to design, build, test, and automate data pipelines that are relied upon across the company as the single source of truth', 'Develops and operationalizes data pipelines to make data available for consumption (BI, Advanced analytics, Services)', 'Works with data architects and data/BI engineers to design data pipelines and recommends ongoing optimization of data storage, data ingestion, data quality, and orchestration', 'Designs, develops, and implements ETL/ELT processes using IICS (informatica cloud)', 'Uses Azure services such as Azure SQL DW (Synapse), ADLS, Azure Event Hub, Azure Data Factory to improve and speed up delivery of our data products and services', 'Implements big data and NoSQL solutions by developing scalable data processing platforms to drive high-value insights to the organization', 'Identifies, designs, and implements internal process improvements: automating manual processes, optimizing data delivery', 'Identifies ways to improve data reliability, efficiency, and quality of data management', 'Communicates technical concepts to non-technical audiences both written and verbal', 'Performs peer reviews for other data engineer’s work'], 'Benefits': ['Level 2 - $100,000 - $135,000,', 'Level 3 - $125,000 - $165,000', 'Level 4 - $155,000 - $195,000, Bonus and Restricted Stock Unit (RSU) eligible', 'We offer a comprehensive package of benefits including paid time off, health benefits — medical/dental/vision/hearing aid/pharmacy/behavioral health/employee assistance, health care reimbursement account, dependent care assistance plan, commuter benefits, short-term disability and long-term disability insurance, AD&D insurance, life insurance, 401(k), stock purchase plan, SmartDollar financial wellness program, to eligible employees']}",Data engineer,en,15111100,5,,,
xlranAfS5CkAAAAAAAAAAA==,"Randstad North America, Inc.",https://mma.prnewswire.com/media/1158927/Randstad_logo.jpg?p=twitter,http://www.randstadusa.com,,Jobrapido.com,FULLTIME,Data Engineer,https://us.jobrapido.com/jobpreview/2962679032,False,0.4492,"Required Qualifications - Option 1: Bachelor's degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years' experience in software engineering or related field. Option 3: Master's degree in Computer Data Engineer, Software Engineer, Computer Science, Database Engineer, Technology, Staffing, Engineer",False,1690329600,2023-07-26T00:00:00.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=20&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=xlranAfS5CkAAAAAAAAAAA%3D%3D",,,"{'no_experience_required': False, 'required_experience_in_months': 72, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': True, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': [""Required Qualifications - Option 1: Bachelor's degree in Computer Science and 4 years' experience in software engineering or related field"", ""Option 2: 6 years' experience in software engineering or related field"", ""Option 3: Master's degree in Computer Data Engineer, Software Engineer, Computer Science, Database Engineer, Technology, Staffing, Engineer""]}",Data engineer,en,15113200,4,,,
H4fbvCM4qssAAAAAAAAAAA==,Apexon,https://mms.businesswire.com/media/20220726005920/en/1524777/23/Apexon_Logo_Colour_CMYK.jpg,http://www.apexon.com,,Salary.com,FULLTIME,AWS Data Engineer,https://www.salary.com/job/apexon/aws-data-engineer/j202307210211154619759,False,0.5713,"Job Description

Technical skills required:
• Experience with big data tools like Hadoop, Spark, Kafka, fink, Hive, Sqoop etc.
• Experience with relational SQL and NoSQL databases like Mysql, Postgres, Mongodb and Cassandra. Experience with data pipeline tools like Airflow, etc.
• Experience with AWS cloud services like: EC2, S3, EMR ETC
• Experience with stream-processing systems like: Storm, Spark-Streaming, Flink etc.
• Experience with object-oriented/object function scripting languages: Python, Java, C , Scala, etc.
• Dice Id: tecnos
• Position Id: 7970708
•",False,1689984000,2023-07-22T00:00:00.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=20&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=H4fbvCM4qssAAAAAAAAAAA%3D%3D",2024-01-21T00:00:00.000Z,1705795200.0,"{'no_experience_required': False, 'required_experience_in_months': None, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': False, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['Experience with big data tools like Hadoop, Spark, Kafka, fink, Hive, Sqoop etc', 'Experience with relational SQL and NoSQL databases like Mysql, Postgres, Mongodb and Cassandra', 'Experience with data pipeline tools like Airflow, etc', 'Experience with AWS cloud services like: EC2, S3, EMR ETC', 'Experience with stream-processing systems like: Storm, Spark-Streaming, Flink etc', 'Experience with object-oriented/object function scripting languages: Python, Java, C , Scala, etc']}",Data engineer,en,15113200,4,,,
vw-9JOTKx18AAAAAAAAAAA==,"AT&T Services, Inc.",https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcS500weGU8Dx9ZPZosQM_sMearUR_pwAnRmX7Ms&s=0,,,Professional Diversity Network,FULLTIME,Principal- Big Data Engineer,https://www.prodivnet.com/job/principal-big-data-engineer-dallas-texas-13312115,False,0.5681,"Principal- Big Data Engineer
AT&T Services, Inc.
Dallas, TX
responsible for interpreting the requirements of various Big Data analytics use cases and scenarios. Apply at
http://att.jobs/, select
JOB SEARCH and APPLY and select Search by Requisition Number at the left bottom
of the page and enter
Job Number: 2317733

recblid j66a6lkvh4wdbjyy95ehj6kmwz3dny

PDN-99b82a39-fa51-469f-ad0d-7cad136b408b",False,1690205878,2023-07-24T13:37:58.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=20&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=vw-9JOTKx18AAAAAAAAAAA%3D%3D",2023-10-22T13:37:58.000Z,1697981878.0,"{'no_experience_required': False, 'required_experience_in_months': None, 'experience_mentioned': False, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': False, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,,,,,{'Responsibilities': ['responsible for interpreting the requirements of various Big Data analytics use cases and scenarios']},Principal,en,15113200,4,,,
Xxd017dEv5YAAAAAAAAAAA==,"Galaxy i Technologies, Inc.",https://galaxyitech.com/wp-content/uploads/2023/04/galaxy-logo.gif,,,Dice,FULLTIME,DATA ENGINEER,https://www.dice.com/job-detail/3c29ce84-8ce6-41cb-9d94-f9425b9662e2,True,0.5622,"DATA ENGINEER

W2 CONTRACT

MA,UT,TX,NC,NH

HYBRID

JOB DESCRIPTION:
• 5+ years of relevant experience in data analytics or process improvement
• Bachelor's degree (e.g., Computer Science, Engineering, Finance) / Master's degree preferred
• Immediately apply Industry-leading analytics approaches and tools to transform data into insights
• Experience deploying and working with diverse data environments
• Financial Services experience preferred
• Proven ability in data analytics, data warehousing, and business intelligence
• Ability to synthesize sophisticated data from multiple, disparate sources to present analysis and relevant insights
• Sophisticated knowledge of database concepts and expertise with SQL (prefer Oracle and Snowflake)
• Data integration development experience procedure and tools (e.g. Informatica, Talend, DataStage)
• Extensive experience deploying data on public cloud (prefer AWS)
• High proficiency in dimensional reporting structures and database design.
• Acquainted with the creation and use of semantic layers
• Data prep experience using agile tools such as Alteryx, Qlik, R, or Python
• Visualization and reporting tools is a plus (e.g. Tableau, OBIEE, Cognos, Domo, Power BI, etc.)
• Analyzing data to identify areas of improvement or insights which drive actions to advance organization objectives
• Work closely with the squad leaders, engineers & the architects to form strategic partnerships and influence strategic decisions and solution development
• Bring depth of experience and influence chosen technologies and design implementation Database, Data Warehousing and Analytics.",False,1690473702,2023-07-27T16:01:42.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=20&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=Xxd017dEv5YAAAAAAAAAAA%3D%3D",2023-08-27T22:18:51.000Z,1693174731.0,"{'no_experience_required': False, 'required_experience_in_months': 60, 'experience_mentioned': True, 'experience_preferred': True}",['AWS'],"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['5+ years of relevant experience in data analytics or process improvement', 'Proven ability in data analytics, data warehousing, and business intelligence', 'Ability to synthesize sophisticated data from multiple, disparate sources to present analysis and relevant insights', 'Sophisticated knowledge of database concepts and expertise with SQL (prefer Oracle and Snowflake)', 'Data integration development experience procedure and tools (e.g', 'Informatica, Talend, DataStage)', 'Extensive experience deploying data on public cloud (prefer AWS)', 'High proficiency in dimensional reporting structures and database design', 'Acquainted with the creation and use of semantic layers', 'Data prep experience using agile tools such as Alteryx, Qlik, R, or Python', 'Tableau, OBIEE, Cognos, Domo, Power BI, etc.)'], 'Responsibilities': ['Analyzing data to identify areas of improvement or insights which drive actions to advance organization objectives', 'Work closely with the squad leaders, engineers & the architects to form strategic partnerships and influence strategic decisions and solution development', 'Bring depth of experience and influence chosen technologies and design implementation Database, Data Warehousing and Analytics']}",Data engineer,en,15113200,4,,,
AXlP4nh2A4AAAAAAAAAAAA==,H-E-B,https://www.heb.com/img/header/logo.png,http://www.heb.com,Retail,Built In,FULLTIME,"Senior Data Engineer, DevX and Platform-Dallas, Austin, or San Antonio, TX (Dallas, TX)",https://builtin.com/job/data/senior-data-engineer-devx-and-platform-dallas-austin-or-san-antonio-tx/1665565,False,0.688,"Overview
H-E-B is one of the largest, independently owned food retailers in the nation operating over 420+ stores throughout Texas and Mexico, with annual sales generating over $34 billion. Described by industry experts as a daring innovator and smart competitor, H-E-B has led the way with creative new concepts, outstanding service and a commitment to diversity in our workforce, workplace and marketplace. H-E-B offers a wealth of career opportunities to our 145,000+ Partners (employees), competitive compensation and benefits program and comprehensive training that lead to successful careers.
Responsibilities
Since H-E-B Digital Technology's inception, we've been investing heavily in our customers' digital experience, reinventing how they find inspiration from food, how they make food decisions, and how they ultimately get food into their homes. This is an exciting time to join H-E-B Digital--we're using the best available technologies to deliver modern, engaging, reliable, and scalable experiences to meet the needs of our growing audience. If you enjoy taking on new challenges, working in a rapidly changing environment, learning new skills, and applying it all to solve large and impactful business problems, we want you as part of our team.
Our Partners thrive The H-E-B Way. In the Senior Data Engineer, DevX that means you have a...
HEART FOR PEOPLE... you can organize multiple engineers, negotiate solutions, and provide upward communication
HEAD FOR BUSINESS... you consistently demonstrate and uphold the standards of coding, infrastructure, and process
PASSION FOR RESULTS... you're capable of high-velocity contributions in multiple technical domains
What you will do:
• Develop solutions to build and continuously improve monitoring and observability for data pipelines and data platform
• Build data platform components using hybrid cloud services (AWS, GCP, and Azure)
• Implement features to improve data platform performance and security continuously
• Build Real-time data streaming tools and associated experience
• Create self-service tools and experience for all enterprise data engineering teams

Project you will impact:
• Build a data platform that can handle petabytes of data and help running advanced analytics workloads
• Improve the data quality and consumer experience for 100K+ enterprise data consumer

Who you are:
• Hands-on experience in Cloud and data pipelines.
• Expert in SQL, and experienced programmer in one or more than one of the languages such as Python, Java, or Scala.
• Understanding of Big Data and Hybrid Cloud infrastructure. Experienced in more than one of the technologies such as Kafka, Kubernetes, Spark, Databricks, AWS EMR, S3, Data warehouses (Snowflake, Teradata), AWS and GCP Cloud services
• Experienced in cloud administration and infrastructure as a code (Terraform, Cloud Formation, Ansible, Chef) is a plus
• Experienced in DevOps tools such as GitLab CI/CD, and Jenkins.
• Up to date on the latest technology developments. Should be able to evaluate and propose new tooling/solutions for data platforms.
• Excellent written, oral communication and presentation skills.
• Understanding of MLOps and Data Engineering

Bonus:
• Databricks or Spark Certifications
• DevOps Certifications
• Cloud certifications (AWS Preferred)",False,1678251629,2023-03-08T05:00:29.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=20&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=AXlP4nh2A4AAAAAAAAAAAA%3D%3D",,,"{'no_experience_required': False, 'required_experience_in_months': None, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': True, 'degree_mentioned': False, 'degree_preferred': False, 'professional_certification_mentioned': True}",False,,,,,"{'Qualifications': ['Hands-on experience in Cloud and data pipelines', 'Expert in SQL, and experienced programmer in one or more than one of the languages such as Python, Java, or Scala', 'Understanding of Big Data and Hybrid Cloud infrastructure', 'Experienced in more than one of the technologies such as Kafka, Kubernetes, Spark, Databricks, AWS EMR, S3, Data warehouses (Snowflake, Teradata), AWS and GCP Cloud services', 'Experienced in DevOps tools such as GitLab CI/CD, and Jenkins', 'Up to date on the latest technology developments', 'Should be able to evaluate and propose new tooling/solutions for data platforms', 'Excellent written, oral communication and presentation skills', 'DevOps Certifications'], 'Responsibilities': ['you consistently demonstrate and uphold the standards of coding, infrastructure, and process', 'Develop solutions to build and continuously improve monitoring and observability for data pipelines and data platform', 'Build data platform components using hybrid cloud services (AWS, GCP, and Azure)', 'Implement features to improve data platform performance and security continuously', 'Build Real-time data streaming tools and associated experience', 'Create self-service tools and experience for all enterprise data engineering teams', 'Build a data platform that can handle petabytes of data and help running advanced analytics workloads', 'Improve the data quality and consumer experience for 100K+ enterprise data consumer'], 'Benefits': ['Databricks or Spark Certifications']}",Data engineer,en,15113200,4,,445110,Supermarkets and Other Grocery (except Convenience) Stores
XBgFtaGDEqoAAAAAAAAAAA==,Docyt,"https://res.cloudinary.com/crunchbase-production/image/upload/c_lpad,f_auto,q_auto:eco,dpr_1/v1464377633/hffpio7eh8djgtpcteyg.png",http://docyt.com,,Salary.com,FULLTIME,Big Data Engineer,https://www.salary.com/job/docyt/big-data-engineer/j202307221606596443368,False,0.5621,"Docyt, a fast-growing FinTech startup based in Silicon Valley, is seeking a highly motivated Big Data Engineer to join our team. The ideal candidate will be responsible for maintaining our data processing infrastructure and optimizing our data architecture, as well as contributing to the development and implementation of new data-driven solutions. At Docyt, we are passionate about empowering businesses to take control of their financial data using an AI-driven super app, and we're looking for a skilled engineer to help us continue to innovate in this exciting space.

Responsibilities
• Develop and manage data pipelines, ensuring the smooth flow of data from various sources to our data warehouse
• Monitor and optimize data processing infrastructure, ensuring fast and reliable ETL pipelines
• Contribute to the design and implementation of new data-driven solutions, using cutting-edge machine learning and artificial intelligence techniques
• Collaborate with other members of the engineering team, sharing knowledge and best practices to continuously improve our data processing capabilities
• Build and maintain data models and ensure data accuracy and consistency
• Implement and manage data security measures, including backups and access controls
• Participate in code reviews, providing constructive feedback to ensure code quality
• Bachelor's degree in Computer Science, Engineering, or related field
• At least 3 years of experience in big data engineering or related field
• Strong understanding of data processing fundamentals, including ETL pipelines, data warehousing, and data modeling
• Proficient in at least one programming language, such as Python or Java
• Experience with SQL and NoSQL databases
• Familiarity with distributed computing frameworks, such as Hadoop or Spark
• Understanding of data security and access control best practices
• Strong problem-solving skills and ability to work independently and in a team environment
• Excellent verbal and written communication skills
• Self-motivated with a strong desire to learn and stay up-to-date with new technologies in the field
• Experience with AWS and Docker is a plus.
• Great growth potential at a fast-growing startup, we want you to grow with us!
• Company-provided laptop and necessary hardware to ensure your setup for success.
• Comprehensive health, dental and vision coverage.
• Company-sponsored 401(k)
• Inclusive and motivating work culture that values team collaboration.

About Us

Docyt, pronounced “docket”, is a FinTech startup headquartered in Silicon Valley, that is passionately focused on giving businesses control of their financial data. While great strides have been made in sending and receiving payments, businesses still struggle to aggregate all their financial data, understand it, and use it to make well-informed, timely decisions. Docyt brings order to data chaos.

Docyt is a super app that applies AI (artificial intelligence) across the entire accounting tech stack. Docyt digitizes financial data, automates both income and expense workflows, continuously reconciles QuickBooks®, and generates real-time financial statements. That explains what we do, but here’s why it’s important. A complete, accurate, real-time financial picture empowers businesses to make timely and smart decisions so their business can thrive.",False,1690156800,2023-07-24T00:00:00.000Z,Dallas,TX,US,32.776665,-96.79699,"['health_insurance', 'retirement_savings', 'dental_coverage']","https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=20&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=XBgFtaGDEqoAAAAAAAAAAA%3D%3D",2024-01-22T00:00:00.000Z,1705881600.0,"{'no_experience_required': False, 'required_experience_in_months': 36, 'experience_mentioned': True, 'experience_preferred': True}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': True, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['At least 3 years of experience in big data engineering or related field', 'Strong understanding of data processing fundamentals, including ETL pipelines, data warehousing, and data modeling', 'Proficient in at least one programming language, such as Python or Java', 'Experience with SQL and NoSQL databases', 'Familiarity with distributed computing frameworks, such as Hadoop or Spark', 'Understanding of data security and access control best practices', 'Strong problem-solving skills and ability to work independently and in a team environment', 'Excellent verbal and written communication skills', 'Self-motivated with a strong desire to learn and stay up-to-date with new technologies in the field'], 'Responsibilities': ['Develop and manage data pipelines, ensuring the smooth flow of data from various sources to our data warehouse', 'Monitor and optimize data processing infrastructure, ensuring fast and reliable ETL pipelines', 'Contribute to the design and implementation of new data-driven solutions, using cutting-edge machine learning and artificial intelligence techniques', 'Collaborate with other members of the engineering team, sharing knowledge and best practices to continuously improve our data processing capabilities', 'Build and maintain data models and ensure data accuracy and consistency', 'Implement and manage data security measures, including backups and access controls', 'Participate in code reviews, providing constructive feedback to ensure code quality', ""Bachelor's degree in Computer Science, Engineering, or related field"", 'Company-provided laptop and necessary hardware to ensure your setup for success', 'Comprehensive health, dental and vision coverage', 'Inclusive and motivating work culture that values team collaboration']}",Data engineer,en,15113200,4,,,
9vfOrrNZWXwAAAAAAAAAAA==,MSRCosmos,https://mma.prnewswire.com/media/1885557/MSRcosmos_logo.jpg?p=facebook,http://www.msrcosmos.com,,Dice,FULLTIME,Senior Data Engineer - Multiple locations,https://www.dice.com/job-detail/ee40beb9-1cd0-48fb-b2ce-66f5ccfc1747,True,0.5757,"Title: Senior Data Engineer

Job Type: Contract to Hire

Location: Can work from one of client's offices within USA (they are located in almost every state)

Description:

The Data Engineer will help build and maintain the cloud Delta Lake platform leveraging Databricks. Candidates will be expected to contribute to all stages of the data lifecycle including data ingestion, data modeling, data profiling, data quality, data transformation, data movement, and data curation.

Job Responsibilities may include:
• Design, implement (deploy) and support on-premise and cloud-based data infrastructure (systems, flow) that are resilient to disruptions and failures
• Enhance and support corporate SQL/NoSQL database, DWH assets and streaming data solutions
• Ensure high uptime for all data services and consider enhanced solutions through scheduled or event-driven design
• Bring multi cloud/cross-platform agnostic technologies and practices into the system to enhance reliability and support rapid scaling of the business's data needs
• Scale up our data infrastructure to meet cross-functional, multi industry business needs
• Develop, leverage and maintain end-to-end data pipelines in production
• Provide subject matter expertise and hands on delivery of data acquisition, curation and consumption pipelines on Azure, Databricks, AWS, Confluent
• Responsible for maintaining current and emerging state of the art compute and cloud based solutions and technologies.
• Build effective relationships with internal stakeholders
• Familiarity with the technology stack available in the industry for metadata management: Data Governance, Data Quality, MDM, Lineage, Data Catalog etc.
• Hands-on experience implementing analytics solutions leveraging Python, Spark SQL, Databricks Lakehouse Architecture, orchestration tools Kubernetes, Docker
• All other duties as assigned

Requirements:
• Bachelor's degree in Computer Science, Information Technology, Management Information Systems (MIS), Data Science or related field. Applicable years of experience may be substituted for degree requirement.
• Minimum 8 years of experience in software engineering
• Experience with leading large and complex data projects, preferred
• Experience with large-scale data warehousing architecture and data modeling, preferred
• Worked with Cloud-based architecture such as Azure, AWS or Google Cloud, preferred
• Experience working with big data technologies e.g. Snowflake, Redshift, Synapse, Postgres, Airflow, Kafka, Spark, DBT, preferred
• Experience implementing pub/sub and streaming use cases, preferred
• Experience leading design reviews, preferred
• Experience influencing a team's technical and business strategy by making insightful contributions to team priorities and approaches, preferred
• Working knowledge of relational databases, preferred
• Expert in SQL, Python, Java and high-level languages such as Scala, C#, or C preferred
• Demonstrate the ability to analyze large data sets to identify gaps and inconsistencies in ETL pipeline and provide solutions for pipeline reliability and data quality, preferred
• Experience in designing and implementing an infrastructure as code / CICD development environment, preferred
• Proven ability to build, manage and foster a team-oriented environment
• Excellent communication (written and oral) and interpersonal skills
• Excellent organizational, multi-tasking, and time-management skills",False,1690403463,2023-07-26T20:31:03.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=20&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=9vfOrrNZWXwAAAAAAAAAAA%3D%3D",2023-08-26T21:46:01.000Z,1693086361.0,"{'no_experience_required': False, 'required_experience_in_months': 96, 'experience_mentioned': True, 'experience_preferred': True}","['Python', 'Azure', 'Data lake', 'data engineer']","{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': True, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': [""Bachelor's degree in Computer Science, Information Technology, Management Information Systems (MIS), Data Science or related field"", 'Applicable years of experience may be substituted for degree requirement', 'Minimum 8 years of experience in software engineering', 'Proven ability to build, manage and foster a team-oriented environment', 'Excellent communication (written and oral) and interpersonal skills', 'Excellent organizational, multi-tasking, and time-management skills'], 'Responsibilities': ['The Data Engineer will help build and maintain the cloud Delta Lake platform leveraging Databricks', 'Candidates will be expected to contribute to all stages of the data lifecycle including data ingestion, data modeling, data profiling, data quality, data transformation, data movement, and data curation', 'Design, implement (deploy) and support on-premise and cloud-based data infrastructure (systems, flow) that are resilient to disruptions and failures', 'Enhance and support corporate SQL/NoSQL database, DWH assets and streaming data solutions', 'Ensure high uptime for all data services and consider enhanced solutions through scheduled or event-driven design', ""Bring multi cloud/cross-platform agnostic technologies and practices into the system to enhance reliability and support rapid scaling of the business's data needs"", 'Scale up our data infrastructure to meet cross-functional, multi industry business needs', 'Develop, leverage and maintain end-to-end data pipelines in production', 'Provide subject matter expertise and hands on delivery of data acquisition, curation and consumption pipelines on Azure, Databricks, AWS, Confluent', 'Responsible for maintaining current and emerging state of the art compute and cloud based solutions and technologies', 'Build effective relationships with internal stakeholders', 'Familiarity with the technology stack available in the industry for metadata management: Data Governance, Data Quality, MDM, Lineage, Data Catalog etc', 'All other duties as assigned']}",Data engineer,en,15113200,4,,,
tHzZ5aQ6XEYAAAAAAAAAAA==,Saxon Global,https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSlFP-6TjZGEvHFMa5VEr-0uRMHpyoOdoANCQHs&s=0,,,Lensa,FULLTIME,Mid- Data Engineer,https://lensa.com/mid-data-engineer-jobs/dallas/jd/b6d4b47da82eebd9829510cce511dcca,False,0.462,"Understanding Business Context Requires knowledge of:

Industry and environmental factors; Common business vernacular; Business practices across two or more domains such as product, finance, marketing, sales, technology, business systems, and human resources and in-depth knowledge of related practices; Directly relevant business metrics and business areas. To support the development of business cases and recommendations. Drives delivery of project activity and tasks assigned by others. Supports process updates and changes. Support, under guidance, in solving business issues.

Data Governance Requires knowledge of:

Data value chains; Data processes and practices; Regulatory and ethical requirements around data; Data modeling, storage, integration, and warehousing; Data value chains (identification, ingestion, processing, storage, analysis, and utilization); Data quality framework and metrics; Regulatory and ethical requirements around data privacy, security, storage, retention, and documentation; Business implications on data usage; Data Strategy; Enterprise regulatory and ethical policies and strategies. To support the documentation of data governance processes. Supports the implementation of data governance practices.

Data Strategy Requires knowledge of: Understanding of business value and relevance of data and data enabled insights / decisions; Appropriate application and understanding of data ecosystem including Data Management, Data Quality Standards and Data Governance, Accessibility, Storage and Scalability etc; Understanding of the methods and applications that unlock the monetary value of data assets. To understand, articulate, and apply principles of the defined strategy to routine business problems that involve a single function. Data Source Identification Requires knowledge of: Functional business domain and scenarios; Categories of data and where it is held; Business data requirements; Database technologies and distributed datastores (e.g. SQL, NoSQL); Data Quality; Existing business systems and processes, including the key drivers and measures of success. To support the understanding of the priority order of requirements and service level agreements. Helps identify the most suitable source for data that is fit for purpose. Performs initial data quality checks on extracted data. Data Transformation and Integration Requires knowledge of: Internal and external data sources including how they are collected, where and how they are stored, and interrelationships, both within and external to the organization; Techniques like ETL batch processing, streaming ingestion, scrapers, API and crawlers; Data warehousing service for structured and semi-structured data, or to MPP databases such as Snowflake, Microsoft Azure, Presto or Google BigQuery; Pre-processing techniques such as transformation, integration, normalization, feature extraction, to identify and apply appropriate methods; Techniques such as decision trees, advanced regression techniques such as LASSO methods, random forests etc; Cloud and big data environments like EDO2 systems. To extract data from identified databases. Creates data pipelines and transform data to a structure that is relevant to the problem by selecting appropriate techniques. Develops knowledge of current data science and analytics trends. Data Modeling Requires knowledge of: Cloud data strategy, data warehouse, data lake, and enterprise big data platforms; Data modeling techniques and tools (For example, Dimensional design and scalability), Entity Relationship diagrams, Erwin, etc. ; Query languages SQL / NoSQL; Data flows through the different systems; Tools supporting automated data loads; Artificial Intelligent - enabled metadata management tools and techniques. To analyze complex data elements, systems, data flows, dependencies, and relationships to contribute to conceptual, physical, and logical data models. Develops the Logical Data Model and Physical Data Models including data warehouse and data mart designs. Defines relational tables, primary and foreign keys, and stored procedures to create a data model structure. Evaluates existing data models and physical databases for variances and discrepancies. Develops efficient data flows.

Analyzes data Job Profile: (USA) Data Engineer III 09:57 AM 06/29/2022 Page 1 of 3 related system integration challenges and proposes appropriate solutions. Creates training documentation and trains end-users on data modeling. Oversees the tasks of less experienced programmers and stipulates system troubleshooting supports. Code Development and Testing Requires knowledge of: Coding languages like SQL, Java, C++, Python and others; Testing methods such as static, dynamic, software composition analysis, manual penetration testing and others; Business, domain understanding. To write code to develop the required solution and application features by determining the appropriate programming language and leveraging business, technical, and data requirements. Creates test cases to review and validate the proposed solution design. Creates proofs of concept. Tests the code using the appropriate testing approach. Deploys software to production servers. Contributes code documentation, maintains playbooks, and provides timely progress updates. Demonstrates up-to-date expertise and applies this to the development, execution, an

Required Skills : .jpg, sql, GCP, Python
Basic Qualification :
Additional Skills :
Background Check :Yes
Drug Screen :Yes
Notes :remote
Selling points for candidate :
Project Verification Info :
Candidate must be your W2 Employee :No
Exclusive to Apex :No
Face to face interview required :No
Candidate must be local :No
Candidate must be authorized to work without sponsorship ::No
Interview times set : :No
Type of project :Development/Engineering
Master Job Title :Big Data: Other
Branch Code :Dallas",False,1690215552,2023-07-24T16:19:12.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=20&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=tHzZ5aQ6XEYAAAAAAAAAAA%3D%3D",2023-08-23T16:19:12.000Z,1692807552.0,"{'no_experience_required': False, 'required_experience_in_months': None, 'experience_mentioned': True, 'experience_preferred': False}","['Reading Comprehension', 'Active Listening', 'Writing', 'Speaking', 'Critical Thinking', 'Active Learning', 'Monitoring', 'Social Perceptiveness', 'Coordination', 'Complex Problem Solving', 'Programming', 'Judgment and Decision Making', 'Systems Analysis', 'Systems Evaluation']","{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': False, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,,,,,{},,en,15113200,4,['15-1199.06 Database Architects'],,
nKAVtQsHlHgAAAAAAAAAAA==,Infojini,https://lookaside.fbsbx.com/lookaside/crawler/media/?media_id=100064129355795,http://www.infojiniconsulting.com,,Jobrapido.com,FULLTIME,Jr. Data Engineer with AWS,https://us.jobrapido.com/jobpreview/2962504484,False,0.4464,"We are looking for a Jr. Data Engineer for SWA. Please see below:
Project length: 12 Months CTH
Looking for Junior level resource
scripting (python or powershell), general knowledge of AWS
will be touching multiple technologies - someone that is ok to pick up and learn
Need to have a great attitude - they can coach, teach mentor in areas that they may be lacking. Need engineer that is hungry to learn.",False,1690329600,2023-07-26T00:00:00.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=30&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=nKAVtQsHlHgAAAAAAAAAAA%3D%3D",,,"{'no_experience_required': False, 'required_experience_in_months': None, 'experience_mentioned': False, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': False, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['Looking for Junior level resource', 'scripting (python or powershell), general knowledge of AWS', 'will be touching multiple technologies - someone that is ok to pick up and learn', 'Need to have a great attitude - they can coach, teach mentor in areas that they may be lacking']}",Data engineer,en,15113200,4,,,
Fw73q18LK2YAAAAAAAAAAA==,Southwest Airlines,https://1000logos.net/wp-content/uploads/2019/08/southwest-airlines-logo.png,http://www.southwest.com,Logistics,Southwest Careers - Southwest Airlines,FULLTIME,Sr Data Engineer,https://careers.southwestair.com/job/R-2023-32207/Sr-Data-Engineer,False,0.8069,"Department:
Technology

Our Company Promise

We are committed to provide our Employees a stable work environment with equal opportunity for learning and personal growth. Creativity and innovation are encouraged for improving the effectiveness of Southwest Airlines. Above all, Employees will be provided the same concern, respect, and caring attitude within the organization that they are expected to share externally with every Southwest Customer.

Job Description:

Job Summary
• Work on complex problems, where analysis of situations or data requires an in-depth evaluation of multiple factors. Lead and/or provide expertise to functional project teams and participate in cross-functional initiatives. Provide direction and guidance to process improvements, including helping to establish/advise on policies. Work with a number of external vendors, helping to provide them with effective solutions and insights. Use independent judgment within broadly defined policies and practices, including determining the best method for accomplishing work.

Additional details:
• Please know this posting is for multiple open Sr Data Engineer positions across various Teams in Technology. These Teams all contribute to important initiatives and are helping to shape the future of Technology at Southwest Airlines. Our Recruiting Team will provide additional Team and technology-specific details in the interview stage. Please reach out to TechnologyRecruitingInformation@wnco.com with any questions.
• This role is offered as a remote workplace position, which may require travel for trainings, meetings, conferences, etc. Outside of those required visits, the majority of your working time may be spent in a remote location, away from our Corporate Campus. Please note, while this is a remote position, there is limited group of states or localities ineligible for Employees to regularly perform their work off-site. Those ineligible locations are: Alaska, Delaware, New Jersey, North Dakota, South Dakota, Vermont, West Virginia, and Wyoming.  
• U.S. citizenship or current authorization to work in the U.S. is required, and no current or future work authorization sponsorship available.

Southwest Airlines is an Equal Opportunity Employer. We continue to look for opportunities to reflect the communities we serve, and welcome applicants with diverse thoughts, backgrounds, and experiences.
• Responsibilities
• Assemble large, complex sets of data that meet non-functional and functional business requirements
• Identify, design and implement internal process improvements including re-designing infrastructure for greater scalability, optimizing data delivery, and automating manual processes
• Build required infrastructure for optimal extraction, transformation and loading of data from various data sources using AWS and SQL technologies
• Build analytical tools to utilize the data pipeline, providing actionable insight into key business performance metrics including operational efficiency and customer acquisition
• Work with stakeholders including data, design, product and executive teams and assisting them with data-related technical issues
• Work with stakeholders including the Executive, Product, Data and Design teams to support their data infrastructure needs while assisting with data-related technical issues
• Generate or adapt equipment and technology to serve user needs
• May perform other job duties as directed by Employee's Leaders
• Knowledge, Skills and Abilities
• Knowledge of the practical application of engineering science and technology, including applying principles, techniques, procedures, and equipment to the design and production of various goods and services
• Knowledge of design techniques, tools, and principles involved in production of precision technical plans, blueprints, drawings, and models
• Ability to use logic and reasoning to identify the strengths and weaknesses of alternative solutions, conclusions or approaches to problems
• Ability to understand the implications of new information for both current and future problem-solving and decision-making
• Skilled in identifying complex problems and reviewing related information to develop and evaluate options and implement solutions
• Ability to tell when something is wrong or is likely to go wrong. It does not involve solving the problem, only recognizing there is a problem
• Ability to combine pieces of information to form general rules or conclusions (includes finding a relationship among seemingly unrelated events)
• Ability to shift back and forth between two or more activities or sources of information (such as speech, sounds, touch, or other sources)
• Ability to arrange things or actions in a certain order or pattern according to a specific rule or set of rules (e.g., patterns of numbers, letters, words, pictures, mathematical operations)
• Ability to identify or detect a known pattern (a figure, object, word, or sound) that is hidden in other distracting material
• Education
• Required: High School Diploma or GED
• Required: Bachelor's Degree in Business, Engineering, Computer Science, Information Systems, Cybersecurity, or related field; or equivalent formal training
• Experience
• Required: Advanced level experience, seasoned and specialized knowledge in:
• Cloud infrastructure, DataLake
• ETL experience ensuring source to target data integrity
• Various filetypes (Delimited Text, Fixed Width, XML, JSON, Parque)
• ServiceBus, setting up ingress and egress within a subscription, or relevant AWS Cloud services administrative experience
• Unit Testing, Code Quality tools, CI/CD Technologies, Security and Container Technologies
• Agile development experience and Agile ceremonies and practices
• Licensing/Certification
• N/A
• Physical Abilities
• Ability to perform work duties from [limited space work station/desk/office area] for extended periods of time
• Ability to communicate and interact with others in the English language to meet the demands of the job
• Ability to use a computer and other office productivity tools with sufficient speed and accuracy to meet the demands of the job
• Other Qualifications
• Must maintain a well-groomed appearance per Company appearance standards as described in established guidelines
• Must be a U.S. citizen or have authorization to work in the United States as defined by the Immigration Reform Act of 1986
• Must be at least 18 years of age
• Must be able to comply with Company attendance standards as described in established guidelines
• Pay & Benefits
• Competitive market salary from $137,250 per year to $152,500 per year* depending on qualifications and experience. For eligible Leadership and individual contributor roles, additional bonus opportunities are available and awarded at the discretion of the company.
• Benefits you'll love:
• Fly for free, as a privilege, on any open seat on all Southwest flights—your eligible dependents too.
• Up to a 9.3% 401(k) Company match, dollar for dollar, per paycheck.*
• Potential for annual ProfitSharing contribution toward retirement - when Southwest profits, you profit.**
• Explore more Benefits you’ll love: swa.is/benefits
• Pay amount doesn’t guarantee employment for any particular period of time
• *401(k) match contributions are subject to the plan’s vesting schedule and applicable IRS limits
• **ProfitSharing contributions are subject to plan’s vesting schedule and are made at the discretion of the Company

Southwest Airlines is an Equal Opportunity Employer.
Please print/save this job description because it won't be available after you apply.",False,1690502400,2023-07-28T00:00:00.000Z,Dallas,TX,US,32.776665,-96.79699,['retirement_savings'],"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=30&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=Fw73q18LK2YAAAAAAAAAAA%3D%3D",,,"{'no_experience_required': False, 'required_experience_in_months': None, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': True, 'professional_certification_mentioned': True}",False,,,,,"{'Qualifications': ['U.S. citizenship or current authorization to work in the U.S. is required, and no current or future work authorization sponsorship available', 'Knowledge of the practical application of engineering science and technology, including applying principles, techniques, procedures, and equipment to the design and production of various goods and services', 'Knowledge of design techniques, tools, and principles involved in production of precision technical plans, blueprints, drawings, and models', 'Ability to use logic and reasoning to identify the strengths and weaknesses of alternative solutions, conclusions or approaches to problems', 'Ability to understand the implications of new information for both current and future problem-solving and decision-making', 'Skilled in identifying complex problems and reviewing related information to develop and evaluate options and implement solutions', 'Ability to tell when something is wrong or is likely to go wrong', 'It does not involve solving the problem, only recognizing there is a problem', 'Ability to identify or detect a known pattern (a figure, object, word, or sound) that is hidden in other distracting material', 'Required: High School Diploma or GED', ""Required: Bachelor's Degree in Business, Engineering, Computer Science, Information Systems, Cybersecurity, or related field; or equivalent formal training"", 'Required: Advanced level experience, seasoned and specialized knowledge in:', 'Must maintain a well-groomed appearance per Company appearance standards as described in established guidelines', 'Must be a U.S. citizen or have authorization to work in the United States as defined by the Immigration Reform Act of 1986', 'Must be at least 18 years of age', 'Must be able to comply with Company attendance standards as described in established guidelines'], 'Responsibilities': ['Work on complex problems, where analysis of situations or data requires an in-depth evaluation of multiple factors', 'Lead and/or provide expertise to functional project teams and participate in cross-functional initiatives', 'Provide direction and guidance to process improvements, including helping to establish/advise on policies', 'Work with a number of external vendors, helping to provide them with effective solutions and insights', 'Use independent judgment within broadly defined policies and practices, including determining the best method for accomplishing work', 'This role is offered as a remote workplace position, which may require travel for trainings, meetings, conferences, etc', 'Assemble large, complex sets of data that meet non-functional and functional business requirements', 'Identify, design and implement internal process improvements including re-designing infrastructure for greater scalability, optimizing data delivery, and automating manual processes', 'Build required infrastructure for optimal extraction, transformation and loading of data from various data sources using AWS and SQL technologies', 'Build analytical tools to utilize the data pipeline, providing actionable insight into key business performance metrics including operational efficiency and customer acquisition', 'Work with stakeholders including the Executive, Product, Data and Design teams to support their data infrastructure needs while assisting with data-related technical issues', 'Generate or adapt equipment and technology to serve user needs', ""May perform other job duties as directed by Employee's Leaders"", 'Ability to combine pieces of information to form general rules or conclusions (includes finding a relationship among seemingly unrelated events)', 'ETL experience ensuring source to target data integrity', 'Various filetypes (Delimited Text, Fixed Width, XML, JSON, Parque)'], 'Benefits': ['Competitive market salary from $137,250 per year to $152,500 per year* depending on qualifications and experience', 'For eligible Leadership and individual contributor roles, additional bonus opportunities are available and awarded at the discretion of the company', 'Fly for free, as a privilege, on any open seat on all Southwest flights—your eligible dependents too', 'Up to a 9.3% 401(k) Company match, dollar for dollar, per paycheck.*', 'Potential for annual ProfitSharing contribution toward retirement - when Southwest profits, you profit', 'Explore more Benefits you’ll love: swa.is/benefits', 'Pay amount doesn’t guarantee employment for any particular period of time', '*401(k) match contributions are subject to the plan’s vesting schedule and applicable IRS limits', '**ProfitSharing contributions are subject to plan’s vesting schedule and are made at the discretion of the Company']}",Data engineer,en,15113200,4,['Technology'],481111,Scheduled Passenger Air Transportation
t0zy0CTqYuoAAAAAAAAAAA==,MSIT,https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTPd-hps7yHu6ZmQPwa8QzKacpqKLbzwCNNoBVY&s=0,,,OPTnation,FULLTIME,Data Engineer,https://www.optnation.com/data-engineer-job-in-dallas-tx-view-jobid-33660,False,0.6987,"Responsiblties Port existing data pipelines and make data available to an internal data fabric. Build new data acquisition and transformation pipelines using big data and cloud technologies. Work with the broader technology team including information technology information systems and 3rd parties to align pipelines. Contribute to proof-of-concept efforts in Advanced Data Analytics. Perform data analysis required to troubleshoot data-related issues and assist in the resolution of data issues. Participate in establishing system documentation standards and QA methodologies.

Key Skillls Strong programming skills. Particularly in languages. Python Java Scala and SQL.",False,1685923200,2023-06-05T00:00:00.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=30&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=t0zy0CTqYuoAAAAAAAAAAA%3D%3D",,,"{'no_experience_required': False, 'required_experience_in_months': None, 'experience_mentioned': False, 'experience_preferred': False}","['Python', 'Java', 'SQL.']","{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': False, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,106200.0,107600.0,USD,YEAR,"{'Qualifications': ['Key Skillls Strong programming skills', 'Particularly in languages', 'Python Java Scala and SQL'], 'Responsibilities': ['Build new data acquisition and transformation pipelines using big data and cloud technologies', 'Work with the broader technology team including information technology information systems and 3rd parties to align pipelines', 'Contribute to proof-of-concept efforts in Advanced Data Analytics', 'Perform data analysis required to troubleshoot data-related issues and assist in the resolution of data issues', 'Participate in establishing system documentation standards and QA methodologies']}",Data engineer,en,15113200,4,,,
UQvc_eGI98wAAAAAAAAAAA==,InfoVision Inc.,https://infovision.com/wp-content/uploads/2018/08/infovision_logo_public.png,http://www.infovision.com,Computer Services,LinkedIn,CONTRACTOR,Big Data Engineer,https://www.linkedin.com/jobs/view/big-data-engineer-at-infovision-inc-3672479393,False,0.5886,"Title: Big Data Engineer

Location: Dallas, TX

Duration: Contract

Job Description:

Main Skills:
• Hadoop
• Apache Spark
• Spark Streaming
• Apache Kafka
• AWS Amazon Web Services

Thanks & Regards,

Khaja Shareef",False,1690214955,2023-07-24T16:09:15.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=30&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=UQvc_eGI98wAAAAAAAAAAA%3D%3D",2023-08-23T16:09:14.000Z,1692806954.0,"{'no_experience_required': False, 'required_experience_in_months': None, 'experience_mentioned': False, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': True, 'degree_mentioned': False, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['Hadoop', 'Apache Spark']}",Data engineer,en,15113200,4,,541511,Custom Computer Programming Services
Zw8-q8mSkhsAAAAAAAAAAA==,UNAVAILABLE,,,,"H-E-B, L.P. - ICIMS",FULLTIME,"Staff Data Engineer, Health & Wellness - Dallas, TX",https://careers-heb.icims.com/jobs/10643/staff-data-engineer%2C-health-%26-wellness---dallas%2C-tx/job,True,0.6721,"Overview

H-E-B is one of the largest, independently owned food retailers in the nation operating over 420+ stores throughout Texas and Mexico, with annual sales generating over $34 billion. Described by industry experts as a daring innovator and smart competitor,
H-E-B has led the way with creative new concepts, outstanding service and a commitment to diversity in our workforce, workplace and marketplace.
H-E-B offers a wealth of career opportunities to our 145,000+ Partners (employees), competitive compensation and benefits program and comprehensive training that lead to successful careers.

Responsibilities

About H-E-BH-E-B is one of the largest, independently owned food retailers in the nation operating over 400 stores throughout Texas and Mexico, with annual sales generating over $34 billion. Described by industry experts as a daring innovator and smart competitor, H-E-B has led the way with creative new concepts, outstanding service and a commitment to diversity in our workforce, workplace and marketplace. H-E-B offers a wealth of career opportunities to our 145,000+ Partners (employees), competitive compensation and benefits program and comprehensive training that lead to successful careers.

H-E-B Digital is seeking new team members (Partners)! Since our inception, we’ve been investing heavily in our customers’ digital experience, reinventing how they find inspiration from food, how they make food decisions, and how they ultimately get food into their homes. This is an exciting time to join H-E-B Digital, and we’re hiring across the stack: front-end web and mobile, full-stack, and backend engineering. We’re using the best available technologies to deliver modern, engaging, reliable, and scalable experiences to meet the needs of our growing audience. Our digital solutions are growing in popularity and adoption—like Curbside and Home Delivery—so you’ll get the opportunity to define the user experience for millions of customers and hundreds of thousands of Partners. If you’re someone who enjoys taking on new challenges, working in a rapidly changing environment, learning new skills, and applying it all to solve large and impactful business problems, we want you as part of our team.Our Partners thrive The H-E-B Way. In the Staff Data Engineer position, that means you have a…

HEART FOR PEOPLE… you can organize multiple engineers, negotiate solutions, and provide upward communication

HEAD FOR BUSINESS… you consistently demonstrate and uphold the standards of coding, infrastructure, and process

PASSION FOR RESULTS… you’re capable of high-velocity contributions in multiple technical domainsWhat you’ll do
• Work with HEB Digital teams to provide data solutions for health and wellness
• Contribute to existing data platforms and implement new technologies
• Develop a deep understanding of HEB’s data and become a domain expert
• Ensure data is distributed in a timely and accurate manner
• Make data discoverable and accessible to business users
• Coach and mentor junior engineers in engineering techniques, processes, and new technologies; enable others to succeed
• Contribute to overall system design, architecture, security, scalability, reliability, and performance of applications
• Identify, scope, and architect solutions for new features while applying sound technical judgment that considers technology alternatives, impact on affected / adjacent systems, and tradeoffs.
• Get the opportunity to stay ahead of new technologies with an eye to evaluating and potentially incorporating them into your team’s architecture

Projects you’ll impact
• Implement data pipelines on AWS using Argo, Kubernetes, Spark and Python
• Integrate health, pharmacy and nutritional data systems
• Evaluate new technologies to improve quality, performance and cost of data pipelines

Who You Are
• 7+ years of data engineering experience
• Proficient with data technologies (e.g. Spark, Kinesis, Kafka, Airflow, Oracle, PostgreSQL, Redshift, Presto, etc.)
• Experienced with designing and developing ETL data pipelines using tools such as Airflow, Nifi, or Kafka.
• Strong understanding of SQL and data modeling
• Understanding of Linux, Amazon Web Services (or other cloud platforms), Python, Docker, and Kubernetes
• Experienced with common software engineering tools (e.g., Git, JIRA, Confluence, or similar)
• Bachelor's degree in computer science or comparable field or equivalent experience
• A proven understanding and application of computer science fundamentals: data structures, algorithms, design patterns, and data modeling

What are the Perks?

A robust Benefits plan with coverage starting Day OneDental, vision, life, and other insurance plans; flexible spending accounts; short term / long term disability coveragePartner Care Team, for any time you have healthcare or coverage questionsTelehealth offers 24/7 access to board-certified doctors by phonePartner Guidance allows free counselor visitsFuneral leave, jury duty, and military pay (subject to applicable law)Maternal / paternal leave for new parents, including adoptions10% off H-E-B brand products in-store and onlineEligibility to participate in 401(k)Opportunity to become a “Partner-Owner” after 12 months

Who We AreH-E-B is one of the largest, independently owned food retailers in the nation, operating over 400 stores throughout Texas and Mexico, with annual sales generating over $25 billionWe hire talented people (109,000+ Partners), and give them autonomy to be creative in how they impact the businessWe’re a Partner-driven company with a Bold Promise – Because People MatterWe embrace Diversity and Inclusion as core values, and support them with thriving company-wide programsWe’re a truly original Texas-based company that created the Spirit of Giving to help Texas communities every dayOnce eligible, our Partners become Owners in the company. “Partner-owned” means our most important resources—People—drive the innovation, growth, and success that make H-E-B The Greatest Retailing Company

Hiring in Dallas!

DATA3232",False,1627261705,2021-07-26T01:08:25.000Z,Dallas,TX,US,32.776665,-96.79699,"['health_insurance', 'dental_coverage', 'retirement_savings']","https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=30&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=Zw8-q8mSkhsAAAAAAAAAAA%3D%3D",2024-07-26T01:08:25.000Z,1721956105.0,"{'no_experience_required': False, 'required_experience_in_months': 84, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': True, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['7+ years of data engineering experience', 'Proficient with data technologies (e.g', 'Spark, Kinesis, Kafka, Airflow, Oracle, PostgreSQL, Redshift, Presto, etc.)', 'Experienced with designing and developing ETL data pipelines using tools such as Airflow, Nifi, or Kafka', 'Strong understanding of SQL and data modeling', 'Understanding of Linux, Amazon Web Services (or other cloud platforms), Python, Docker, and Kubernetes', 'Experienced with common software engineering tools (e.g., Git, JIRA, Confluence, or similar)', ""Bachelor's degree in computer science or comparable field or equivalent experience"", 'A proven understanding and application of computer science fundamentals: data structures, algorithms, design patterns, and data modeling'], 'Responsibilities': ['HEART FOR PEOPLE… you can organize multiple engineers, negotiate solutions, and provide upward communication', 'HEAD FOR BUSINESS… you consistently demonstrate and uphold the standards of coding, infrastructure, and process', 'Work with HEB Digital teams to provide data solutions for health and wellness', 'Contribute to existing data platforms and implement new technologies', 'Develop a deep understanding of HEB’s data and become a domain expert', 'Ensure data is distributed in a timely and accurate manner', 'Make data discoverable and accessible to business users', 'Coach and mentor junior engineers in engineering techniques, processes, and new technologies; enable others to succeed', 'Contribute to overall system design, architecture, security, scalability, reliability, and performance of applications', 'Identify, scope, and architect solutions for new features while applying sound technical judgment that considers technology alternatives, impact on affected / adjacent systems, and tradeoffs', 'Get the opportunity to stay ahead of new technologies with an eye to evaluating and potentially incorporating them into your team’s architecture', 'Implement data pipelines on AWS using Argo, Kubernetes, Spark and Python', 'Integrate health, pharmacy and nutritional data systems', 'Evaluate new technologies to improve quality, performance and cost of data pipelines'], 'Benefits': ['A robust Benefits plan with coverage starting Day OneDental, vision, life, and other insurance plans; flexible spending accounts; short term / long term disability coverage', 'Partner Care Team, for any time you have healthcare or coverage questionsTelehealth offers 24/7 access to board-certified doctors by phone', 'Partner Guidance allows free counselor visits', 'Funeral leave, jury duty, and military pay (subject to applicable law)Maternal / paternal leave for new parents, including adoptions10% off H-E-B brand products in-store and online']}",Data engineer,en,15113200,4,['Digital'],,
zpHp8hO8r5gAAAAAAAAAAA==,Hinge,https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQLPWFWVwd5KOcMLGD-nVhSrioNWrTds9AlMEfr&s=0,,,The Muse,FULLTIME,Sr. Data Engineer,https://www.themuse.com/jobs/hinge/sr-data-engineer,False,0.5766,"As a Senior Data Engineer, you will be implementing critical ETL pipelines and advancing best practices for the data engineering team, and the rest of the organization. You will work on delivering an actual big data architecture while concentrating on real-world problems such as privacy concerns.

This role is key to the success of Match Group. Not only will you help power the love lives of millions of people, but you will play a critical part in the functioning of every brand at Match Group (Match, Tinder, Hinge, Okcupid, PlentyofFish, BLK, and others), with stakeholders ranging from customer experience to marketing to leadership.

We’re based in Dallas, TX. However, we are open to considering a remote office for a qualified candidate who can travel periodically to Dallas (when safe to do so).

How you’ll make an impact:
• Work with our Engineering teams to ensure data is flowing accurately through data creation to our presentation layers
• Become an advocate for the Data Engineering team by developing and championing Data Engineering practices with the team and with the company at large
• Improve our Data Engineering stack through containerization, data modeling, developing our ETL pipelines, and building scalable/reliable solutions
• Work with stakeholders and translate their needs and expectations into action items and deliverables
• Lead infrastructure initiatives, from design to implementation to delivery
• Support existing on-prem infrastructure and help expand our processes into the cloud (AWS)

We could be a match if you bring:
• Expertise in SQL, Data Modeling, and Python
• Used Redshift, Airflow, Spectrum and relational database like SQL Server
• Capability to drive initiatives and articulate their value to Engineering and other stakeholders
• Experience delivering data products from conception to delivery
• Good communication skills (written/verbal)
• Passionate about designing elegant ETL pipelines
• 5+ years of professional/industry experience

Our team culture:
• Authenticity: Share your genuine thoughts and opinions directly
• Courage: Invite and deeply consider challenges and criticism
• Empathy: Be empathetic, communitarian and trustworthy

What's the team like?
• Our BI team is a service organization that delivers reporting solutions to the entire Match Group enterprise
• The BI team is responsible for architecting and engineering new data systems and reporting to help facilitate business decision-making

#LI-CENTRAL
#LI-REMOTE

Why Match Group?

Our mission is simple – to help people find love and happiness!
We love our employees too – here are some examples how:

Annual training budget for each employee
100% employer match on 401k contributions
Specific COVID-19 allowance for home office set-up
Matched giving to qualified organizations
100% paid Parental Leave
Happy Hours and Company events (they are all virtual now, but still a ton of fun!)

We value diversity at our company and will never discriminate based on someone’s race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",False,1619044350,2021-04-21T22:32:30.000Z,Dallas,TX,US,32.776665,-96.79699,['retirement_savings'],"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=30&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=zpHp8hO8r5gAAAAAAAAAAA%3D%3D",,,"{'no_experience_required': False, 'required_experience_in_months': 60, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': False, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['Expertise in SQL, Data Modeling, and Python', 'Used Redshift, Airflow, Spectrum and relational database like SQL Server', 'Capability to drive initiatives and articulate their value to Engineering and other stakeholders', 'Experience delivering data products from conception to delivery', 'Good communication skills (written/verbal)', 'Passionate about designing elegant ETL pipelines', '5+ years of professional/industry experience', 'Empathy: Be empathetic, communitarian and trustworthy'], 'Responsibilities': ['As a Senior Data Engineer, you will be implementing critical ETL pipelines and advancing best practices for the data engineering team, and the rest of the organization', 'You will work on delivering an actual big data architecture while concentrating on real-world problems such as privacy concerns', 'Work with our Engineering teams to ensure data is flowing accurately through data creation to our presentation layers', 'Become an advocate for the Data Engineering team by developing and championing Data Engineering practices with the team and with the company at large', 'Improve our Data Engineering stack through containerization, data modeling, developing our ETL pipelines, and building scalable/reliable solutions', 'Work with stakeholders and translate their needs and expectations into action items and deliverables', 'Lead infrastructure initiatives, from design to implementation to delivery', 'Support existing on-prem infrastructure and help expand our processes into the cloud (AWS)'], 'Benefits': ['Annual training budget for each employee', '100% employer match on 401k contributions', 'Specific COVID-19 allowance for home office set-up', 'Matched giving to qualified organizations', '100% paid Parental Leave']}",Data engineer,en,15113200,4,,,
n2SRAN_BDGAAAAAAAAAAAA==,Georgia IT Inc.,,,,Talent.com,FULLTIME,Data engineer,https://www.talent.com/view?id=376ab70841cb,False,0.4858,"Data Engineer

Location : Dallas, Texas

Type : Contract

Rate : DOE

NO third-party Corp to Corp accepted for this job

Description
• Strong Python, bash, Linux shell or similar
• Experience integrating with native AWS services (CodePipeline, CodeCommit, CodeBuild, CodeDeploy, EC2, EKS, ECR, S3)
• Knowledge of networking, IAM, API and security assessment tools / methodologies.
• Familiar with IAM protocols such as SAML, SPML, XACML, SCIM, OpenID and OAuth.
• Understanding of the cyber threat landscape and methodologies to protect technology assets.
• AWS Certified Developer Associate or AWS Certified Solutions Architect Associate preferred.
• Excellent verbal and written communication skills
• Proficient in automation and deploying CI and CD tools and services (Jenkins Pipeline as Code, Git, Maven).
• Hands on experience building solutions with tools and services like AWS CloudFormation, Terraform, or custom build orchestration tools leveraging SDKs or directly interacting with APIs
• Strong understanding of fundamental Application and Infrastructure Security concepts, including common types of attacks and exploitation techniques.
• Solid Experience with various application security tools (Example ZAP, BURP, Tenable,Check Mark, Semmel, fortify, Sonatype, Kali, WebInspect / AppScan, dependency check).
• Solid understanding of common web and systems application vulnerabilities.Experience integrating security tools into the DevOps environment (such as Zap or Burp)

Last updated : 2023-07-26",False,1690329600,2023-07-26T00:00:00.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=30&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=n2SRAN_BDGAAAAAAAAAAAA%3D%3D",2023-09-28T00:00:00.000Z,1695859200.0,"{'no_experience_required': False, 'required_experience_in_months': None, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': False, 'degree_preferred': False, 'professional_certification_mentioned': True}",False,,,,,"{'Qualifications': ['Strong Python, bash, Linux shell or similar', 'Experience integrating with native AWS services (CodePipeline, CodeCommit, CodeBuild, CodeDeploy, EC2, EKS, ECR, S3)', 'Knowledge of networking, IAM, API and security assessment tools / methodologies', 'Familiar with IAM protocols such as SAML, SPML, XACML, SCIM, OpenID and OAuth', 'Understanding of the cyber threat landscape and methodologies to protect technology assets', 'Excellent verbal and written communication skills', 'Proficient in automation and deploying CI and CD tools and services (Jenkins Pipeline as Code, Git, Maven)', 'Hands on experience building solutions with tools and services like AWS CloudFormation, Terraform, or custom build orchestration tools leveraging SDKs or directly interacting with APIs', 'Strong understanding of fundamental Application and Infrastructure Security concepts, including common types of attacks and exploitation techniques', 'Solid Experience with various application security tools (Example ZAP, BURP, Tenable,Check Mark, Semmel, fortify, Sonatype, Kali, WebInspect / AppScan, dependency check)', 'Solid understanding of common web and systems application vulnerabilities', 'Experience integrating security tools into the DevOps environment (such as Zap or Burp)', 'Last updated : 2023-07-26']}",Data engineer,en,15113200,4,['15-1243.00'],,
hH0fMST3sloAAAAAAAAAAA==,ryan,http://companies.naukri.com/ryan-jobs/wp-content/uploads/sites/2082/2015/02/product.jpg,http://www.ryan.com,,Salary.com,FULLTIME,"Senior Data Engineer, Data Engineering",https://www.salary.com/job/ryan/senior-data-engineer-data-engineering/j202305230636442430293,False,0.6703,"The Senior Data Engineer is responsible for the identifying, developing, and maintaining the technologies that enable the efficient flow of data throughout the organization. This role requires an enterprise mindset to build out robust, high-performance technology. Duties and Responsibilities, aligned with Key Results: People Use a variety of programming languages and tools to develop, test, and maintain data pipelines within the Platform Reference Architecture. Working directly with management, product teams and practice personnel to understand their platform data requirements Maintaining a positive work atmosphere by behaving and communicating in a manner that encourages productive interactions with customers, co-workers and supervisors Developing and engaging with team members by creating a motivating work environment that recognizes, holds team members accountable, and rewards strong performance Fostering an innovative, inclusive and diverse team environment, promoting positive team culture, encouraging collaboration and self-organization while delivering high quality solutions Client Collaborating on an Agile team to design, develop, test, implement and support highly scalable data solutions Collaborating with product teams and clients to deliver robust cloud-based data solutions that drive tax decisions and provide powerful experiences Analyzing user feedback and activity and iterate to improve the services and user experience Value Securing data in alignment with internal information and data security policies, best practices and client requirements Creating and implementing robust cloud-based data solutions that scale effectively, and provide powerful experiences for both internal teams and clients Performing unit tests and conducting reviews with other team members to make sure solutions and code are rigorously designed, elegantly coded and effectively tuned for performance Staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities and mentoring other members of the engineering community Perform other duties as assigned Education and Experience: Bachelor’s and/or Master’s degree in a related field. 7 years of experience developing data technologies. 7 years of experience deploying ETL solutions in production environments. 7 years of experience with cloud-based data services, preferably in AWS or Azure. 7 years of experience developing Python, Scala, Java, .Net or similar solutions in a backend or data wrangling capacity. 7 years of experience in mixed Windows/Linux environments. Additional Required Skills and Experience: Results-proven track record of exceeding goals and evidence of the ability to consistently make good decisions through a combination of analysis, experience and judgment Fluency in one or more databases, preferably relational and NoSQL is a plus. Experience with distributed data platforms is a plus. Exposure to AI/ML pipelines is preferred. Experience deploying, monitoring, and maintaining data pipelines in production environments Computer Skills: To perform this job successfully, an individual must have intermediate knowledge of Microsoft Project, Word, Excel, Access, PowerPoint, Outlook, and Internet navigation and research. Supervisory Responsibilities: Requires supervisory responsibilities, including training employees, assigning work, and assuring quality throughout any deliverables Work Environment: Standard indoor working environment. Occasional long periods of sitting while working at computer. Position requires regular interaction with employees at all levels of the Firm and interface with external vendors as necessary. Independent travel requirement: As Needed Remote position * For Denver, CO-based roles, the base salary hiring range for this position is $135,000 - $165,000. * For New York, NY-based roles, the base salary hiring range for this position is $155,000-$185,000. * For Bellevue, WA- based roles, the base salary hiring range for this position is $140,750-$173,000. * For Carlsbad, Glendale, Irvine, Los Angelos, Sacramento, and San Diego, CA-based roles, the base salary hiring range for this position is $140,750-$173,000. * For Oakland and San Jose, CA-based roles, the base salary hiring range for this position is $155,000-$185,000. *The Company makes offers based on many factors, including qualifications and experience Ryan offers outstanding opportunities to work in a dynamic, rapidly expanding tax services firm serving the world’s most respected Global 5000 companies. Our innovative work environment, accelerated growth path for high performers, competitive benefits package, and outstanding earning potential provide the most rewarding career experience available in the industry. Ryan employees are given the freedom to do their best work in the way they work best. With a clear understanding of expectations and accountabilities, our employees are given ownership of their time and flexibility to meet the demands of their professional and personal lives. Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Ryan LLC (i.e., H1-B visa, F-1 visa (OPT), TN visa or any other non-immigrant status). Job duties related to this role are to be conducted in a manner that adheres to privacy laws, as well as follows internal governance related to protecting confidential information and trade secrets, and to securing data and company records. Equal Employment Opportunity/Affirmative Action/Accommodation Ryan, LLC is an equal opportunity employer and is committed to compliance with all applicable laws prohibiting employment discrimination. It is our policy to take all employment actions and make all employment decisions without regard to race, color, religion, creed, gender, sex (including pregnancy), affectional or sexual orientation, gender identity or expression, national origin, ancestry, age, marital status, citizenship status, genetic predisposition or carrier status, disability, military status, status as a disabled or other protected veteran or any other protected status under applicable law. It is Ryan's policy to make reasonable accommodation for qualified individuals with disabilities. Please contact our People Group at 972.934.0022 or peoplegroup@ryan.com if you are interested in applying and need assistance to submit your application, or if you are interested in a position and believe you may require a reasonable commodation in order for you to perform its essential functions. Click here to view the entire EEO poster and supplement. *Notice to Canada Candidates – In accordance with the Accessibility for Ontarians with Disabilities Act (AODA), Ryan ULC will provide accommodation, accessible formats and communication supports for the interview upon request. Ryan welcomes and encourages applications from people with disabilities*. Ryan recognizes and is committed to compliance with the new General Data Protection Regulation (GDPR) promulgated by the European Union (EU). Please access our Privacy Notice in relation to this at the following link. Please access our Personal Data Protection Policy at the following link.",False,1688515200,2023-07-05T00:00:00.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=30&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=hH0fMST3sloAAAAAAAAAAA%3D%3D",2024-01-03T00:00:00.000Z,1704240000.0,"{'no_experience_required': False, 'required_experience_in_months': 84, 'experience_mentioned': True, 'experience_preferred': True}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': True, 'professional_certification_mentioned': False}",False,,,,,{},Data engineer,en,15113200,4,,,
LNndS8ll-f4AAAAAAAAAAA==,Costco Wholesale,https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQMEXpjzxSXP_hEYETqQMZmfop0Uwnb1a8puH1-&s=0,,,JobzMall,FULLTIME,Data Engineer - IT Sustainability,https://www.jobzmall.com/costco-wholesale/job/data-engineer-it-sustainability-1,True,0.5613,"We are looking for an experienced and passionate Data Engineer – IT Sustainability to join the IT team at Costco Wholesale. In this role, you will be responsible for developing and managing data solutions that support our IT sustainability objectives. The successful candidate should have a strong background in data engineering and experience working with sustainability initiatives in the IT space.You will need to be a highly-motivated, self-driven individual with strong interpersonal and problem-solving skills. We are looking for someone who is detail-oriented and can think outside the box to develop innovative solutions to complex problems. If you have a passion for sustainability initiatives, technical expertise, and a commitment to excellence, then this is the perfect opportunity for you.The successful candidate will possess a degree in a related field such as computer science, engineering, or information technology. Additionally, a minimum of two years of professional experience in data engineering and/or working with sustainability initiatives is required. Knowledge of database architecture and experience with data analytics and data visualization tools is also preferred.

Costco Wholesale is an Equal Opportunity Employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. We do not discriminate based upon race, religion, color, national origin, sex, sexual orientation, gender identity, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.",False,1676932976,2023-02-20T22:42:56.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=40&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=LNndS8ll-f4AAAAAAAAAAA%3D%3D",2023-08-25T23:59:59.000Z,1693007999.0,"{'no_experience_required': False, 'required_experience_in_months': 24, 'experience_mentioned': True, 'experience_preferred': True}",['Sql <br>Security <br>Python <br>Networking <br>Linux <br>Data Analysis <br>Communication <br>Leadership <br>Problem Solving <br>Time management <br>Big Data <br>Data Modeling <br>ETL <br>Data Visualization <br>Automation <br>Cloud Computing <br>Interpersonal Skills <br>creativity <br>flexibility <br>Organizational skills <br>Performance tuning <br>Data governance <br>collaboration <br>Adaptability <br>Data WarehouseCommunication <br>Leadership <br>Problem Solving <br>Time management <br>Interpersonal Skills <br>creativity <br>flexibility <br>Organizational skills <br>collaboration <br>Adaptability'],"{'postgraduate_degree': True, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': True, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['The successful candidate should have a strong background in data engineering and experience working with sustainability initiatives in the IT space', 'You will need to be a highly-motivated, self-driven individual with strong interpersonal and problem-solving skills', 'We are looking for someone who is detail-oriented and can think outside the box to develop innovative solutions to complex problems', 'The successful candidate will possess a degree in a related field such as computer science, engineering, or information technology', 'Additionally, a minimum of two years of professional experience in data engineering and/or working with sustainability initiatives is required'], 'Responsibilities': ['In this role, you will be responsible for developing and managing data solutions that support our IT sustainability objectives']}",Data engineer,en,15113200,4,,,
XJyrP7Ypp5EAAAAAAAAAAA==,Deloitte,https://1000logos.net/wp-content/uploads/2021/05/Deloitte-logo.png,http://www.deloitte.com,Consulting,Deloitte Jobs,FULLTIME,Cloud Data Engineer - Healthcare,https://jobsus.deloitte.com/dallas-tx/cloud-data-engineer-healthcare/5347059EE1A64B8EB63C4D1D17227594/job/,False,0.7262,"Are you an experienced, passionate pioneer in technology who wants to work in a collaborative environment? As an experienced Cloud Data Engineer - Healthcare you will have the ability to share new ideas and collaborate on projects as a consultant without the extensive demands of travel. If so, consider an opportunity with Deloitte under our Project Delivery Talent Model. Project Delivery Model (PDM) is a talent model that is tailored specifically for long-term, onsite client service delivery. This position is working on a multi-year project for a major healthcare client. This is a remote role.

Work you'll do/Responsibilities

You will determine processes and automation tools to reduce IT spend and increase efficiencies on multiple projects within the Healthcare domain.

This position includes collaborating with DevOps teams to implement CI/CD pipelines, automated deployments, and infrastructure as code (IaC) practices for AWS-based solutions. Document design, development, and deployment processes, as well as create technical specifications and user guides for developed solutions.

Your role will be to design, develop, and deploy cloud-based solutions for data processing, analytics, and integration using cloud services and big data technologies. Collaborate with architects, data engineers, and business stakeholders to understand requirements and translate them into technical solutions.

You will implement data ingestion, transformation, and storage processes using cloud services like AWS's S3, Glue, Athena, Redshift, and EMR. Implement security, data governance, and compliance measures to ensure data integrity and protection in AWS-based solutions. Develop and optimize data pipelines using Snowpark, SnowSQL, Hadoop and PySpark to extract, transform, and load data efficiently.

You will conduct performance tuning and optimization of data processing and analytics workflows to maximize efficiency and scalability. Work with cross-functional teams to troubleshoot and resolve issues related to data processing, data integration, and analytics solutions.

Communicate regularly with Engagement Managers (Directors), project team members, and representatives from various functional and / or technical teams, including escalating any matters that require additional attention and consideration from engagement management

The Team

As a part of the US Strategy & Analytics Offering Portfolio, the AI & Data Operations offering provides managed AI, Intelligent Automation, and Data DevOps services across the advise-implement-operate spectrum.

Qualifications

Required

• 3 + years' experience as a Cloud Data Engineer

• 3 + years' hands on experience in Snowpark, SnowSQL, Hadoop and PySpark

• 3 + years' experience in AWS services such as S3, Glue, Athena, Redshift, EMR, Lambda and Cloud Formation.

• 3 + years' experience in Python with a focus on data processing and analytics

• 3+ years in healthcare domain

• 3 + years in consulting

• Strong knowledge and hands-on experience in designing, developing, and deploying scalable solutions on the cloud platforms

• Expertise in SQL and database technologies for data manipulation and querying

• Bachelor's degree or equivalent experience

• Limited immigration sponsorship may be available

Preferred

• Familiarity with data modeling, data warehousing, and data integration concepts.

• Experience with DevOps practices, CI/CD pipelines, and infrastructure as code (IAAC) using tools like Jenkins, Git, and Terraform.

• Strong analytical and problem-solving skills, with the ability to troubleshoot and resolve complex technical issues.

• Familiarity with agile development methodologies and experience working in Agile teams

• Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve

• Bachelor's degree, preferably in Computer Science, Information Technology, Computer Engineering, or related IT discipline; or equivalent experience

• Analytical/ decision making responsibilities

• Analytical ability to manage multiple projects and prioritize tasks into manageable work products

• Can operate independently or with minimum supervision

• Excellent communication skills

• Ability to deliver technical demonstrations

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.",False,1689047561,2023-07-11T03:52:41.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=40&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=XJyrP7Ypp5EAAAAAAAAAAA%3D%3D",,,"{'no_experience_required': False, 'required_experience_in_months': 36, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': [""3 + years' experience as a Cloud Data Engineer"", ""3 + years' hands on experience in Snowpark, SnowSQL, Hadoop and PySpark"", ""3 + years' experience in AWS services such as S3, Glue, Athena, Redshift, EMR, Lambda and Cloud Formation"", ""3 + years' experience in Python with a focus on data processing and analytics"", '3+ years in healthcare domain', '3 + years in consulting', 'Strong knowledge and hands-on experience in designing, developing, and deploying scalable solutions on the cloud platforms', 'Expertise in SQL and database technologies for data manipulation and querying', ""Bachelor's degree or equivalent experience"", 'Limited immigration sponsorship may be available'], 'Responsibilities': ['You will determine processes and automation tools to reduce IT spend and increase efficiencies on multiple projects within the Healthcare domain', 'This position includes collaborating with DevOps teams to implement CI/CD pipelines, automated deployments, and infrastructure as code (IaC) practices for AWS-based solutions', 'Document design, development, and deployment processes, as well as create technical specifications and user guides for developed solutions', 'Your role will be to design, develop, and deploy cloud-based solutions for data processing, analytics, and integration using cloud services and big data technologies', 'Collaborate with architects, data engineers, and business stakeholders to understand requirements and translate them into technical solutions', ""You will implement data ingestion, transformation, and storage processes using cloud services like AWS's S3, Glue, Athena, Redshift, and EMR"", 'Implement security, data governance, and compliance measures to ensure data integrity and protection in AWS-based solutions', 'Develop and optimize data pipelines using Snowpark, SnowSQL, Hadoop and PySpark to extract, transform, and load data efficiently', 'You will conduct performance tuning and optimization of data processing and analytics workflows to maximize efficiency and scalability', 'Work with cross-functional teams to troubleshoot and resolve issues related to data processing, data integration, and analytics solutions', 'Communicate regularly with Engagement Managers (Directors), project team members, and representatives from various functional and / or technical teams, including escalating any matters that require additional attention and consideration from engagement management']}",Data engineer,en,15113200,4,,541613,Marketing Consulting Services
_M1aY3afaAIAAAAAAAAAAA==,Logic20/20 Inc.,"https://res.cloudinary.com/crunchbase-production/image/upload/c_lpad,f_auto,q_auto:eco,dpr_1/ffwrq37xnvyhjt1nwrdm",http://www.logic2020.com,,Recruit.net,FULLTIME,Cloud Data Engineer,https://www.recruit.net/job/data-engineer-jobs/06F50F3CC7184312,False,0.4154,"Job Description

As a senior or lead Data Engineer joining Logic20/20's Advanced Analytics practice, you'll be supporting a team at one of the largest utility companies in California creating data pipelines to land data in an AWS data lake, and working with data transformation and integration to support future analytics. You will improve risk modeling that will allow the client to better understand the integrity of their pipelines for improved customer safety.

Hear more about these efforts as Jeff Lovington shares his experience working in Data Science and Machine Learning for the Energy & Utilities sector.

About the Team

The Logic20/20 Advanced Analytics team is where skilled professionals in data engineering, data science, and visual analytics join forces to build simple solutions for complex data problems. We make it look like magic, but for us, it’s all in a day’s work. As part of our team, you’ll collaborate on projects that help clients spin their data into a high-performance asset, all while enjoying the company of kindred spirits who are as committed to your success as you are. And when you’re ready to level up in your career, you’ll have access to the training, the project opportunities, and the mentorship to get you where you want to go.

“We build an environment where we really operate as one team, building up each other’s careers and capabilities.” – Adam Cornille, Senior Director, Advanced Analytics",False,1690502400,2023-07-28T00:00:00.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=40&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=_M1aY3afaAIAAAAAAAAAAA%3D%3D",2023-08-27T00:00:00.000Z,1693094400.0,"{'no_experience_required': False, 'required_experience_in_months': None, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': False, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,,,,,{'Responsibilities': ['You will improve risk modeling that will allow the client to better understand the integrity of their pipelines for improved customer safety']},Data engineer,en,15113200,4,,,
iIPKNvIu2lsAAAAAAAAAAA==,Anblicks,https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSQELFQA-mOEuM-uxSMFuX5c178DZQmERReaPz9&s=0,,,Built In,FULLTIME,"Senior Data Engineer (Dallas, TX)",https://builtin.com/job/data/senior-data-engineer/1600833,False,0.7071,"Job Title: Senior Data Engineer

JOB DUTIES:

Participate in daily agile and scrum processes to understand changing business requirements, including examining system configurations and operating procedures, as well as functional requirements gathering. Ingest and prepare business-ready data in the cloud using Azure Data Factory (ADF) to build ELT(Extract Load and Transform)/ETL (Extract Transform and Load) data pipelines, then move the data into a data warehouse (Dedicated SQL Pool) and create data lake zones for data analytics and visualization. Work with a combination of Azure Data Factory and Azure Databricks, extract, load, and transform data from cloud sources and on-premises databases such as Oracle, SAP, and SQL Server to Data Lake Storage and Azure Synapse Analytics. Create an Azure Data Factory Pipeline Template to migrate an on-premises data platform to the Azure Cloud using batch processing methods by incremental or full load, and an ADF config driven framework to pull data from multiple sources with different table structures with less manual work and less resource usage. Analyze, design, and build modern data solutions using Azure PaaS services to support data visualization. Understand the current production state of the application and the impact of new implementation on existing business processes. Enable private end point, firewall setting and Azure Key Vault for robust data security. Analyze the existing SSIS packages and integrate it with Azure Data Factory, using SSIS transformations like Lookup, Derived column, Data conversion, Aggregate, Conditional split, SQL task, Script task, and Send Mail task. Create a JSON structure for data storage in Azure Cosmos DB (SQL API), write stored procedures and functions and work with the API team to create Cosmos DB queries that use fewer request units. Data Model in Snowflake and ELT using Snowflake SQL, implementing complex stored procedures and best practices with data warehouse and ETL concepts. Design and customize dimension data models for data warehouse supporting data using Azure Synapse Analytics, and select the appropriate distribution method in dimension and fact tables to load the data in an optimized manner, as well as implement complex stored procedures and best practices with data warehouse. Build a distributed in-memory application using spark applications and perform analytics efficiently on large datasets using python and Spark SQL, also use Spark SQL to implement transformation logic in Databricks and mount/unmount Azure Blob Storage. Read the data from different file format parquet, avro, csv and json using pySpark (Python API) in Azure Databricks and perform data extraction, transformation to uncover insights into customer usage patterns and insert curated data into a data warehouse. Create data visualization reports and dashboards in Power BI using data from the data warehouse, flat files, and Azure SQL. Responsible for fixing problems and conducting investigations into SQL queries, Stored Procedures related to long running jobs and Azure service performance. Utilize Azure Monitor and Alert services, create monitors, alerts, and notifications for Data Factory, Synapse Analytics, and Data Lake Storage. Perform the required daily GIT support for various projects. Be in charge of maintaining GIT repositories and access control procedures. Create CI&CD using azure dev ops pipeline to deploy Azure Services (Storage, Data factory, Key vault & Logic App) using ARM Templates.

JOB REQUIREMENT:

Master's degree in Computer Science, Computer Information Systems, or Engineering related or Technical related fields plus 2 years of experience. In lieu of the above, we will also accept a Bachelor's degree in Computer Science, Computer Information Systems, or Engineering related or Technical related fields plus 5 years of progressively responsible post-baccalaureate experience. Foreign degree equivalent is acceptable. We will also accept any suitable combination of education, training and/or experience. Experience to include working on Azure Data Factory (ADF), Oracle, SQL server, Azure Databricks, Azure Synapse Analytics, Data Lake Storage, Azure PaaS services, SSIS packages, Azure Cosmos DB (SQL API), Python, Spark applications, Azure SQL, SQL queries, Azure Monitor and Alert services, GIT Support, ARM Templates.

HOURS: M-F, 8:00 a.m. - 5:00 p.m.

JOB LOCATION: Dallas, Texas. Travel is not required, but candidates must be willing to relocate to unanticipated work locations across the country per contract demand.

CONTACT: Email resume referencing job code# SDE01302023ANB to Maruthi Technologies INC. DBA Anblicks at hr@anblicks.com",False,1675497656,2023-02-04T08:00:56.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=40&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=iIPKNvIu2lsAAAAAAAAAAA%3D%3D",,,"{'no_experience_required': False, 'required_experience_in_months': 60, 'experience_mentioned': True, 'experience_preferred': True}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': True, 'degree_mentioned': True, 'degree_preferred': True, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['Create CI&CD using azure dev ops pipeline to deploy Azure Services (Storage, Data factory, Key vault & Logic App) using ARM Templates', ""In lieu of the above, we will also accept a Bachelor's degree in Computer Science, Computer Information Systems, or Engineering related or Technical related fields plus 5 years of progressively responsible post-baccalaureate experience"", 'Foreign degree equivalent is acceptable', 'We will also accept any suitable combination of education, training and/or experience', 'Experience to include working on Azure Data Factory (ADF), Oracle, SQL server, Azure Databricks, Azure Synapse Analytics, Data Lake Storage, Azure PaaS services, SSIS packages, Azure Cosmos DB (SQL API), Python, Spark applications, Azure SQL, SQL queries, Azure Monitor and Alert services, GIT Support, ARM Templates'], 'Responsibilities': ['Participate in daily agile and scrum processes to understand changing business requirements, including examining system configurations and operating procedures, as well as functional requirements gathering', 'Ingest and prepare business-ready data in the cloud using Azure Data Factory (ADF) to build ELT(Extract Load and Transform)/ETL (Extract Transform and Load) data pipelines, then move the data into a data warehouse (Dedicated SQL Pool) and create data lake zones for data analytics and visualization', 'Work with a combination of Azure Data Factory and Azure Databricks, extract, load, and transform data from cloud sources and on-premises databases such as Oracle, SAP, and SQL Server to Data Lake Storage and Azure Synapse Analytics', 'Analyze, design, and build modern data solutions using Azure PaaS services to support data visualization', 'Understand the current production state of the application and the impact of new implementation on existing business processes', 'Enable private end point, firewall setting and Azure Key Vault for robust data security', 'Analyze the existing SSIS packages and integrate it with Azure Data Factory, using SSIS transformations like Lookup, Derived column, Data conversion, Aggregate, Conditional split, SQL task, Script task, and Send Mail task', 'Create a JSON structure for data storage in Azure Cosmos DB (SQL API), write stored procedures and functions and work with the API team to create Cosmos DB queries that use fewer request units', 'Data Model in Snowflake and ELT using Snowflake SQL, implementing complex stored procedures and best practices with data warehouse and ETL concepts', 'Design and customize dimension data models for data warehouse supporting data using Azure Synapse Analytics, and select the appropriate distribution method in dimension and fact tables to load the data in an optimized manner, as well as implement complex stored procedures and best practices with data warehouse', 'Build a distributed in-memory application using spark applications and perform analytics efficiently on large datasets using python and Spark SQL, also use Spark SQL to implement transformation logic in Databricks and mount/unmount Azure Blob Storage', 'Read the data from different file format parquet, avro, csv and json using pySpark (Python API) in Azure Databricks and perform data extraction, transformation to uncover insights into customer usage patterns and insert curated data into a data warehouse', 'Create data visualization reports and dashboards in Power BI using data from the data warehouse, flat files, and Azure SQL', 'Responsible for fixing problems and conducting investigations into SQL queries, Stored Procedures related to long running jobs and Azure service performance', 'Utilize Azure Monitor and Alert services, create monitors, alerts, and notifications for Data Factory, Synapse Analytics, and Data Lake Storage', 'Perform the required daily GIT support for various projects', 'Be in charge of maintaining GIT repositories and access control procedures']}",Data engineer,en,15113200,4,,,
GVXNPo1qmE4AAAAAAAAAAA==,Amazon.com Services LLC,,,,"Dallas, TX - Geebo",FULLTIME,Data Engineer,https://dallas-tx.geebo.com/jobs-online/view/id/1082323003-data-engineer-/,True,0.424,"Job summaryAmazon is one of the largest employers on the planet with hundreds of thousands of employees across the globe.
Amazon's HR mission is to build a workplace for Amazonians to invent on behalf of our customers.
We are enablers to help Amazon scale quickly and efficiently as we continue to expand rapidly across countries, business lines and size in general.
The volume of internal human resource transactions and range of experiences to fulfill in this scale and diversity are massive and unique respectively.
This requires a highly reliable, scalable and customized series of software applications that ensure our global employee base receives accurate, timely and best experiences throughout their employee lifecycle.
Amazon has grown significantly since the deployment of these tools and we are now at an inflection point where we are making long term decisions to support our explosive global growth.
Our Time and Attendance group is seeking a bright and motivated Data Engineer for leading the launch of timekeeping systems to support business expansions and deliver automations to achieve process efficiency and perfect pay for associates.
Job
Responsibilities:
Translate business and functional requirements into robust, scalable, operable solutions that work well within the overall data architecture.
Design, develop, implement, test, document, and operate large-scale, high-volume and low latency applications.
Build integrations between HR, Time & Attendance and Payroll systems to automate employee hire, schedule, punch and pay.
Designs data integrations and data quality framework.
Develops and maintains scalable data pipelines and builds out new API integrations.
Implement data structures using best practices in data modeling, ETL/ELT processes, SQL, and Oracle.
Manage stakeholder communication, prioritization of tasks and on time solution delivery.
Participate in the full development life cycle, end-to-end, from design, implementation and testing, to documentation, delivery, support, and maintenance.
Produce comprehensive, usable dataset documentation and metadata.
Design and develop operational and analytical reports as per the customer needs by using the tools.
Evaluate and make decisions around the use of new or existing software products and tools.
Mentor junior data engineers.
.
Estimated Salary: $20 to $28 per hour based on qualifications.",False,1690416000,2023-07-27T00:00:00.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=40&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=GVXNPo1qmE4AAAAAAAAAAA%3D%3D",2023-08-03T00:00:00.000Z,1691020800.0,"{'no_experience_required': False, 'required_experience_in_months': None, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': False, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,20.0,28.0,USD,HOUR,"{'Responsibilities': ['Translate business and functional requirements into robust, scalable, operable solutions that work well within the overall data architecture', 'Design, develop, implement, test, document, and operate large-scale, high-volume and low latency applications', 'Build integrations between HR, Time & Attendance and Payroll systems to automate employee hire, schedule, punch and pay', 'Designs data integrations and data quality framework', 'Develops and maintains scalable data pipelines and builds out new API integrations', 'Implement data structures using best practices in data modeling, ETL/ELT processes, SQL, and Oracle', 'Manage stakeholder communication, prioritization of tasks and on time solution delivery', 'Participate in the full development life cycle, end-to-end, from design, implementation and testing, to documentation, delivery, support, and maintenance', 'Produce comprehensive, usable dataset documentation and metadata', 'Design and develop operational and analytical reports as per the customer needs by using the tools', 'Evaluate and make decisions around the use of new or existing software products and tools'], 'Benefits': ['Estimated Salary: $20 to $28 per hour based on qualifications']}",Data engineer,en,15113200,4,,,
6F_oejzQGBcAAAAAAAAAAA==,Galderma S.A.,https://cdn.cookielaw.org/logos/9eb64978-23c0-4924-97a4-03eb6aab1106/83dc1859-114b-46cf-b32e-e3bbebc77feb/ad633653-014e-4c29-b120-efef9829e7a2/GALDERMA_LOGO_BLACK_RGB.jpg,http://www.galderma.com,Manufacturing,ZipRecruiter,FULLTIME,Data Engineer,"https://www.ziprecruiter.com/c/Galderma-S.A./Job/Data-Engineer/-in-Dallas,TX?jid=a2ca00aba7b601c2",False,0.7258,"With a unique legacy in dermatology as well as decades of cutting-edge innovation, Galderma is the pure-play dermatology category leader, present in approximately 90 countries. We deliver an innovative, science-based portfolio of premium flagship brands and services that spans the full spectrum of the fast-growing dermatology market through Injectable Aesthetics, Dermo-cosmetics, and Therapeutic Dermatology. Since our foundation in 1981, we have dedicated our focus and passion to the human body's largest organ - the skin - meeting individual consumer and patient needs with superior outcomes in partnership with healthcare professionals. Because we understand that the skin we're in shapes our lives, we are advancing dermatology for every skin story.

We look for people who focus on getting results, embrace learning and bring a positive energy. They must combine initiative with a sense of teamwork and collaboration. Above all, they must be passionate about doing something meaningful for consumers, patients, and the healthcare professionals we serve every day. We aim to empower each employee and promote their personal growth while ensuring business needs are met now and into the future. Across our company, we embrace diversity and respect the dignity, privacy, and personal rights of every employee.

At Galderma, we actively give our teams reasons to believe in our bold ambition to become the leading dermatology company in the world. With us, you have the ultimate opportunity to gain new and challenging work experiences and create an unparalleled, direct impact.

Job Title: Data Engineer

Location: Dallas, TX (Hybrid)

Job Description

The Data Engineer leads initiatives to develop and implement business-driven BI and Analytics solutions to enable business to win in the markets and gain competitive advantage. This individual serves as the primary liaison between IT Analytics, Shared Services, and the Business Units.

Key Responsibilities
• Understand customers' overall data estate business, related success measures, and IT priorities in order to design data solutions that drive business value
• Educate the business and promote best practices on how to leverage BI and analytics solutions, as well as help facilitate discussions to anticipate future needs and opportunities
• Assist in the identification and integration of data sources
• Clearly communicate findings, recommendations, and opportunities to improve data systems and solutions
• Seek out information to learn about emerging methodologies and technologies
• Work closely with DevOps team to automate the deployment of resources to our various Azure subscription
• Performs technical design reviews and code reviews

Skills & Qualifications
• Bachelor's degree in Information Technology or a related field, required
• 5 years of experience in implementing DWH / BI solutions
• 3 years of experience leading projects in analysis, architecture, design, and development of traditional data warehouse, data pipeline and business intelligence solutions
• 3 years of experience as a Data Engineer using Data Brick and Snowflake
• Good understanding of various Data Models such as Dimensional Data Modeling and DataVault Modeling
• Experience with Azure cloud services such as azure cloud security, monitoring, logging, scaling, caching, etc.
• Experience dealing with cloud workloads, application, and infrastructure architecture, data ingestion architecture, data storage, and transformations, data analytics, serverless function/application design, micro-services, DevOps
• Experience with Linux and cloud environment including commands and scripting
• Solid experience in writing complex SQL queries as well as PL/SQL programs on Oracle database
• Familiarity with DevOps best practices and automation of documentation, testing, build, deployment, configuration, and monitoring
• Experience in visualization tools/solution such as Tableau and Power BI
• Solid communication skills, particularly in writing technical solution proposals

What we offer in return

You will be working for an organization that embraces diversity & inclusion and believe we will deliver better outcomes by reflecting the perspectives of our diverse customer base. You will also have access to a range of company benefits, including a competitive wage with shift differential, annual bonus opportunities and career advancement and cross-training.

Next Steps
• If your profile is a match, we will invite you for a first virtual conversation with the recruiter.
• The next step is a virtual conversation with the hiring manager
• The final step is a panel conversation with the extended team

Our people make a difference:

At Galderma, you'll work with people who are like you. And people that are different. We value what every member of our team brings. Professionalism, collaboration, and a friendly, supportive ethos is the perfect environment for people to thrive and excel in what they do.

Employer's Rights:

This job description does not list all the duties of the job. You may be asked by your supervisors or managers to perform other duties. You will be evaluated in part based on your performance of the tasks listed in this job description. The employer has the right to revise this job description at any time. This job description is not an employment contract, and either you or the employer may terminate employment at any time, for any reason. In addition, reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions of this position.",False,1689552000,2023-07-17T00:00:00.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=40&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=6F_oejzQGBcAAAAAAAAAAA%3D%3D",2023-08-26T00:00:00.000Z,1693008000.0,"{'no_experience_required': False, 'required_experience_in_months': 60, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': True, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': [""Bachelor's degree in Information Technology or a related field, required"", '5 years of experience in implementing DWH / BI solutions', '3 years of experience leading projects in analysis, architecture, design, and development of traditional data warehouse, data pipeline and business intelligence solutions', '3 years of experience as a Data Engineer using Data Brick and Snowflake', 'Good understanding of various Data Models such as Dimensional Data Modeling and DataVault Modeling', 'Experience with Azure cloud services such as azure cloud security, monitoring, logging, scaling, caching, etc', 'Experience dealing with cloud workloads, application, and infrastructure architecture, data ingestion architecture, data storage, and transformations, data analytics, serverless function/application design, micro-services, DevOps', 'Experience with Linux and cloud environment including commands and scripting', 'Solid experience in writing complex SQL queries as well as PL/SQL programs on Oracle database', 'Familiarity with DevOps best practices and automation of documentation, testing, build, deployment, configuration, and monitoring', 'Experience in visualization tools/solution such as Tableau and Power BI', 'Solid communication skills, particularly in writing technical solution proposals'], 'Responsibilities': ['This individual serves as the primary liaison between IT Analytics, Shared Services, and the Business Units', ""Understand customers' overall data estate business, related success measures, and IT priorities in order to design data solutions that drive business value"", 'Educate the business and promote best practices on how to leverage BI and analytics solutions, as well as help facilitate discussions to anticipate future needs and opportunities', 'Assist in the identification and integration of data sources', 'Clearly communicate findings, recommendations, and opportunities to improve data systems and solutions', 'Seek out information to learn about emerging methodologies and technologies', 'Work closely with DevOps team to automate the deployment of resources to our various Azure subscription', 'Performs technical design reviews and code reviews'], 'Benefits': ['You will also have access to a range of company benefits, including a competitive wage with shift differential, annual bonus opportunities and career advancement and cross-training']}",Data engineer,en,15113200,4,['15-2041.00: Statisticians'],325412,Pharmaceutical Preparation Manufacturing
42NJql7l_7EAAAAAAAAAAA==,Sage IT Inc,https://sageitinc.com/sagefiles/2021/12/Sage-IT-Logo-SVG.svg,http://sageitinc.com,,Salary.com,FULLTIME,Azure Data Engineer,https://www.salary.com/job/sage-it-inc/azure-data-engineer/j202301310152169988722,False,0.6615,"Job Description
Hello
Hope you are doing well.
My name is Fayyaz, and I am a staffing specialist in Sage IT. We are looking for Aws Data Engineer with one of our Client

To speed up the process, I would really appreciate it if you could review the job description below and get back to me with the most recent word format of your Resume at .

Title : . Azure Data Engineer
Location : Jersey City, NJ
Job Type : W2 Contract Role
Location: Plano TX || Day One Hybrid Onsite

Roles and Responsibilities:
Essential Skills/Basic Qualifications:
The Data Engineer Lead will be responsible for guiding development of multiple (2-4) projects at a single time.
His/her tasks will include directing Data Engineer team members in best practices and design/implementation decisions to support Data and Analytics Business Customers.
He/she will also be responsible to actively develop at least one of the projects under their leadership.
The proper candidate will be expected to identify risks and potential blockers and elevate appropriately or mitigate as needed.
This candidate should have strong communication skills.
Technical Skills: SAP Development Very Strong
Azure Development Strong to Very Strong

For more information, you can reach me onlt;/div> Have a great day ahead

Abu Fayyaz | Sales Manager
Direct:

;/b>

Report this job
• Dice Id: 10120222
• Position Id: 2023-38552
•",False,1690243200,2023-07-25T00:00:00.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=40&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=42NJql7l_7EAAAAAAAAAAA%3D%3D",2023-10-31T00:00:00.000Z,1698710400.0,"{'no_experience_required': False, 'required_experience_in_months': None, 'experience_mentioned': False, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': False, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['The proper candidate will be expected to identify risks and potential blockers and elevate appropriately or mitigate as needed', 'This candidate should have strong communication skills', 'Technical Skills: SAP Development Very Strong'], 'Responsibilities': ['The Data Engineer Lead will be responsible for guiding development of multiple (2-4) projects at a single time', 'His/her tasks will include directing Data Engineer team members in best practices and design/implementation decisions to support Data and Analytics Business Customers', 'He/she will also be responsible to actively develop at least one of the projects under their leadership']}",Data engineer,en,15113200,4,,,
sli4eini4GgAAAAAAAAAAA==,Koch Industries,https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQJLPxwM4W8LjSXGoaKBgxNiDWrXZE5FSPfBg&usqp=CAU,http://www.kochind.com,Manufacturing,LinkedIn,FULLTIME,Security Data Engineer,https://www.linkedin.com/jobs/view/security-data-engineer-at-koch-industries-3675614617,False,0.5519,"Your Job

The Koch Cyber Security Team is seeking a Security Data Engineer to join our global cyber security team. As a member of this team your primary duties will be to attend to the health and support of our SIEM tool and work closely with our analyst to ensure that data is available to them when needed.

Our Team

The Koch Cyber Security team is a dynamic and proactive force, fueled by an unwavering commitment to Koch's vision for value creation. With a relentless drive, we tackle cyber threats head-on, always ready to protect our stakeholders from any potential harm. Our team members are trailblazers, spearheading transformational efforts in areas such as Incident Response, Automation, exposure management, awareness, and the ever-evolving cyber landscape. We thrive on challenges and constantly seek innovative solutions to safeguard our organization and its interests.

What You Will Do
• Oversee the ingestion and normalization of new data sources.
• Maintain data availability
• Detect and remediate any drop in data ingestion
• Support, maintain and improve infrastructure for the data collection tools overall health
• Respond to customer inquiries surrounding the collection of data
• Work closely with Cyber Security team to ensure that analyst have access to the data they need and that it’s presented in a clear and concise manner
• Stay up to date with the latest trends and technologies in data engineering and cloud infrastructure management and applying them to our data collection tool stack
• Actively seek ways to improve our current data collection tool stack.

Who You Are (Basic Qualifications)
• Experience supporting a SIEM tool
• Experience deploying Infrastructure in cloud environments
• Experience building and troubleshooting data pipelines.

What Will Put You Ahead
• Experience with Global Information\Cyber Security Teams
• Experience with Machine Learning
• Experience with Multiple Operating Systems
• Knowledge with PowerShell, JavaScript, or Python Scripting
• Windows Or Linux Administration Experience
• SOAR Platform Experience
• Familiar with CIM date compliance

At Koch companies, we are entrepreneurs. This means we openly challenge the status quo, find new ways to create value and get rewarded for our individual contributions. Any compensation range provided for a role is an estimate determined by available market data. The actual amount may be higher or lower than the range provided considering each candidate’s knowledge, skills, abilities, and geographic location. If you have questions, please speak to your recruiter about the flexibility and detail of our compensation philosophy.

Hiring Philosophy

All Koch companies value diversity of thought, perspectives, aptitudes, experiences, and backgrounds. We are Military Ready and Second Chance employers. Learn more about our hiring philosophy here.

Who We Are

As a Koch company, Koch Global Services (KGS) creates solutions spanning technology, human resources, finance, project management and anything else our businesses need. With locations in India, Mexico, Poland and the United States, our employees have the opportunity to make a global impact.

At Koch, employees are empowered to do what they do best to make life better. Learn how our business philosophy helps employees unleash their potential while creating value for themselves and the company.

Our Benefits

Our goal is for each employee, and their families, to live fulfilling and healthy lives. We provide essential resources and support to build and maintain physical, financial, and emotional strength focusing on overall wellbeing so you can focus on what matters most. Our benefits plan includes medical, dental, vision, flexible spending and health savings accounts, life insurance, ADD, disability, retirement, paid vacation/time off, educational assistance, and may also include infertility assistance, paid parental leave and adoption assistance. Specific eligibility criteria is set by the applicable Summary Plan Description, policy or guideline and benefits may vary by geographic region. If you have questions on what benefits apply to you, please speak to your recruiter.

Equal Opportunities

Equal Opportunity Employer, including disability and protected veteran status. Except where prohibited by state law, all offers of employment are conditioned upon successfully passing a drug test. This employer uses E-Verify. Please visit the following website for additional information: http://www.kochcareers.com/doc/Everify.pdf",False,1690317872,2023-07-25T20:44:32.000Z,Dallas,TX,US,32.776665,-96.79699,"['health_insurance', 'retirement_savings', 'dental_coverage', 'paid_time_off']","https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=40&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=sli4eini4GgAAAAAAAAAAA%3D%3D",2023-08-24T20:44:32.000Z,1692909872.0,"{'no_experience_required': False, 'required_experience_in_months': None, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': True, 'degree_mentioned': True, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['Experience supporting a SIEM tool', 'Experience deploying Infrastructure in cloud environments', 'Experience building and troubleshooting data pipelines', 'Experience with Global Information\\Cyber Security Teams', 'Experience with Machine Learning', 'Experience with Multiple Operating Systems', 'Knowledge with PowerShell, JavaScript, or Python Scripting', 'Windows Or Linux Administration Experience', 'SOAR Platform Experience', 'Familiar with CIM date compliance'], 'Responsibilities': ['Oversee the ingestion and normalization of new data sources', 'Maintain data availability', 'Detect and remediate any drop in data ingestion', 'Support, maintain and improve infrastructure for the data collection tools overall health', 'Respond to customer inquiries surrounding the collection of data', 'Work closely with Cyber Security team to ensure that analyst have access to the data they need and that it’s presented in a clear and concise manner', 'Stay up to date with the latest trends and technologies in data engineering and cloud infrastructure management and applying them to our data collection tool stack', 'Actively seek ways to improve our current data collection tool stack'], 'Benefits': ['Any compensation range provided for a role is an estimate determined by available market data', 'Our benefits plan includes medical, dental, vision, flexible spending and health savings accounts, life insurance, ADD, disability, retirement, paid vacation/time off, educational assistance, and may also include infertility assistance, paid parental leave and adoption assistance']}",Data engineer,en,15112200,4,,32519,Other Basic Organic Chemical Manufacturing
8SyHUOO43CsAAAAAAAAAAA==,"Ryan, LLC",http://companies.naukri.com/ryan-jobs/wp-content/uploads/sites/2082/2015/02/product.jpg,http://www.ryan.com,,Glassdoor,FULLTIME,"Senior Data Engineer, Data Engineering","https://www.glassdoor.com/job-listing/senior-data-engineer-data-engineering-ryan-llc-JV_IC1139977_KO0,37_KE38,46.htm?jl=1008660428279",False,0.566,"The Senior Data Engineer is responsible for the identifying, developing, and maintaining the technologies that enable the efficient flow of data throughout the organization. This role requires an enterprise mindset to build out robust, high-performance technology.
Duties and Responsibilities, aligned with Key Results:

People
• Use a variety of programming languages and tools to develop, test, and maintain data pipelines within the Platform Reference Architecture.
• Working directly with management, product teams and practice personnel to understand their platform data requirements
• Maintaining a positive work atmosphere by behaving and communicating in a manner that encourages productive interactions with customers, co-workers and supervisors
• Developing and engaging with team members by creating a motivating work environment that recognizes, holds team members accountable, and rewards strong performance
• Fostering an innovative, inclusive and diverse team environment, promoting positive team culture, encouraging collaboration and self-organization while delivering high quality solutions

Client
• Collaborating on an Agile team to design, develop, test, implement and support highly scalable data solutions
• Collaborating with product teams and clients to deliver robust cloud-based data solutions that drive tax decisions and provide powerful experiences
• Analyzing user feedback and activity and iterate to improve the services and user experience

Value
• Securing data in alignment with internal information and data security policies, best practices and client requirements
• Creating and implementing robust cloud-based data solutions that scale effectively, and provide powerful experiences for both internal teams and clients
• Performing unit tests and conducting reviews with other team members to make sure solutions and code are rigorously designed, elegantly coded and effectively tuned for performance
• Staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities and mentoring other members of the engineering community
• Perform other duties as assigned

Education and Experience:

Bachelor’s and/or Master’s degree in a related field.
• 7+ years of experience developing data technologies.
• 7+ years of experience deploying ETL solutions in production environments.
• 7+ years of experience with cloud-based data services, preferably in AWS or Azure.
• 7+ years of experience developing Python, Scala, Java, .Net or similar solutions in a backend or data wrangling capacity.
• 7+ years of experience in mixed Windows/Linux environments.

Additional Required Skills and Experience:
• Results-proven track record of exceeding goals and evidence of the ability to consistently make good decisions through a combination of analysis, experience and judgment
• Fluency in one or more databases, preferably relational and NoSQL is a plus.
• Experience with distributed data platforms is a plus.
• Exposure to AI/ML pipelines is preferred.
• Experience deploying, monitoring, and maintaining data pipelines in production environments

Computer Skills:

To perform this job successfully, an individual must have intermediate knowledge of Microsoft Project, Word, Excel, Access, PowerPoint, Outlook, and Internet navigation and research.

Supervisory Responsibilities:

Requires supervisory responsibilities, including training employees, assigning work, and assuring quality throughout any deliverables

Work Environment:
• Standard indoor working environment.
• Occasional long periods of sitting while working at computer.
• Position requires regular interaction with employees at all levels of the Firm and interface with external vendors as necessary.
• Independent travel requirement: As Needed

Remote position
• For Denver, CO-based roles, the base salary hiring range for this position is

$135,000 - $165,000.
• For New York, NY-based roles, the base salary hiring range for this position is

$155,000-$185,000.
• For Bellevue, WA- based roles, the base salary hiring range for this position is

$140,750-$173,000.
• For Carlsbad, Glendale, Irvine, Los Angelos, Sacramento, and San Diego, CA-based roles, the base salary hiring range for this position is $140,750-$173,000.
• For Oakland and San Jose, CA-based roles, the base salary hiring range for this position is $155,000-$185,000.
• The Company makes offers based on many factors, including qualifications and experience",True,1689984000,2023-07-22T00:00:00.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=50&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=8SyHUOO43CsAAAAAAAAAAA%3D%3D",,,"{'no_experience_required': False, 'required_experience_in_months': 84, 'experience_mentioned': True, 'experience_preferred': True}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': True, 'professional_certification_mentioned': False}",False,135000.0,165000.0,USD,YEAR,"{'Qualifications': ['Bachelor’s and/or Master’s degree in a related field', '7+ years of experience deploying ETL solutions in production environments', '7+ years of experience with cloud-based data services, preferably in AWS or Azure', '7+ years of experience developing Python, Scala, Java, .Net or similar solutions in a backend or data wrangling capacity', '7+ years of experience in mixed Windows/Linux environments', 'Results-proven track record of exceeding goals and evidence of the ability to consistently make good decisions through a combination of analysis, experience and judgment', 'Experience deploying, monitoring, and maintaining data pipelines in production environments', 'To perform this job successfully, an individual must have intermediate knowledge of Microsoft Project, Word, Excel, Access, PowerPoint, Outlook, and Internet navigation and research'], 'Responsibilities': ['This role requires an enterprise mindset to build out robust, high-performance technology', 'Use a variety of programming languages and tools to develop, test, and maintain data pipelines within the Platform Reference Architecture', 'Working directly with management, product teams and practice personnel to understand their platform data requirements', 'Maintaining a positive work atmosphere by behaving and communicating in a manner that encourages productive interactions with customers, co-workers and supervisors', 'Developing and engaging with team members by creating a motivating work environment that recognizes, holds team members accountable, and rewards strong performance', 'Fostering an innovative, inclusive and diverse team environment, promoting positive team culture, encouraging collaboration and self-organization while delivering high quality solutions', 'Collaborating on an Agile team to design, develop, test, implement and support highly scalable data solutions', 'Collaborating with product teams and clients to deliver robust cloud-based data solutions that drive tax decisions and provide powerful experiences', 'Analyzing user feedback and activity and iterate to improve the services and user experience', 'Creating and implementing robust cloud-based data solutions that scale effectively, and provide powerful experiences for both internal teams and clients', 'Performing unit tests and conducting reviews with other team members to make sure solutions and code are rigorously designed, elegantly coded and effectively tuned for performance', 'Staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities and mentoring other members of the engineering community', 'Perform other duties as assigned', 'Requires supervisory responsibilities, including training employees, assigning work, and assuring quality throughout any deliverables', 'Occasional long periods of sitting while working at computer'], 'Benefits': ['For Oakland and San Jose, CA-based roles, the base salary hiring range for this position is $155,000-$185,000']}",Data engineer,en,15113200,4,,,
qIeZ_iz27YwAAAAAAAAAAA==,Wipro Limited,https://www.wipro.com/content/dam/nexus/en/wipro-logo-new-og-502x263.jpg,http://www.wipro.com,Computer Services,OPTnation,FULLTIME,Data Engineer,https://www.optnation.com/data-engineer-job-in-dallas-tx-view-jobid-29161,False,0.6901,Responsibilities Design data integrations and data quality framework using AWS Cloud technologies. Develop and maintain scalable data pipelines and ETL processes using Python. Write unit/integration tests contribute to engineering wiki and document work. SQL Performance & Tuning Implement processes to monitor data quality ensuring high availability and high accuracy of production data. Provide operational support for the data pipeline and perform data analysis required to troubleshoot data related issues and the resolution. Collaborate with analytics and business teams to build data models that feed business intelligence tools to foster data-driven decision making across the organization. Work closely with the business users product managers analysts and off-shore team (India) to develop strategy for long term data architecture and the development for the business solution. Requirements BS or MS degree in Computer Science or a related technical field 0-2 years of experience in the Information Technology field.,False,1677196800,2023-02-24T00:00:00.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=50&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=qIeZ_iz27YwAAAAAAAAAAA%3D%3D",,,"{'no_experience_required': False, 'required_experience_in_months': None, 'experience_mentioned': True, 'experience_preferred': False}","['python', 'AWS', 'ETL', 'Data modeling', 'MySQL']","{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': True, 'professional_certification_mentioned': False}",False,120000.0,140000.0,USD,YEAR,"{'Qualifications': ['Requirements BS or MS degree in Computer Science or a related technical field 0-2 years of experience in the Information Technology field'], 'Responsibilities': ['Responsibilities Design data integrations and data quality framework using AWS Cloud technologies', 'Develop and maintain scalable data pipelines and ETL processes using Python', 'Write unit/integration tests contribute to engineering wiki and document work', 'SQL Performance & Tuning Implement processes to monitor data quality ensuring high availability and high accuracy of production data', 'Provide operational support for the data pipeline and perform data analysis required to troubleshoot data related issues and the resolution', 'Collaborate with analytics and business teams to build data models that feed business intelligence tools to foster data-driven decision making across the organization', 'Work closely with the business users product managers analysts and off-shore team (India) to develop strategy for long term data architecture and the development for the business solution']}",Data engineer,en,15113200,4,,541511,Custom Computer Programming Services
6VJKKZ1oBBkAAAAAAAAAAA==,Randstad USA,,,,Monster,CONTRACTOR,Sr. Data Engineer,https://www.monster.com/job-openings/sr-data-engineer-dallas-tx--37e67443-4bdb-4d63-a605-9f6778fa8531,True,0.6571,"job summary:
• strong in real time & batch pipelines in big data technologies (i.e. Spark/Kafka/Cassandra/Hadoop/Hive/Elasticsearch)
• Proficient in RESTful Services, Java, Scala, Spring Boot/Play Framework, RDBMS, NoSql, Python
• Proficient in development of scalable cloud native microservices
• Proficient with Designing and building APIs

location: Dallas, Texas
job type: Contract
salary: $70 - 75 per hour
work hours: 8am to 4pm
education: No Degree Required

responsibilities:

strong in real time & batch pipelines in big data technologies
• (i.e. Spark/Kafka/Cassandra/Hadoop/Hive/Elasticsearch)

Proficient in RESTful Services, Java, Scala, Spring Boot/Play Framework, RDBMS, NoSql, Python
• Proficient in development of scalable cloud native microservices
• Proficient with Designing and building APIs

Azure and or GCP exposure and experience

qualifications:
• Experience level: Experienced
• Minimum 7 years of experience
• Education: No Degree Required

skills:
• Hadoop (7 years of experience is required)
• Java (7 years of experience is required)

Equal Opportunity Employer: Race, Color, Religion, Sex, Sexual Orientation, Gender Identity, National Origin, Age, Genetic Information, Disability, Protected Veteran Status, or any other legally protected group status.

At Randstad, we welcome people of all abilities and want to ensure that our hiring and interview process meets the needs of all applicants. If you require a reasonable accommodation to make your application or interview experience a great one, please contact HRsupport@randstadusa.com.

Pay offered to a successful candidate will be based on several factors including the candidate's education, work experience, work location, specific job duties, certifications, etc. In addition, Randstad offers a comprehensive benefits package, including health, an incentive and recognition program, and 401K contribution (all benefits are based on eligibility).

For certain assignments, Covid-19 vaccination and/or testing may be required by Randstad's client or applicable federal mandate, subject to approved medical or religious accommodations. Carefully review the job posting for details on vaccine/testing requirements or ask your Randstad representative for more information.

About the Company:
Randstad USA

Randstad was founded in 1960 by Frits Goldschmeding. We've never let go of his passion or the values that he established. By staying true to those fundamentals, we've expanded to represent more than 90 percent of the HR services market.

We provide outsourcing, staffing, consulting and workforce solutions within the areas of engineering, accounting and finance, healthcare, human resources, IT, legal, life sciences, manufacturing and logistics, office and administration and sales and marketing. We can’t wait to tell you all about it.

Our mission is to be a world leader in matching demand for, and supply of, labor and HR services. We believe in the value of work as a unifying force that shapes society for the better. We live by the core values established early in our company's history: to know, serve and trust, striving for perfection and simultaneous promotion of all interests.

Company Size:
10,000 employees or more

Industry:
Staffing/Employment Agencies

Founded:
1960

Website:
https://www.randstadusa.com/",False,1690416000,2023-07-27T00:00:00.000Z,Dallas,TX,US,32.776665,-96.79699,"['retirement_savings', 'health_insurance', 'dental_coverage']","https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=50&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=6VJKKZ1oBBkAAAAAAAAAAA%3D%3D",,,"{'no_experience_required': False, 'required_experience_in_months': 84, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': False, 'degree_preferred': False, 'professional_certification_mentioned': True}",False,,,,,"{'Qualifications': ['Proficient in RESTful Services, Java, Scala, Spring Boot/Play Framework, RDBMS, NoSql, Python', 'Proficient in development of scalable cloud native microservices', 'Proficient with Designing and building APIs', 'Azure and or GCP exposure and experience', 'Experience level: Experienced', 'Minimum 7 years of experience', 'Hadoop (7 years of experience is required)'], 'Responsibilities': ['work hours: 8am to 4pm'], 'Benefits': ['salary: $70 - 75 per hour', ""Pay offered to a successful candidate will be based on several factors including the candidate's education, work experience, work location, specific job duties, certifications, etc"", 'In addition, Randstad offers a comprehensive benefits package, including health, an incentive and recognition program, and 401K contribution (all benefits are based on eligibility)']}",Data engineer,en,15113200,4,,,
Hxm5v2wJMHUAAAAAAAAAAA==,Cognizant Technology Solutions,https://www.cognizant.com/content/dam/cognizant/en_us/dotcom/logos/COG-Logo-2022.svg,http://www.cognizant.com,Computer Services,Ladders,FULLTIME,Senior Data Engineer- Databricks,https://www.theladders.com/job/senior-data-engineer-databricks-cognizant-dallas-tx_64139874,False,0.5671,"Senior Data Engineer- DataBricks

Location: Dallas, TX (Hybrid/Onsite)

Cognizant (NASDAQ: CTSH) is a leading provider of information technology, consulting, and business process outsourcing services, dedicated to helping the world's leading companies build stronger businesses. Headquartered in Teaneck, New Jersey (U.S.). Cognizant is a member of the NASDAQ-100, the S&P 500, the Forbes Global 1000, and the Fortune 500 and we are among the top performing and fastest growing companies in the world.

Please note, this role is not able to offer visa transfer or sponsorship now or in the future

Practice - AIA - Artificial Intelligence and Analytics

Qualification:
• Bachelors in science , engineering or equivalent
• 10+ years of experience building, deploying, and designing data solutions: ETL, data warehousing, or Big Data.
• 3-6 Years of experience working with DataBricks.
• Experience working with Azure Data stack; Data Lake, Data factory, DataBricks, Synapse, etc.

Responsibility:
• Provide input to cloud engineer for the design and implementation of data management and/or architecture solutions.
• Partner with cloud engineer and ML engineer to develop and evolve the concept of data ops.
• Design implement and deploy data loaders to load data into the Engineering Sandbox.
• Assist in pulling filtering tagging joining parsing and normalizing data sets for use.
• Work with the analytics translator data quality analyst and IT to resolve data quality issues.
• Experience in designing and implementing large scale data loading manipulation processing analysis and exploration solutions.
• Deep technical expertise with pulling and massaging data understanding of first/third party data.
• Experience in R Python Modeling Big Data etc. with focus on AI/ML techniques
• Advanced SQL skills and understanding of data management principles and processes.

Must Have Skills
• Databricks

Good To Have Skills
• PySpark
• Azure Databricks
• Azure Data Factory
• eCommerce

Salary and Other Compensation:

This position is also eligible for Cognizant’s discretionary annual incentive program, based on performance and subject to the terms of Cognizant’s applicable plans.

Benefits: Cognizant offers the following benefits for this position, subject to applicable eligibility requirements:
• · Medical/Dental/Vision/Life Insurance
• · Paid holidays plus Paid Time Off
• · 401(k) plan and contributions
• · Long-term/Short-term Disability
• · Paid Parental Leave
• · Employee Stock Purchase Plan

Disclaimer: The salary, other compensation, and benefits information is accurate as of the date of this posting. Cognizant reserves the right to modify this information at any time, subject to applicable law.

Cognizant is an Equal Opportunity Employer M/F/D/V. Cognizant is committed to ensuring that all current and prospective associates are afforded equal opportunities and treatment and a work environment free of harassment.

Cognizant is recognized as a Military Friendly Employer and is a coalition member of the Veteran Jobs Mission. Our Cognizant Veterans Network assists Veterans in building and growing a career at Cognizant that allows them to leverage the leadership, loyalty, integrity, and commitment to excellence instilled in them through participation in military service.

#LI-IR1 #CB #Ind123

Employee Status : Full Time Employee

Shift : Day Job

Travel : No

Job Posting : Jun 30 2023

About Cognizant

Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 185 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead wiApplicants may be required to attend interviews in person or by video conference. In addition, candidates may be required to present their current state or government issued ID during each interview.

Cognizant is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law.

If you have a disability that requires a reasonable accommodation to search for a job opening or submit an application, with your request and contact information.

Be aware of fraudulent offers!!

Cognizant does not charge anything at any stage of the recruitment process and has not authorized any agencies or partners or individuals to charge any fee at any stage of the recruitment process. In case you receive offers that you suspect are fraudulent,By this, we want to avoid and prevent unaware prospective candidates from falling victim to these scams.

Kindly note that any payment made to either individuals or agencies for gaining employment at Cognizant, will be at your own risk & volition and Cognizant cannot be held accountable for the same.
Get notified for similar jobs

Sign up to receive job alerts

Enter Email address

SUBMIT",False,1688352222,2023-07-03T02:43:42.000Z,Dallas,TX,US,32.776665,-96.79699,"['dental_coverage', 'retirement_savings', 'paid_time_off', 'health_insurance']","https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=50&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=Hxm5v2wJMHUAAAAAAAAAAA%3D%3D",,,"{'no_experience_required': False, 'required_experience_in_months': 120, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,100000.0,150000.0,USD,YEAR,"{'Qualifications': ['Bachelors in science , engineering or equivalent', '10+ years of experience building, deploying, and designing data solutions: ETL, data warehousing, or Big Data', '3-6 Years of experience working with DataBricks', 'Experience working with Azure Data stack; Data Lake, Data factory, DataBricks, Synapse, etc', 'PySpark', 'eCommerce'], 'Responsibilities': ['Provide input to cloud engineer for the design and implementation of data management and/or architecture solutions', 'Partner with cloud engineer and ML engineer to develop and evolve the concept of data ops', 'Design implement and deploy data loaders to load data into the Engineering Sandbox', 'Assist in pulling filtering tagging joining parsing and normalizing data sets for use', 'Work with the analytics translator data quality analyst and IT to resolve data quality issues', 'Experience in designing and implementing large scale data loading manipulation processing analysis and exploration solutions', 'Deep technical expertise with pulling and massaging data understanding of first/third party data', 'Advanced SQL skills and understanding of data management principles and processes'], 'Benefits': ['This position is also eligible for Cognizant’s discretionary annual incentive program, based on performance and subject to the terms of Cognizant’s applicable plans', 'Medical/Dental/Vision/Life Insurance', 'Paid holidays plus Paid Time Off', '401(k) plan and contributions', 'Long-term/Short-term Disability', 'Paid Parental Leave', 'Employee Stock Purchase Plan', 'Disclaimer: The salary, other compensation, and benefits information is accurate as of the date of this posting']}",Data engineer,en,15113200,4,,541511,Custom Computer Programming Services
0uC1tfLfQNoAAAAAAAAAAA==,Infinity Consulting Solutions,https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTuUR1-jQ4Y1CJaEdnrJ5J24Ybu94wWwoqmUKpK&s=0,http://www.infinity-cs.com,,Lensa,FULLTIME,Data Engineer,https://lensa.com/data-engineer-jobs/dallas/jd/b8d9c2125bf7388601b5a0f327748a49,False,0.4713,"ICS, a Korn Ferry company, is looking for a Data Engineer, who is a SQL and SSIS expert, to join our growing Financial Services' client's team in the Dallas/Fort Worth, TX area! This position will sit on the Data Services Team and be responsible for sourcing data and loading it into the enterprise data warehouse across multiple projects in the organization. The ideal candidate will be a self-starter and a team player!

What You'll Do:
• Communicating with Technology teams and business owners to develop, test, and implement reports for internal and external users.
• The developer will be responsible for the design, development, and deployment of data extracts, transformations, and loads.
• ETL development will utilize the Microsoft SQL platform, specifically SQL Server Integration Services (SSIS)
• Experience with various reporting methods, including SSRS.
• Develop reports based on defined requirements.
• Responsible for analyzing the business requirements for data file requests, designing, developing, and deploying fully automated ETL jobs to produce data files
• Write advanced SQL statements to retrieve data from tables and stored procedures
• Use known education principles and stay up-to-date on new reporting methods and techniques.
• Partner with internal stakeholders and liaise with experts regarding instructional design

Skills Required:
• Experience with MS SQL Server and T-SQL code development
• Experience with ETL - SSIS
• Experience in building stored procedures, functions, merges and Ad Hoc scripts
• Experience with data management and understanding of data structures, database design
• Ability to collaborate and communicate effectively across functional groups
• Ability to independently perform database development, testing and implementation with little supervision
• Ability to effectively communicate technical issues and resolve problems
• Experience with C# or Python a plus
• Visual studio to create SSIS package, stored procedure, code review

TITLE: Data Engineer

Client Industry: Financial Services, Industry

Location: Remote in the Dallas/Fort Worth area

Pay Rate: $50-60/hour",False,1689437824,2023-07-15T16:17:04.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=50&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=0uC1tfLfQNoAAAAAAAAAAA%3D%3D",2023-08-14T16:17:04.000Z,1692029824.0,"{'no_experience_required': False, 'required_experience_in_months': None, 'experience_mentioned': True, 'experience_preferred': True}","['Reading Comprehension', 'Active Listening', 'Writing', 'Speaking', 'Critical Thinking', 'Active Learning', 'Monitoring', 'Social Perceptiveness', 'Coordination', 'Complex Problem Solving', 'Programming', 'Judgment and Decision Making', 'Systems Analysis', 'Systems Evaluation']","{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': False, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['Experience with MS SQL Server and T-SQL code development', 'Experience with ETL - SSIS', 'Experience in building stored procedures, functions, merges and Ad Hoc scripts', 'Experience with data management and understanding of data structures, database design', 'Ability to collaborate and communicate effectively across functional groups', 'Ability to independently perform database development, testing and implementation with little supervision', 'Ability to effectively communicate technical issues and resolve problems', 'Visual studio to create SSIS package, stored procedure, code review'], 'Responsibilities': ['This position will sit on the Data Services Team and be responsible for sourcing data and loading it into the enterprise data warehouse across multiple projects in the organization', 'The ideal candidate will be a self-starter and a team player!', 'Communicating with Technology teams and business owners to develop, test, and implement reports for internal and external users', 'The developer will be responsible for the design, development, and deployment of data extracts, transformations, and loads', 'ETL development will utilize the Microsoft SQL platform, specifically SQL Server Integration Services (SSIS)', 'Experience with various reporting methods, including SSRS', 'Develop reports based on defined requirements', 'Responsible for analyzing the business requirements for data file requests, designing, developing, and deploying fully automated ETL jobs to produce data files', 'Write advanced SQL statements to retrieve data from tables and stored procedures', 'Use known education principles and stay up-to-date on new reporting methods and techniques', 'Partner with internal stakeholders and liaise with experts regarding instructional design'], 'Benefits': ['Pay Rate: $50-60/hour']}",Data engineer,en,15113200,4,['15-1199.06 Database Architects'],,
hmPiuV0MhssAAAAAAAAAAA==,Salesforce,https://www.sfdcstatic.com/common/assets/img/logo-company-large.png,http://www.salesforce.com,Information,"Dallas, TX - Geebo",FULLTIME,"Associate Data Engineer, Enterprise Data Warehouse at Salesforce in Dallas, TX",https://dallas-tx.geebo.com/jobs-online/view/id/1051796261-associate-data-engineer-enterprise-/,True,0.4366,"Job Details Business Technology blazes the trail of enterprise IT. Built on the foundation of our core values, we own more than the traditional IT components with a heavy focus on working closely with our business partners for amazing outcomes. Our goal is to deliver technology that is centered around our business and our collective success. We oversee technology strategy, Salesforce on Salesforce, customer and partner enablement, applications engineering, infrastructure, collaboration, enterprise operations, architecture, and program enablement. We own the world's foremost Salesforce implementation and enable our global Ohana to do their best work by leveraging our platform. The IT Enterprise Data Warehouse (EDW) function is responsible for the delivery of operational reporting and performance metrics to various business domains including Sales and Sales Operations, Marketing, Finance, Customer success and Employee Success. This platform also includes management of a Big Data Hadoop platform to store unstructured application log data that is generated by the Salesforce product offerings, this data is predominately used by the data science teams. Team also leads all aspects of rolling out Salesforce's analytics tool Wave to internal business partners. The Salesforce IT EDW team is looking for an experienced BI designer who will work on designing, developing and implementing new functionality and increasing test coverage of systems that support various internal business processes at Salesforce.com. This requires the candidate to be able to learn quickly, work in a fast paced environment, and have the ability to communicate well with technical and non-technical personnel.
Responsibilities:
? Experience in designing and development of analytical solutions including Salesforce analytics solution - Wave and Tableau ? Contribute towards designing data models, ETL mappings and associated objects of analytical solutions. ? Review solution design with Lead members and ensure that the defined EDW standards and framework are followed. ? Review and validate logical and physical design to ensure alignment with the defined solution architecture. ? Create/review technical documentation for all new and modified objects. ? Ensure quality assurance plans and cases are comprehensive to validate the solution thoroughly. ? Follow standard practises for QA in the organization ? Support QA, UAT and performance testing phases of the development cycle. ? Understand and incorporate required security framework in the developed data model and ETL objects. ? Define standards and procedures; refine methods and techniques for data extraction, transformation and loading (ETL) both in batch and near real time modes. ? Evaluate, determine root cause and resolve production issues. ? Work closely with other IT development groups to deliver coordinated software solutions Required Skills:
? 1+year of experience working as a BI technical resource in a customer-focused IT EDW team ? 2+years of experience in the data warehousing domain as a technical resource ? Deep understanding of data warehousing concepts, relational star-schema database designs and big data platforms and associated tools. ?Basic understanding and hands-on experience of Informatica 9.x, Tableau and snowflake system components, internal processes and architecture. ? Good knowledge of SQL and relational database models. ? Hands-on experience creating Unix shell scripts ? Data visualization tool experience like Tableau ? Good understanding of data modeling ? Basic working experience in an agile environment ? Excellent team player able to work with virtual and global across functional teams at all levels. ? Self-starter, highly motivated, able to shift directions quickly when priorities change, think through problems to come up with innovative solutions and deliver against tight deadlines. ? Excellent spoken and written communication as well as receptive listening skills, with ability to present complex ideas in a clear, concise fashion towards technical and nontechnical audiences. ? Excellent interpersonal skills will be needed in order to build strong relationships that will be critical for success of this role. Desired Skills:
? Salesforce, Data Warehousing, customer success and Data Analysis ? Working experience on Data science or Python scripting is a plus ? Working experience of snowflake ? Excellent analytical, problem solving and debugging skills, with strong ability to quickly learn and solve problems in order to effectively develop technical solutions to their requirements
Salary Range:
$80K -- $100K
Minimum Qualification
Data Science & Machine LearningEstimated Salary: $20 to $28 per hour based on qualifications.",False,1690502400,2023-07-28T00:00:00.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=50&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=hmPiuV0MhssAAAAAAAAAAA%3D%3D",2023-08-04T00:00:00.000Z,1691107200.0,"{'no_experience_required': False, 'required_experience_in_months': 24, 'experience_mentioned': True, 'experience_preferred': True}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': False, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,20.0,28.0,USD,HOUR,"{'Qualifications': ['This requires the candidate to be able to learn quickly, work in a fast paced environment, and have the ability to communicate well with technical and non-technical personnel', '1+year of experience working as a BI technical resource in a customer-focused IT EDW team ?', '2+years of experience in the data warehousing domain as a technical resource ?', 'Deep understanding of data warehousing concepts, relational star-schema database designs and big data platforms and associated tools', 'Basic understanding and hands-on experience of Informatica 9.x, Tableau and snowflake system components, internal processes and architecture', 'Good knowledge of SQL and relational database models', 'Hands-on experience creating Unix shell scripts ?', 'Data visualization tool experience like Tableau ?', 'Good understanding of data modeling ?', 'Basic working experience in an agile environment ?', 'Excellent team player able to work with virtual and global across functional teams at all levels', 'Self-starter, highly motivated, able to shift directions quickly when priorities change, think through problems to come up with innovative solutions and deliver against tight deadlines', 'Excellent spoken and written communication as well as receptive listening skills, with ability to present complex ideas in a clear, concise fashion towards technical and nontechnical audiences', 'Excellent interpersonal skills will be needed in order to build strong relationships that will be critical for success of this role', 'Salesforce, Data Warehousing, customer success and Data Analysis ?', 'Excellent analytical, problem solving and debugging skills, with strong ability to quickly learn and solve problems in order to effectively develop technical solutions to their requirements', 'Data Science & Machine LearningEstimated Salary: $20 to $28 per hour based on qualifications'], 'Responsibilities': ['Contribute towards designing data models, ETL mappings and associated objects of analytical solutions', 'Review solution design with Lead members and ensure that the defined EDW standards and framework are followed', 'Review and validate logical and physical design to ensure alignment with the defined solution architecture', 'Create/review technical documentation for all new and modified objects', 'Ensure quality assurance plans and cases are comprehensive to validate the solution thoroughly', 'Follow standard practises for QA in the organization ?', 'Support QA, UAT and performance testing phases of the development cycle', 'Understand and incorporate required security framework in the developed data model and ETL objects', 'Define standards and procedures; refine methods and techniques for data extraction, transformation and loading (ETL) both in batch and near real time modes', 'Evaluate, determine root cause and resolve production issues', 'Work closely with other IT development groups to deliver coordinated software solutions Required Skills:'], 'Benefits': ['$80K -- $100K']}",Data engineer,en,15113200,4,,511210,Software Publishers
F0BzDvq8V2EAAAAAAAAAAA==,H-E-B,https://www.heb.com/img/header/logo.png,http://www.heb.com,Retail,ZipRecruiter,FULLTIME,"Senior Data Engineer, Dallas, Austin, or San Antonio, TX","https://www.ziprecruiter.com/c/H-E-B/Job/Senior-Data-Engineer,-Dallas,-Austin,-or-San-Antonio,-TX/-in-Dallas,TX?jid=1e6c47e6fd30e3b3",False,0.6602,"Overview

H-E-B is one of the largest, independently owned food retailers in the nation operating over 420+ stores throughout Texas and Mexico, with annual sales generating over $34 billion. Described by industry experts as a daring innovator and smart competitor, H-E-B has led the way with creative new concepts, outstanding service and a commitment to diversity in our workforce, workplace and marketplace. H-E-B offers a wealth of career opportunities to our 145,000+ Partners (employees), competitive compensation and benefits program and comprehensive training that lead to successful careers.
Responsibilities

Since H-E-B Digital Technology's inception, we've been investing heavily in our customers' digital experience, reinventing how they find inspiration from food, how they make food decisions, and how they ultimately get food into their homes. This is an exciting time to join H-E-B Digital--we're using the best available technologies to deliver modern, engaging, reliable, and scalable experiences to meet the needs of our growing audience. If you enjoy taking on new challenges, working in a rapidly changing environment, learning new skills, and applying it all to solve large and impactful business problems, we want you as part of our team.Our team is made up of data engineers with various levels of experience. The primary focus is current customer data which our team consolidates, cleanses, formats and validates for various stakeholders within our Digital team. As a Data Engineer you'll:Design and build a modern data warehouse in the cloud

Enhance data collection procedures to build analytic systems.

Work as an Agile partner and participate in back log refinement, sprint planning, review, and retrospective.

Coach and mentor junior engineers in engineering techniques, processes, and new technologies; enable others to succeed.

Contribute to overall system design, architecture, security, scalability, reliability, and performance of applications.Support the build and deployment pipeline and when necessary, both diagnose and solve production support issues.

Work with Product, Design, and QA to deliver world-class digital experiences.

Get the opportunity to stay ahead of new technologies with an eye to evaluating and potentially incorporating them into your team's architecture.

Apply understanding to help improve the cloud infrastructure that powers our high-performance, consumer-scale site and mobile apps.Who You Are:3-5+ years of experience with ETL, Data Modeling, Data Warehousing, and working with large-scale datasets (enterprise experience is a plus!)

3-5+ years of hands-on experience in multiple modern programming languages such as Python or Java

2+ years of experience leveraging DevOps principals such as CI/CD and using tools like Git, Jenkins, etc.

Strong working knowledge of Data Engineering and associated tools and technologies like Apache, Spark, Databricks, Python, SQL, and data lake concepts.

Experience with Argo Informatica

Working experience with AWS services such as Lambda, RDS, ECS, DynamoDB, API Gateway, S3, etc.

Bachelor's degree in Computer Engineering, Computer Science or related discipline, Master's Degree preferred

An equivalent combination of education and experience may be accepted as a satisfactory substitute for the specific education and experience listed above.

It's a Plus if you have:

Experience working with other public cloud technologies AWS, GCP

Hands on experience with data virtualization technologies: CIS (Tibco), Denodo, or SQL 2019 Virtualization

Experience building test automation to ensure data quality and accuracy

Proficient in data modeling (specifically RDS, PostgreSQL, Oracle)

DATA3232
Employment Type: FULL_TIME",False,1627369200,2021-07-27T07:00:00.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=50&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=F0BzDvq8V2EAAAAAAAAAAA%3D%3D",2023-08-26T00:00:00.000Z,1693008000.0,"{'no_experience_required': False, 'required_experience_in_months': 36, 'experience_mentioned': True, 'experience_preferred': True}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': True, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['3-5+ years of hands-on experience in multiple modern programming languages such as Python or Java', '2+ years of experience leveraging DevOps principals such as CI/CD and using tools like Git, Jenkins, etc', 'Strong working knowledge of Data Engineering and associated tools and technologies like Apache, Spark, Databricks, Python, SQL, and data lake concepts', 'Experience with Argo Informatica', 'Working experience with AWS services such as Lambda, RDS, ECS, DynamoDB, API Gateway, S3, etc', 'An equivalent combination of education and experience may be accepted as a satisfactory substitute for the specific education and experience listed above', 'Experience working with other public cloud technologies AWS, GCP', 'Hands on experience with data virtualization technologies: CIS (Tibco), Denodo, or SQL 2019 Virtualization', 'Experience building test automation to ensure data quality and accuracy', 'Proficient in data modeling (specifically RDS, PostgreSQL, Oracle)'], 'Responsibilities': [""As a Data Engineer you'll:Design and build a modern data warehouse in the cloud"", 'Enhance data collection procedures to build analytic systems', 'Work as an Agile partner and participate in back log refinement, sprint planning, review, and retrospective', 'Coach and mentor junior engineers in engineering techniques, processes, and new technologies; enable others to succeed', 'Contribute to overall system design, architecture, security, scalability, reliability, and performance of applications', 'Support the build and deployment pipeline and when necessary, both diagnose and solve production support issues', 'Work with Product, Design, and QA to deliver world-class digital experiences', ""Get the opportunity to stay ahead of new technologies with an eye to evaluating and potentially incorporating them into your team's architecture"", 'Apply understanding to help improve the cloud infrastructure that powers our high-performance, consumer-scale site and mobile apps']}",Data engineer,en,15113200,4,['15-1199.06: Database Architects'],445110,Supermarkets and Other Grocery (except Convenience) Stores
GZboUoqtmI4AAAAAAAAAAA==,Dice,https://s24.q4cdn.com/133441296/files/images/brands/dice.png,,Information,LinkedIn,FULLTIME,Big Data Engineer/Data Engineer(Only W2 or Self Corp.),https://www.linkedin.com/jobs/view/big-data-engineer-data-engineer-only-w2-or-self-corp-at-dice-3674337930,False,0.5631,"Dice is the leading career destination for tech experts at every stage of their careers. Our client, Newt Global, is seeking the following. Apply via Dice today!

Big Data Engineer /Data Engineer (Only W2 or Self Corp.)

Location: Dallas, TX(Hybrid)

12 Months+

Required:

8 plus year's experience

Expert on PySpark

Expert in Python and Spark

Nice to have Banking experience.

Big Data Engineer/Data Engineer(Only W2 or Self Corp.)",False,1690213856,2023-07-24T15:50:56.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=50&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=GZboUoqtmI4AAAAAAAAAAA%3D%3D",2023-08-23T15:50:56.000Z,1692805856.0,"{'no_experience_required': False, 'required_experience_in_months': None, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': True, 'degree_mentioned': False, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': [""8 plus year's experience"", 'Nice to have Banking experience']}",Engineer,en,15113200,4,,519130,Internet Publishing and Broadcasting and Web Search Portals
ziqGUCDHBPwAAAAAAAAAAA==,CoreLogic,https://www.corelogic.com/wp-content/uploads/sites/4/2021/06/Featured_FB_OG-corelogic-logo_1200x1200.png,http://www.corelogic.com,Information,Talent.com,FULLTIME,Senior data engineer,https://www.talent.com/view?id=8e0ac49a262d,False,0.4889,"Description

CoreLogic is seeking a Senior Data Engineer who is passionate about all things data and has the desire to turn data processing into a competitive advantage.

Employees in this role need to be well versed with innovation and trends in the world of data processing which can include data management, data quality and data curation.

If you like being at the forefront and for your work to be impactful, this is the position you want. This is a highly visible role with direct revenue impact as data is our product.

This role also provides a tremendous opportunity to learn while making an impactful contribution to the success of the company.

Job Responsibilities :

Process complex data sets, leverage technologies used to process these disparate data sets and understand the correlation as well as patterns that exist between the data sets.

Work closely with other teams to develop solutions to meet business requirements, perform assessments, POC’s and establish an execution or development plan.

Forecast technical challenges and develop implementation strategies.

Identify enabling technologies and develop solutions based on identified technologies as required.

Prepare and present white papers and proposals.

Employ lateral thinking to develop innovative solutions to meet business needs.

Communicate complex technical ideas in a straightforward and compelling way.

Job Qualifications :

8 years of relevant IT experience and 3 years of experience with Java coding

Bachelor's degree in Engineering, Computer Science, Information Technology, related discipline or significant industry experience

Excellent coding skills with expertise in Java, REST APIs, SQL, and micro-services

Experience with Apache Spark / Beam, Google Cloud Dataflow, MySQL, Big Query, Airflow, Kafka, Kubernetes, and Anthos

Experience with development & operations in cloud native technologies (GCP preferred)

Broad knowledge of open-source libraries & packages

Well versed with big data concepts and data engineering principles or techniques

Excellent communication and organization skills

Must have a go-getter attitude and a willingness to pick up new technologies and programming languages

Must be a team player with a creative mindset who's always looking for novel solutions to challenging problems and open to learning as well as sharing knowledge with others

Preferred Qualifications :

Working knowledge of Python, DBT, React.JS & Angular.JS

Professional certifications

Knowledge of Cloud architecture, networking and protocols

Analytical mindset and good problem-solving skills

Good organizational skills

Someone who enjoys having fun and maintaining work life balance while working on exciting projects

Someone who's interested in working at a company that believes in mandatory development of its staff and has a culture of promoting from within

Annual Pay Range : 97,200 - 130,000 USD

97,200 - 130,000 USD

CoreLogic benefits information can be found here : . Qualifications, locations and experience of the individual ultimately selected for the position may impact the final actual offered compensation, which may vary from any posted range.

CoreLogic's Diversity Commitment :

CoreLogic is fully committed to employing a diverse workforce and creating an inclusive work environment that embraces everyone’s unique contributions, experiences and values.

We offer an empowered work environment that encourages creativity, initiative and professional growth and provides a competitive salary and benefits package.

We are better together when we support and recognize our differences.

EOE AA M / F / Veteran / Disability :

CoreLogic is an Equal Opportunity / Affirmative Action employer committed to attracting and retaining the best-qualified people available, without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, disability or status as a veteran of the Armed Forces, or any other basis protected by federal, state or local law.

CoreLogic maintains a Drug-Free Workplace.

Please apply on our website for consideration.

Privacy Policy -

By providing your telephone number, you agree to receive automated (SMS) text messages at that number from CoreLogic regarding all matters related to your application and, if you are hired, your employment and company business.

Message & data rates may apply. You can opt out at any time by responding STOP or UNSUBSCRIBING and will automatically be opted out company-wide.

Connect with us on social media! Click on the quicklinks below to find out more about our company and associates.

Last updated : 2023-07-27",False,1690416000,2023-07-27T00:00:00.000Z,Dallas,TX,US,32.776665,-96.79699,['retirement_savings'],"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=50&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=ziqGUCDHBPwAAAAAAAAAAA%3D%3D",2023-08-31T00:00:00.000Z,1693440000.0,"{'no_experience_required': False, 'required_experience_in_months': 96, 'experience_mentioned': True, 'experience_preferred': True}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': True, 'degree_mentioned': True, 'degree_preferred': True, 'professional_certification_mentioned': True}",False,,,,,"{'Qualifications': ['8 years of relevant IT experience and 3 years of experience with Java coding', ""Bachelor's degree in Engineering, Computer Science, Information Technology, related discipline or significant industry experience"", 'Excellent coding skills with expertise in Java, REST APIs, SQL, and micro-services', 'Experience with Apache Spark / Beam, Google Cloud Dataflow, MySQL, Big Query, Airflow, Kafka, Kubernetes, and Anthos', 'Broad knowledge of open-source libraries & packages', 'Well versed with big data concepts and data engineering principles or techniques', 'Excellent communication and organization skills', 'Must have a go-getter attitude and a willingness to pick up new technologies and programming languages', ""Must be a team player with a creative mindset who's always looking for novel solutions to challenging problems and open to learning as well as sharing knowledge with others"", 'Working knowledge of Python, DBT, React.JS & Angular.JS', 'Professional certifications', 'Knowledge of Cloud architecture, networking and protocols', 'Analytical mindset and good problem-solving skills', 'Good organizational skills', 'Someone who enjoys having fun and maintaining work life balance while working on exciting projects', ""Someone who's interested in working at a company that believes in mandatory development of its staff and has a culture of promoting from within""], 'Responsibilities': ['Process complex data sets, leverage technologies used to process these disparate data sets and understand the correlation as well as patterns that exist between the data sets', 'Work closely with other teams to develop solutions to meet business requirements, perform assessments, POC’s and establish an execution or development plan', 'Forecast technical challenges and develop implementation strategies', 'Identify enabling technologies and develop solutions based on identified technologies as required', 'Prepare and present white papers and proposals', 'Employ lateral thinking to develop innovative solutions to meet business needs', 'Communicate complex technical ideas in a straightforward and compelling way'], 'Benefits': ['Annual Pay Range : 97,200 - 130,000 USD', 'CoreLogic benefits information can be found here : . Qualifications, locations and experience of the individual ultimately selected for the position may impact the final actual offered compensation, which may vary from any posted range', 'We offer an empowered work environment that encourages creativity, initiative and professional growth and provides a competitive salary and benefits package']}",Data engineer,en,15113200,4,['15-1243.00'],518210,"Data Processing, Hosting, and Related Services"
pB9FEDB1j4sAAAAAAAAAAA==,"IT Engagements,Inc.",,,,Glassdoor,FULLTIME,Sr Cloud Data Engineer,"https://www.glassdoor.com/job-listing/sr-cloud-data-engineer-it-engagements-inc-JV_IC1139977_KO0,22_KE23,41.htm?jl=1008579705781",True,0.5566,"Greeting from IT Engagements…!

IT Engagements is a global staff augmentation firm providing a wide range of talent on-demand and total workforce solutions. We have an immediate opening for the below position with our premium clients.

Job:- Sr Cloud Data Engineer

Location:- McLean VA or Dallas, TX (Onsite)
Duration:- 6+ Months Contract to hire

Exp: 8 years+

Job Description

Must Haves:
• Building data lake platform in AWS (Glue, DynamoDB S3, EMR)
• Python
• Scala
• Understand data engineering, data governance, data lineage
• Linux Shell Scripting

Really Nice to Have:
• Snowflake
• Data warehousing
• Kubernetes
• Hadoop infrastructure

Requirements:
• Experience with Big Data technologies such as Hadoop/Hive/Spark specific to AWS related services is a plus.
• Expertise in ETL optimization, designing, coding, and tuning big data processes using Apache Spark or similar technologies.
• Sound knowledge of distributed systems and data architecture - design and implement batch and stream data processing pipelines, knows how to optimize the distribution, partitioning, and MPP of high-level data structures.
• 5+ years of work experience with building Data Pipelines, Data Processing, Data Modeling, and Data Architecture.
• Experience operating very large data warehouses or data lakes. (Snowflake, etc)
• Excellent skills in writing and optimizing SQL.
• Knowledge of Engineering and Operational Excellence using standard methodologies.
• Knowledge of IT, service-oriented architectures, software development life cycles, or information security platforms and applications.
• Minimum 5+ years of experience in software development.
• 3+ years of related industry experience in an enterprise environment.
• 5+ years of data engineering experience.
• Scala / Python, pySpark(Boto, Boto3, etc.)/ Spark experience.
• Delta lake, delta table and lakehouse architecture
• Datewarehouse Experience (Snowflake)
• Experience with lambda, EMR, SQS, DynamoDB, Glue, Stepfunctions, etc.
• Linux and shell scripting.

Knowledge of:
• Kubernetes.
• Formal design patterns and industry best-practices.
• 2+ years of experience with requirements, design, implementation, integration, and testing for data and analytics integration.
• 2+ years of experience across a variety of technologies such databases, directory services, application servers, network infrastructures, Linux operating systems, and an understanding of fundamental security and data flows within these components.
• Excellent verbal and written communication skills.
• Self-motivated, driven, and creative individual.
• Scaling systems and microservices.
• Familiarity with CI/CD processes
• Code coverage analysis / static analysis tools.
• Agile programming processes and methodologies such as Scrum.
• Scheduling tools like Autosys , ControlM.
• Informatica IICS , Talend

Thankyou

Divya Kumari

Technical Recruiter

divya(at)itengagements(dot)com

Job Types: Full-time, Contract

Pay: From $65.00 per hour

Experience level:
• 8 years

Schedule:
• 8 hour shift

Experience:
• Informatica: 1 year (Preferred)
• SQL: 1 year (Preferred)
• Data warehouse: 1 year (Preferred)

Work Location: On the road

Speak with the employer
+91 7864080647",False,1688947200,2023-07-10T00:00:00.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=50&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=pB9FEDB1j4sAAAAAAAAAAA%3D%3D",,,"{'no_experience_required': False, 'required_experience_in_months': 60, 'experience_mentioned': True, 'experience_preferred': True}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['Building data lake platform in AWS (Glue, DynamoDB S3, EMR)', 'Understand data engineering, data governance, data lineage', 'Linux Shell Scripting', 'Data warehousing', 'Kubernetes', 'Expertise in ETL optimization, designing, coding, and tuning big data processes using Apache Spark or similar technologies', 'Sound knowledge of distributed systems and data architecture - design and implement batch and stream data processing pipelines, knows how to optimize the distribution, partitioning, and MPP of high-level data structures', '5+ years of work experience with building Data Pipelines, Data Processing, Data Modeling, and Data Architecture', 'Experience operating very large data warehouses or data lakes', 'Knowledge of Engineering and Operational Excellence using standard methodologies', 'Knowledge of IT, service-oriented architectures, software development life cycles, or information security platforms and applications', 'Minimum 5+ years of experience in software development', '3+ years of related industry experience in an enterprise environment', 'Scala / Python, pySpark(Boto, Boto3, etc.)/ Spark experience', 'Experience with lambda, EMR, SQS, DynamoDB, Glue, Stepfunctions, etc', 'Formal design patterns and industry best-practices', '2+ years of experience with requirements, design, implementation, integration, and testing for data and analytics integration', '2+ years of experience across a variety of technologies such databases, directory services, application servers, network infrastructures, Linux operating systems, and an understanding of fundamental security and data flows within these components', 'Excellent verbal and written communication skills', 'Self-motivated, driven, and creative individual', 'Scaling systems and microservices', 'Familiarity with CI/CD processes', 'Code coverage analysis / static analysis tools', 'Agile programming processes and methodologies such as Scrum', 'Scheduling tools like Autosys , ControlM', 'Informatica IICS , Talend', '8 years'], 'Responsibilities': ['Delta lake, delta table and lakehouse architecture'], 'Benefits': ['Pay: From $65.00 per hour']}",Data engineer,en,15113200,4,,,
7-6zJm6_MhYAAAAAAAAAAA==,Costco Wholesale,https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQMEXpjzxSXP_hEYETqQMZmfop0Uwnb1a8puH1-&s=0,,,JobzMall,FULLTIME,Data Engineer,https://www.jobzmall.com/costco-wholesale/job/data-engineer-251,True,0.5613,"At Costco Wholesale, we offer an exciting opportunity for a Data Engineer to join our team and make a real difference. We are looking for a highly organized and creative individual who can develop and maintain our data-driven systems.The successful candidate will have a strong technical background and the ability to think strategically about our data architecture. You must have a Bachelor's degree in Computer Science, Software Engineering, Information Systems, Data Science or a related field and at least two years of experience in working with data architectures, ETL pipelines, and data warehousing.We are looking for an individual who is passionate about data and has the ability to analyze and interpret complex datasets. You should have excellent problem-solving skills, be comfortable working with multiple stakeholders, and have a keen eye for detail. If you are motivated, organized, and an excellent communicator, we would love to hear from you!

Costco Wholesale is an Equal Opportunity Employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. We do not discriminate based upon race, religion, color, national origin, sex, sexual orientation, gender identity, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.",False,1676932949,2023-02-20T22:42:29.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=60&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=7-6zJm6_MhYAAAAAAAAAAA%3D%3D",2023-08-26T23:59:59.000Z,1693094399.0,"{'no_experience_required': False, 'required_experience_in_months': None, 'experience_mentioned': True, 'experience_preferred': False}",['Sql <br>Python <br>Business Intelligence <br>Data Analysis <br>Data Quality <br>Communication <br>Conflict Resolution <br>Leadership <br>Negotiation <br>Time management <br>Data Security <br>Big Data <br>Data Modeling <br>ETL <br>Hadoop <br>Data warehousing <br>Data Visualization <br>Cloud Computing <br>Interpersonal Skills <br>creativity <br>Teamwork <br>Data migration <br>Data governance <br>Adaptability <br>Problem-SolvingCommunication <br>Conflict Resolution <br>Leadership <br>Negotiation <br>Time management <br>Interpersonal Skills <br>creativity <br>Teamwork <br>Adaptability <br>Problem-Solving'],"{'postgraduate_degree': True, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': True, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['The successful candidate will have a strong technical background and the ability to think strategically about our data architecture', ""You must have a Bachelor's degree in Computer Science, Software Engineering, Information Systems, Data Science or a related field and at least two years of experience in working with data architectures, ETL pipelines, and data warehousing.We are looking for an individual who is passionate about data and has the ability to analyze and interpret complex datasets"", 'You should have excellent problem-solving skills, be comfortable working with multiple stakeholders, and have a keen eye for detail', 'If you are motivated, organized, and an excellent communicator, we would love to hear from you!']}",Data engineer,en,15113200,4,,,
fciHxK29OeAAAAAAAAAAAA==,Walmart,https://upload.wikimedia.org/wikipedia/commons/thumb/c/ca/Walmart_logo.svg/2560px-Walmart_logo.svg.png,https://www.walmart.com,Retail,"Dallas, TX - Geebo",FULLTIME,Data Engineer III,https://dallas-tx.geebo.com/jobs-online/view/id/1139475167-data-engineer-iii-/,True,0.404,"What you'll do at Position Summary What you'll do At Walmart, we help people save money, so they can live better. This mission serves as the foundation for every decision we make and drives us to create the future of retail. We can't do that without the best talent - talent that is innovative, curious, and driven to create exceptional experiences for our customers. Do you have boundless energy and passion for engineering data used to solve dynamic problems that will shape the future of retail ? With the sheer scale of Walmart's environment comes the biggest of big data sets. As a Walmart Data Engineer, you will dig into our mammoth scale of data to help unleash the power of retail data science by imagining, developing, and maintaining data pipelines that our Data Scientists and Analysts can rely on . You will be responsible for contributing to an orchestration layer of complex data transformations, refining raw data from source into targeted, valuable data assets for consumption in a governed way. You will partner with Data Scientists, Analysts, other engineers and business stakeholders to solve complex and exciting challenges so that we can build out capabilities that evolve the retail business model while making a positive impact on our customers' lives. You'll make an impact by:
Design, develop and build database to power Big Data analytical systems. Design data integration pipeline architecture and ensure successful creation of the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using Spark, SQL, HQL and other technologies. Build robust and scalable applications using SQL, Scala/Python and Spark. Create real time data streaming and processing using Kafka and/or Spark streaming. Work on creating data ingestion processes to maintain Global Data lake on Google cloud or Azure Engage with architects and senior technical leads to create and enhance complex software components. Design, configure and implement systems that can scale to process terabytes of data between heterogeneous systems on premise and cloud. Work with business customers, product managers and engineers to design feature-based solutions and implement them in an agile fashion. Develop proof-of-concept prototype with fast iteration and experimentation. Develop and maintain design documentation, test cases, performance and monitoring and performance evaluation using Git, Crontab, Putty, Jenkins, Maven, Confluence, ETL, Automic, Zookeeper, Cluster Manager Perform continuous integration and deployment using Jenkins and Git You'll sweep us off our feet if 3
years of experience with 1
years of Big data development experience Experience in HDFS, Hive, Hive UDF's, MapReduce, Druid, Spark, Python, Hue, Shell Scripting, Unix. Demonstrates expertise in writing complex, highly optimized queries across large data sets Retail experience and knowledge of commercial data is a huge plus Experience with BI Tool Tableau or Looker is a plu The above information has been designed to indicate the general nature and level of work performed in the role. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process. About Global Tech Imagine working in an environment where one line of code can make life easier for hundreds of millions of people and put a smile on their face. That's what we do at Walmart Global Tech. We're a team of 15,000
software engineers, data scientists and service professionals within Walmart, the world's largest retailer, delivering innovations that improve how our customers shop and empower our 2.2 million associates. To others, innovation looks like an app, service or some code, but Walmart has always been about people. People are why we innovate, and people power our innovations. Being human-led is our true disruption. We're virtual Working virtually this year has helped us make quicker decisions, remove location barriers across our global team, be more flexible in our personal lives and spend less time commuting. Today, we are reimagining the tech workplace of the future by making a permanent transition to virtual work for most of our team. Of course, being together in person is an important part of our culture and shared success. We'll collaborate in person at a regular cadence and with purpose. Benefits & Perks:
Beyond competitive pay, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more. Equal Opportunity Employer Walmart, Inc. is an Equal Opportunity Employer - By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting and valuing diversity- unique styles, experiences, identities, ideas and opinions - while being inclusive of all people. Who We Are Join Walmart and your work could help over 275 million global customers live better every week. Yes, we are the Fortune #1 company. But you ' ll quickly find we ' re a company who wants you to feel comfortable bringing your whole self to work. A career at Walmart is where the world's most complex challenges meet a kinder way of life. Our mission spreads far beyond the walls of our stores. Join us and you'll discover why we are a world leader in diversity and inclusion, sustainability, and community involvement. From day one, you ' ll be empowered and equipped to do the best work of your life. careers.walmart.com Minimum Qualifications Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications. Option 1:
Bachelor's degree in Computer Science and 2 years' experience in software engineering or related field. Option 2:
4 years' experience in software engineering or related field. Option 3:
Master's degree in Computer Science. Preferred Qualifications Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications. Data engineering, database engineering, business intelligence, or business analytics, Master's degree in Computer Science or related field and 2 years' experience in software engineering or related field Primary Location 603 MUNGER AVE STE 400, DALLAS, TX 75202, United States of America About Walmart At Walmart, we help people save money so they can live better. This mission serves as the foundation for every decision we make, from responsible sourcing to sustainability-and everything in between. As a Walmart associate, you will play an integral role in shaping the future of retail, tech, merchandising, finance and hundreds of other industries-all while affecting the lives of millions of customers all over the world. Here, your work makes an impact every day. What are you waiting for? Walmart, Inc. is an Equal Opportunity Employer- By Choice. We believe we are best equipped to help our associates, customers, and the communities we serve live better when we really know them. That means understanding, respecting, and valuing diversity- unique styles, experiences, identities, abilities, ideas and opinions- while being inclusive of all people. All the benefits you need for you and your family Multiple health plan options, including vision & dental plans for you & dependents Financial benefits including 401(k), stock purchase plans, life insurance and more Associate discounts in-store and online Education assistance for Associate and dependents Parental Leave Pay during military service Paid Time off - to include vacation, sick, parental Short-term and long-term disability for when you can't work because of injury, illness, or childbirth Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to specific plan or program terms. For information about benefits and eligibility, see One.Walmart.com/Benefits . Frequently asked questions On average, how long does it take to fill out an application? On average, it takes 45-60 minutes to complete your application for the first time. Subsequent applications will take less time to apply as our system saves some of your application information. Please note that some positions require the completion of assessments in order to receive consideration for that role. Those would take additional time. Can I change my application after submitting? No, you cannot change your application after submitting, so please make sure that everything is finalized before you hit the submit button. How do you protect my personal information? Processing of information on paper is minimal, and Walmart processes application information using an applicant tracking system (ATS). Access to the data within the ATS is restricted to authorized personnel, and the system itself is held to high security standards by Walmart. What are the recommended Internet Browsers for applying for open roles? Internet Explorer 8.0
Firefox 4.0
Safari 4.0
Chrome 12+
Salary Range:
$80K -- $100K
Minimum Qualification
Data Science & Machine LearningEstimated Salary: $20 to $28 per hour based on qualifications.",False,1690416000,2023-07-27T00:00:00.000Z,Dallas,TX,US,32.776665,-96.79699,"['paid_time_off', 'retirement_savings', 'health_insurance', 'dental_coverage']","https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=60&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=fciHxK29OeAAAAAAAAAAAA%3D%3D",2023-08-03T00:00:00.000Z,1691020800.0,"{'no_experience_required': False, 'required_experience_in_months': 48, 'experience_mentioned': True, 'experience_preferred': True}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': True, 'professional_certification_mentioned': False}",False,20.0,28.0,USD,HOUR,"{'Qualifications': ['years of experience with 1', ""years of Big data development experience Experience in HDFS, Hive, Hive UDF's, MapReduce, Druid, Spark, Python, Hue, Shell Scripting, Unix"", 'Demonstrates expertise in writing complex, highly optimized queries across large data sets Retail experience and knowledge of commercial data is a huge plus Experience with BI Tool Tableau or Looker is a plu The above information has been designed to indicate the general nature and level of work performed in the role', 'Data Science & Machine LearningEstimated Salary: $20 to $28 per hour based on qualifications'], 'Responsibilities': ['You will be responsible for contributing to an orchestration layer of complex data transformations, refining raw data from source into targeted, valuable data assets for consumption in a governed way', ""You will partner with Data Scientists, Analysts, other engineers and business stakeholders to solve complex and exciting challenges so that we can build out capabilities that evolve the retail business model while making a positive impact on our customers' lives"", 'Design, develop and build database to power Big Data analytical systems', 'Design data integration pipeline architecture and ensure successful creation of the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using Spark, SQL, HQL and other technologies', 'Build robust and scalable applications using SQL, Scala/Python and Spark', 'Create real time data streaming and processing using Kafka and/or Spark streaming', 'Work on creating data ingestion processes to maintain Global Data lake on Google cloud or Azure Engage with architects and senior technical leads to create and enhance complex software components', 'Design, configure and implement systems that can scale to process terabytes of data between heterogeneous systems on premise and cloud', 'Work with business customers, product managers and engineers to design feature-based solutions and implement them in an agile fashion', 'Develop proof-of-concept prototype with fast iteration and experimentation', ""Develop and maintain design documentation, test cases, performance and monitoring and performance evaluation using Git, Crontab, Putty, Jenkins, Maven, Confluence, ETL, Automic, Zookeeper, Cluster Manager Perform continuous integration and deployment using Jenkins and Git You'll sweep us off our feet if 3""], 'Benefits': ['Beyond competitive pay, you can receive incentive awards for your performance', 'Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more', ""All the benefits you need for you and your family Multiple health plan options, including vision & dental plans for you & dependents Financial benefits including 401(k), stock purchase plans, life insurance and more Associate discounts in-store and online Education assistance for Associate and dependents Parental Leave Pay during military service Paid Time off - to include vacation, sick, parental Short-term and long-term disability for when you can't work because of injury, illness, or childbirth Eligibility requirements apply to some benefits and may depend on your job classification and length of employment"", 'Benefits are subject to change and may be subject to specific plan or program terms', '$80K -- $100K']}",Data engineer,en,15113200,4,,452990,All Other General Merchandise Stores
gbgzIjy0vDoAAAAAAAAAAA==,Sphinix Solutions,https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQd1Iu8RoMwh5xJq8yGk6lyzpIamO--IiysvtJC&s=0,,,Built In,FULLTIME,"Sr Data Engineer (Dallas, TX)",https://builtin.com/job/data/sr-data-engineer/361150,False,0.5966,"Sr Data Engineer - 5 Positions

Call Notes:

Top Skills:

Data Engineers with -

3-5 years of genuine experience ( will not count the academic experience in this)

Python

Spark/Pyspark/ Scala

Spring Boot

Java

AWS or any other Cloud

Looking for hands on resources.

Data Pipeline, data analysis

This is a hands on up and running Senior Level role.

Team Info:

Data space

Risk management called - TDGRM

Role Info:

Building controls for tech and data environment

The team/ hiring will be distributed based on these skills -
• Python with Pyspark and AWS - 1st track
• Java with Spark or Scala and AWS- 2nd track

Minimum Requirements:
• At least 3 years of experience developing Data Pipelines for Data Ingestion or Transformation using Java or Scala or Python
• At least 2 years experience in the following Big Data frameworks: File Format (Parquet, AVRO, ORC etc)
• At least 3 years of developing applications with Monitoring, Build Tools, Version Control, Unit Test, TDD, Change Management to support DevOps
• At least 3 years of experience with SQL and Shell Scripting experience
• At least 2 years of experience with software design and must have an understanding of cross systems usage and impact

Nice-to-Have qualifications:
• 2+ years of experience working with Dimensional Data Model and pipelines in relation with the same
• 2+ years' experience with Amazon Web Services (AWS), Microsoft Azure or another public cloud service
• 2+ years of experience working with Streaming using Spark or Flink or Kafka or NoSQL
• Intermediate level experience/knowledge in at least one scripting language (Python, Perl, JavaScript)
• Hands on design experience with data pipelines, joining data between structured and unstructured data",False,1635462453,2021-10-28T23:07:33.000Z,,TX,US,32.707874,-96.92091,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=60&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=gbgzIjy0vDoAAAAAAAAAAA%3D%3D",,,"{'no_experience_required': False, 'required_experience_in_months': 36, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': True, 'degree_mentioned': False, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['3-5 years of genuine experience ( will not count the academic experience in this)', 'Python with Pyspark and AWS - 1st track', 'Java with Spark or Scala and AWS- 2nd track', 'At least 3 years of experience developing Data Pipelines for Data Ingestion or Transformation using Java or Scala or Python', 'At least 2 years experience in the following Big Data frameworks: File Format (Parquet, AVRO, ORC etc)', 'At least 3 years of developing applications with Monitoring, Build Tools, Version Control, Unit Test, TDD, Change Management to support DevOps', 'At least 3 years of experience with SQL and Shell Scripting experience', 'At least 2 years of experience with software design and must have an understanding of cross systems usage and impact', '2+ years of experience working with Dimensional Data Model and pipelines in relation with the same', ""2+ years' experience with Amazon Web Services (AWS), Microsoft Azure or another public cloud service"", '2+ years of experience working with Streaming using Spark or Flink or Kafka or NoSQL', 'Intermediate level experience/knowledge in at least one scripting language (Python, Perl, JavaScript)', 'Hands on design experience with data pipelines, joining data between structured and unstructured data'], 'Responsibilities': ['This is a hands on up and running Senior Level role', 'Building controls for tech and data environment', 'The team/ hiring will be distributed based on these skills -']}",Data engineer,en,15113200,4,,,
Zl5bZRbb03QAAAAAAAAAAA==,BuzzClan Private Limited,,,,Indeed,FULLTIME,Data Engineer,https://www.indeed.com/viewjob?jk=e185e49f149ae1b0,True,0.6156,"-Job Title: Data Engineer /Data Analyst
Location: Dallas, TX

Job Overview
Shall apply specialized knowledge in writing high-performance SQL
queries and data engineering solutions that moves, cleans, and loads data to differing systems. The
person will interact with our clients and differing roles within IT to gain understanding of the business
environment, technical context, and strategic direction. This person will also be responsible for
generating documentation as needed; conform to security and quality standards; and stay current on
emerging trends. Teams supported include: Application Engineering, Data Platform Engineering, Data
Engineering, Decision Science, and Business Analytics
A successful candidate for this position, you must:
? Be comfortable with researching data questions, identify root causes, and interact closely with business users and technical resources on various data related decisions
? Proactively identify and assist in solving recurring data quality or data availability issues.
? Have experience in monitoring, troubleshooting, and resolving ETL issues.
? Be able to develop high performance data queries, stored procedures and/or functional code for data related ad-hoc reporting and/or ETL batch triage reasons.
? Understand how to profile code, queries, programming objects and optimize performance
? Aspire to be efficient, thorough, and proactive

Responsibilities and Duties
? Monitors, supports, triages data pipelines and ETL tasks that ingest, move, transform, and integrate data in a secure and performant manner.
? Prepares necessary SQL scripts to perform data manipulation in key systems to address data related application and reporting needs.
? Explores new technologies and data processing methods to increase efficiency, performance, and flexibility to proactively address recurring data related issues.
? Document requirements and translate into proper system requirements specifications using high-maturity methods, processes, and tools.
? Designs, prepares, and executes unit tests.
? Participates in cross-functional teams.
? Represents team to clients.
? Demonstrates technical leadership and exerts influence outside of immediate team.
? Develops innovative team solutions to complex problems.
? Contributes to strategic direction for teams.
? Applies in-depth or broad technical knowledge to provide maintenance solutions across one or more technology areas (e.g. SSIS, Azure ADF).
? Integrates technical expertise and business understanding to create superior solutions for clients.
? Consults with team members and other organizations, clients and vendors on complex issues.
? Work on Special projects as requested
? Performs other duties as assigned

Qualifications
? Bachelor’s degree in IT preferred. Equivalent combination of education and experience may be substituted in lieu of degree.
? 2 to 4 years of Microsoft SSIS package development experience including experience with Microsoft Visual Studio
? 1+ years of experience working with enterprise data warehouses
? 5+ years of experience in SQL and be able to write complex logic using SQL as part of ETL, and use SQL effectively to perform complex data analysis and discovery
? 1+ years of experience building reports with SSRS.
? Exposure to Azure and Azure Data Factory
? Exposure to an Enterprise Data Lake
? Demonstrate strong organization skills and detail-oriented
? Experience with CMD shell and PowerShell
? Experience with large-scale, complex data environments
? Ability to self-motivate and meet deadlines
? Intense desire to learn
? Ability to express complex technical concepts effectively, both verbally and in writing
? Ability to multi-task in a fast-paced, changing environment
? Ability to maintain confidentiality

Job Types: Full-time, Contract, Temporary

Salary: Up to $80,000.00 per year

Benefits:
• 401(k)
• Dental insurance
• Flexible schedule
• Health insurance
• Paid time off
• Tuition reimbursement
• Vision insurance

Experience level:
• 4 years

Schedule:
• 8 hour shift

Ability to commute/relocate:
• Dallas, TX 75240: Reliably commute or planning to relocate before starting work (Required)

Experience:
• Informatica: 1 year (Preferred)
• SQL: 1 year (Preferred)
• Data warehouse: 1 year (Preferred)

Work Location: In person",False,1680704545,2023-04-05T14:22:25.000Z,Dallas,TX,US,32.776665,-96.79699,"['paid_time_off', 'health_insurance', 'retirement_savings', 'dental_coverage']","https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=60&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=Zl5bZRbb03QAAAAAAAAAAA%3D%3D",,,"{'no_experience_required': False, 'required_experience_in_months': 60, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': True, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['Equivalent combination of education and experience may be substituted in lieu of degree', '2 to 4 years of Microsoft SSIS package development experience including experience with Microsoft Visual Studio', '1+ years of experience working with enterprise data warehouses', '5+ years of experience in SQL and be able to write complex logic using SQL as part of ETL, and use SQL effectively to perform complex data analysis and discovery', '1+ years of experience building reports with SSRS', 'Exposure to Azure and Azure Data Factory', 'Exposure to an Enterprise Data Lake', 'Demonstrate strong organization skills and detail-oriented', 'Experience with CMD shell and PowerShell', 'Experience with large-scale, complex data environments', 'Ability to self-motivate and meet deadlines', 'Intense desire to learn', 'Ability to express complex technical concepts effectively, both verbally and in writing', 'Ability to multi-task in a fast-paced, changing environment', 'Ability to maintain confidentiality', 'Dallas, TX 75240: Reliably commute or planning to relocate before starting work (Required)'], 'Responsibilities': ['queries and data engineering solutions that moves, cleans, and loads data to differing systems', 'person will interact with our clients and differing roles within IT to gain understanding of the business', 'This person will also be responsible for', 'generating documentation as needed; conform to security and quality standards; and stay current on', 'Be comfortable with researching data questions, identify root causes, and interact closely with business users and technical resources on various data related decisions', 'Proactively identify and assist in solving recurring data quality or data availability issues', 'Have experience in monitoring, troubleshooting, and resolving ETL issues', 'Be able to develop high performance data queries, stored procedures and/or functional code for data related ad-hoc reporting and/or ETL batch triage reasons', 'Understand how to profile code, queries, programming objects and optimize performance', 'Monitors, supports, triages data pipelines and ETL tasks that ingest, move, transform, and integrate data in a secure and performant manner', 'Prepares necessary SQL scripts to perform data manipulation in key systems to address data related application and reporting needs', 'Explores new technologies and data processing methods to increase efficiency, performance, and flexibility to proactively address recurring data related issues', 'Document requirements and translate into proper system requirements specifications using high-maturity methods, processes, and tools', 'Designs, prepares, and executes unit tests', 'Participates in cross-functional teams', 'Represents team to clients', 'Demonstrates technical leadership and exerts influence outside of immediate team', 'Develops innovative team solutions to complex problems', 'Contributes to strategic direction for teams', 'Applies in-depth or broad technical knowledge to provide maintenance solutions across one or more technology areas (e.g', 'Integrates technical expertise and business understanding to create superior solutions for clients', 'Consults with team members and other organizations, clients and vendors on complex issues', 'Work on Special projects as requested', 'Performs other duties as assigned'], 'Benefits': ['Salary: Up to $80,000.00 per year', '401(k)', 'Dental insurance', 'Flexible schedule', 'Health insurance', 'Paid time off', 'Tuition reimbursement', 'Vision insurance']}",Data engineer,en,15113200,4,,,
9Z1mzqAMpa8AAAAAAAAAAA==,"Employer Direct Healthcare, LLC",,http://www.edhc.com,,Monster,FULLTIME,Data Engineer,https://www.monster.com/job-openings/data-engineer-dallas-tx--85381867-01d8-4e40-85d5-6de644c3e7c7,True,0.6695,"Responsible for developing complex logic to analyze, prepare, and discover insights within relational databases for innovative healthcare solutions provider. Specific duties include: (1) architecting database schema and other programmatic objects within database to store and secure data; (2) developing routines using SQL Server Integration Services, Azure Data Factory, and other ETL toolsets to ingest, transform, move, prepare, and extract data from different data stores; (3) utilizing SQL, Databricks, and other analytics tools to derive insights from data sets; (4) utilizing data visualization toolsets such as SQL Server Reporting Services and Microsoft Power BI to produce reports and data visualization for business partners; and (5) working data engineering team to conduct peer review and code analysis for data SDLC process.

Minimum Requirements: B.S. in Computer Science, Electrical Engineering, Electronics Engineering, or closely related field; five years of IT development or related experience, including specific experience using Microsoft SQL server database to write complex logic and data analysis; knowledge of data warehouses, Microsoft SSIS package development, and building reports with SSR; and proficiency with large-scale, complex data environments, Microsoft Power BI, Azure and Azure Data Factory, Enterprise Data Lake, CMD shell and PowerShell.

Interested candidates should submit a resume & cover letter to HR, Employer Direct Healthcare, LLC, 2100 Ross Avenue, Suite 1900, Dallas, TX 75201.

About the Company:
Employer Direct Healthcare, LLC",False,1688688000,2023-07-07T00:00:00.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=60&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=9Z1mzqAMpa8AAAAAAAAAAA%3D%3D",2023-08-06T20:38:56.000Z,1691354336.0,"{'no_experience_required': False, 'required_experience_in_months': 60, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': True, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['Minimum Requirements: B.S. in Computer Science, Electrical Engineering, Electronics Engineering, or closely related field; five years of IT development or related experience, including specific experience using Microsoft SQL server database to write complex logic and data analysis; knowledge of data warehouses, Microsoft SSIS package development, and building reports with SSR; and proficiency with large-scale, complex data environments, Microsoft Power BI, Azure and Azure Data Factory, Enterprise Data Lake, CMD shell and PowerShell'], 'Responsibilities': ['Responsible for developing complex logic to analyze, prepare, and discover insights within relational databases for innovative healthcare solutions provider', 'Specific duties include: (1) architecting database schema and other programmatic objects within database to store and secure data; (2) developing routines using SQL Server Integration Services, Azure Data Factory, and other ETL toolsets to ingest, transform, move, prepare, and extract data from different data stores; (3) utilizing SQL, Databricks, and other analytics tools to derive insights from data sets; (4) utilizing data visualization toolsets such as SQL Server Reporting Services and Microsoft Power BI to produce reports and data visualization for business partners; and (5) working data engineering team to conduct peer review and code analysis for data SDLC process']}",Data engineer,en,15113200,4,,,
JH3OAdcicPwAAAAAAAAAAA==,Mindlance,https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTkhYZMlIJNU1lj96ZEzQYztcEocOhFFTGmJ_nF&s=0,,,Lensa,FULLTIME,Lead Data Engineer,https://lensa.com/lead-data-engineer-jobs/dallas/jd/e4b6a0390857a679def8b8fc111a2057,False,0.475,"Job Description

Duration:
Possibility of extensions

Location:
Dallas, TX & Miami, FL (Hybrid)
2 days/week - between Monday through Thursday

Position Responsibilities:
Principal level engineering background technically but won't be spending most of their time hands on and need to be comfortable managing the process without getting hands-on
More delegating because they will manage 2 teams - architects are doing the modeling so these leads will be working with the business most
Need to be able to manage off-shore resources
Each team is going to have 3 data engineers and 2 QA engineers and each lead will be responsible for two of these off-shore teams
Highly regulatory industry experience would be a huge advantage

Position Qualifications:
Snowflake and python - high level experience in the data engineering/science space
For ETL -- Into snowflake using Kafka - in snowflake its python and IDMC
Experience doing large enterprise data migrations like they are doing

Education/Certifications Required/Preferred:
Any kind of degree is a plus - builds perspective and shows ability to adapt and learn but feels like you can also get that perspective different ways so not a must have if they are otherwise great

""Mindlance is an Equal Opportunity Employer and does not discriminate in employment on the basis of - Minority/Gender/Disability/Religion/LGBTQI/Age/Veterans.""",False,1689265152,2023-07-13T16:19:12.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=60&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=JH3OAdcicPwAAAAAAAAAAA%3D%3D",2023-08-12T16:19:12.000Z,1691857152.0,"{'no_experience_required': False, 'required_experience_in_months': None, 'experience_mentioned': True, 'experience_preferred': False}","['Reading Comprehension', 'Active Listening', 'Writing', 'Speaking', 'Critical Thinking', 'Active Learning', 'Monitoring', 'Social Perceptiveness', 'Coordination', 'Complex Problem Solving', 'Programming', 'Judgment and Decision Making', 'Systems Analysis', 'Systems Evaluation']","{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': False, 'professional_certification_mentioned': True}",False,,,,,"{'Qualifications': [""Principal level engineering background technically but won't be spending most of their time hands on and need to be comfortable managing the process without getting hands-on"", 'Need to be able to manage off-shore resources', 'Each team is going to have 3 data engineers and 2 QA engineers and each lead will be responsible for two of these off-shore teams', 'Highly regulatory industry experience would be a huge advantage', 'Snowflake and python - high level experience in the data engineering/science space', 'For ETL -- Into snowflake using Kafka - in snowflake its python and IDMC', 'Experience doing large enterprise data migrations like they are doing'], 'Responsibilities': ['More delegating because they will manage 2 teams - architects are doing the modeling so these leads will be working with the business most']}",Data engineer,en,15113200,4,['15-1199.06 Database Architects'],,
GjPMRB4MIFMAAAAAAAAAAA==,Sam's Club,"https://scene7.samsclub.com/is/image/samsclub/sc_logo_blue?fmt=png-alpha&resMode=sharp2&op_usm=1.75,0.3,2,0&wid=200",http://www.samsclub.com,Retail,Walmart Careers,FULLTIME,"Senior Manager I, Data Engineering",https://careers.walmart.com/us/jobs/WD1527986-senior-manager-i-data-engineering,False,0.6831,"Position Summary...

What you'll do...

As a Senior Manager I, Data Engineer you are managing a large global Engineering team building scalable, highly available, enterprise-grade data flows. You will drive the execution of multiple data engineering project that unlocks the potential of data for the business. You will lead and inspire your teams while effectively prioritizing work and maintaining a strong customer focus to create business value while putting processes in-place to ensure successful outcomes. You will find ways to deliver incremental value while solving tactical problems strategically. Quantifying opportunities and measuring the quality, performance, and business impact of our solutions and use data to inform prioritization and operations.

About Team:
Sam's Club is our membership warehouse club, a business model that provides our members with high-quality products at prices that are unrivaled by traditional retail. Sam's Club provides a carefully curated assortment of items, as well as developing and leading technologies and services such as Scan & Go, Club Pickup, and home delivery service in select markets. Sam's Club also provides travel, auto purchasing, pharmacy, optical, hearing aid centers, tire and battery centers, and a portfolio of business operations support services.

What you'll do:
• Lead a team of Data engineers to design, build, test and deploy cutting edge solutions at scale, impacting millions of customers worldwide drive value from data.
• Interact with Sam's Club engineering teams across geographies to leverage expertise and contribute to the tech community.
• Engage with Product Management and Business to drive the agenda, set your priorities and deliver awesome product features to keep platform ahead of market scenarios.
• Identify right open source tools to deliver product features by performing research, POC/Pilot and/or interacting with various open source forums.
• Develop and/or Contribute to add features that enable adoption of data across Sam’s Club.
• Deploy and monitor products on Cloud platforms.
• Develop and implement best-in-class monitoring processes to enable data applications meet SLAs.
• Guide the team technically for end-to-end solution Lifecyle.

What you'll bring:
• 3 - 5 Years of Experience leading a high performing data engineering team.
• 8 - 10 years of Big data development experience.
• 2 -3 Years of Experience in GCP/Azure cloud platforms.
• 2 -3 years of experience building streaming pipeline using spark streaming or similar.
• Demonstrates up-to-date expertise in Data Engineering, complex data pipeline development.
• Architect, Design, develop, implement and tune distributed data processing pipelines that process large volume of data; focusing on scalability, low -latency, and fault-tolerance in every system built.
• Exposure to Data Governance ( Data Quality, Metadata Management, Security, etc.).
• Experience with Java, Scala and/or Python to write data pipelines and data processing layers.
• Demonstrates expertise in writing complex, highly-optimized queries across large data sets.
• Proven working expertise with Big Data Technologies Spark Scala/PySpark, and SQL.
• Knowledge and experience in Kafka, Storm, Druid and Presto.
• Architect, Design, develop, implement, and tune distributed data processing pipelines that process large volume of data; focusing on scalability, low -latency, and fault-tolerance in every system built.

About Walmart Global Tech
Imagine working in an environment where one line of code can make life easier for hundreds of millions of people. That’s what we do at Walmart Global Tech. We’re a team of software engineers, data scientists, cybersecurity expert's and service professionals within the world’s leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.

Flexible, hybrid work:
We use a hybrid way of working that is primarily in office coupled with virtual when not onsite. Our campuses serve as a hub to enhance collaboration, bring us together for purpose and deliver on business needs. This approach helps us make quicker decisions, remove location barriers across our global team and be more flexible in our personal lives.

Benefits:
Benefits: Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more.

Equal Opportunity Employer:
Walmart, Inc. is an Equal Opportunity Employer – By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting and valuing diversity- unique styles, experiences, identities, ideas and opinions – while being inclusive of all people.

The above information has been designed to indicate the general nature and level of work performed in the role. It is not designed to contain or be interpreted as a comprehensive inventory of all responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process.

At Sam's Club, we offer competitive pay as well as performance-based incentive awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable. For information about PTO, see https://one.walmart.com/notices .

Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms. For information about benefits and eligibility, see One.Walmart at https://bit.ly/3iOOb1J .

The annual salary range for this position is $112,000.00-$192,000.00

Additional compensation includes annual or quarterly performance incentives.

Additional compensation for certain positions may also include:

- Regional Pay Zone (RPZ) (based on location)

- Stock equity incentives

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelor’s degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years’ experience in software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Master’s degree in Computer Science or related field and 4 years' experience in software engineering or related field, Supervisory

Primary Location...
603 MUNGER AVE STE 400, DALLAS, TX 75202, United States of America",False,1686268800,2023-06-09T00:00:00.000Z,Dallas,TX,US,32.776665,-96.79699,"['retirement_savings', 'dental_coverage', 'paid_time_off', 'health_insurance']","https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=60&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=GjPMRB4MIFMAAAAAAAAAAA%3D%3D",,,"{'no_experience_required': False, 'required_experience_in_months': 72, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': True, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['3 - 5 Years of Experience leading a high performing data engineering team', '8 - 10 years of Big data development experience', '2 -3 Years of Experience in GCP/Azure cloud platforms', '2 -3 years of experience building streaming pipeline using spark streaming or similar', 'Demonstrates up-to-date expertise in Data Engineering, complex data pipeline development', 'Exposure to Data Governance ( Data Quality, Metadata Management, Security, etc.)', 'Experience with Java, Scala and/or Python to write data pipelines and data processing layers', 'Demonstrates expertise in writing complex, highly-optimized queries across large data sets', 'Proven working expertise with Big Data Technologies Spark Scala/PySpark, and SQL', 'Knowledge and experience in Kafka, Storm, Druid and Presto', ""Option 1: Bachelor’s degree in Computer Science and 4 years' experience in software engineering or related field"", ""Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related field"", ""Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Master’s degree in Computer Science or related field and 4 years' experience in software engineering or related field, Supervisory""], 'Responsibilities': ['As a Senior Manager I, Data Engineer you are managing a large global Engineering team building scalable, highly available, enterprise-grade data flows', 'You will drive the execution of multiple data engineering project that unlocks the potential of data for the business', 'You will lead and inspire your teams while effectively prioritizing work and maintaining a strong customer focus to create business value while putting processes in-place to ensure successful outcomes', 'You will find ways to deliver incremental value while solving tactical problems strategically', 'Lead a team of Data engineers to design, build, test and deploy cutting edge solutions at scale, impacting millions of customers worldwide drive value from data', ""Interact with Sam's Club engineering teams across geographies to leverage expertise and contribute to the tech community"", 'Engage with Product Management and Business to drive the agenda, set your priorities and deliver awesome product features to keep platform ahead of market scenarios', 'Identify right open source tools to deliver product features by performing research, POC/Pilot and/or interacting with various open source forums', 'Develop and/or Contribute to add features that enable adoption of data across Sam’s Club', 'Deploy and monitor products on Cloud platforms', 'Develop and implement best-in-class monitoring processes to enable data applications meet SLAs', 'Guide the team technically for end-to-end solution Lifecyle'], 'Benefits': ['Benefits: Beyond our great compensation package, you can receive incentive awards for your performance', 'Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more', 'Health benefits include medical, vision and dental coverage', 'Financial benefits include 401(k), stock purchase and company-paid life insurance', 'Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting', 'Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more', 'You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes', 'It will meet or exceed the requirements of paid sick leave laws, where applicable', 'Tuition, books, and fees are completely paid for by Walmart', 'The annual salary range for this position is $112,000.00-$192,000.00', 'Additional compensation includes annual or quarterly performance incentives', 'Additional compensation for certain positions may also include:', 'Regional Pay Zone (RPZ) (based on location)', 'Stock equity incentives']}",Senior manager,en,11302100,4,,452990,All Other General Merchandise Stores
3KBM7t96SksAAAAAAAAAAA==,Capco,https://upload.wikimedia.org/wikipedia/commons/thumb/6/66/Capco_logo.svg/800px-Capco_logo.svg.png,http://www.capco.com,Consulting,Salary.com,FULLTIME,Data Engineer,https://www.salary.com/job/capco/data-engineer/j202301250117332463849,False,0.6827,"Data Engineer

About the team:

Capco’s Data Team helps our clients transform every aspect of their business. We are highly skilled at formulating data strategy, defining business and technology initiatives across the data management lifecycle, and aligning multi-year strategic roadmaps with client’s business goals. As digital technologies advance and regulations tighten, today’s consumers – and, therefore, today’s businesses – are becoming more aware of the importance of good quality data. We work to establish holistic ways to effectively manage data through the modern data supply chain and facilitate consumption through analytics, modelling, AI, machine learning, dashboarding, and reporting.

About the Job:

As a member of our Data Team, you will work across Capco’s different domains and solution offerings to help break down large problems, develop approaches and solutions. As a Data Engineer, you will create analytics reporting and provide data-driven strategic insights, trends, and perspective to help drive transformation for our clients.

What You’ll Get to Do:
• Work on hard problems with smart people
• Be highly motivated, result-oriented, and take pride in being a problem solver
• Work with new technology, focus on using the right tool for the job, rather than any sticky preference for a tool or technology
• Learn and share knowledge across our engineering teams, so we can continue to iterate and improve
• Write reusable, testable, and efficient code as needed
• Design and implement of low-latency, high-availability, and performant database systems
• Work on implementation of data pipelines/data warehouses/data marts/ODSs/Lakehouses
• Collaborate and work on integration of data storage solutions
• Focus on performance tuning, improvement, balancing, usability and automation

What You’ll Bring with You:
• 6 years of demonstrated hands on data engineering experience-- preferably in consulting or financial services
• Success working in ANY ONE of the following Data Engineering/Management technology areas, including but not limited to:
• Experience with ETL tools with data tracking
• Experience developing ETL Data Pipelines and Data Model solutions for integrating new data sets into a data platform from different sources.
• Experience implementing enterprise systems
• Experience with Big Data (Hadoop, MongoDB, Exadata)
• Experience developing real time ETL solutions (Kafka, Kinesis, etc)
• Strong knowledge of RDBS systems (Oracle preferred)
• Cloud Data Platforms across Azure and/or AWS is a plus
• Strong data modelling skills
• Experience developing complex SQL queries and PL/SQL
• PL/SQL development experience with enterprise software systems
• Experience developing Shell scripts and Python programs to automate tasks
• Knowledge of BI Solutions (MS Power BI, Tableau, Qlik, Alteryx, etc.)

Why Capco?

A career at Capco is a chance to help reshape the competitive landscape in financial services. We launch new banks, transform existing ones, and help our clients navigate complex change. As consultants, we work on the front-end business design all the way through to technology implementation.

We are the largest Financial Services focused consultancy in the world, serving everyone from global banks to emerging FinTechs, from strategy through digital transformation, design, business consulting, data and analytics, cyber, cloud, technology architecture, and engineering.

Capco is a young and growing firm. We maintain an entrepreneurial spirit and growth mindset and have minimal bureaucracy. We have no internal silos that get in the way of your career opportunities or ability to focus on our clients and make a difference to the business. We offer the opportunity for everyone to learn rapidly, take on tough challenges, and get promoted quickly. We take pride in our creative, collaborative, diverse, and inclusive culture, where everyone can #BYAW.

We offer highly competitive benefits, including medical, dental and vision insurance, a 401(k) plan, tuition reimbursement, and a work culture focused on innovation and creation of lasting value for our clients and employees.

Ready to take the Next Step?

If this sounds like you, we would love to hear from you. This is an opportunity to make a difference and contribute to a highly successful company with a significant growth trajectory.",False,1684454400,2023-05-19T00:00:00.000Z,Dallas,TX,US,32.776665,-96.79699,"['retirement_savings', 'health_insurance', 'dental_coverage']","https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=60&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=3KBM7t96SksAAAAAAAAAAA%3D%3D",2023-11-18T00:00:00.000Z,1700265600.0,"{'no_experience_required': False, 'required_experience_in_months': 72, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': False, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['6 years of demonstrated hands on data engineering experience-- preferably in consulting or financial services', 'Success working in ANY ONE of the following Data Engineering/Management technology areas, including but not limited to:', 'Experience with ETL tools with data tracking', 'Experience developing ETL Data Pipelines and Data Model solutions for integrating new data sets into a data platform from different sources', 'Experience implementing enterprise systems', 'Experience with Big Data (Hadoop, MongoDB, Exadata)', 'Experience developing real time ETL solutions (Kafka, Kinesis, etc)', 'Strong data modelling skills', 'Experience developing complex SQL queries and PL/SQL', 'PL/SQL development experience with enterprise software systems', 'Experience developing Shell scripts and Python programs to automate tasks', 'Knowledge of BI Solutions (MS Power BI, Tableau, Qlik, Alteryx, etc.)'], 'Responsibilities': ['As a Data Engineer, you will create analytics reporting and provide data-driven strategic insights, trends, and perspective to help drive transformation for our clients', 'Work on hard problems with smart people', 'Learn and share knowledge across our engineering teams, so we can continue to iterate and improve', 'Write reusable, testable, and efficient code as needed', 'Design and implement of low-latency, high-availability, and performant database systems', 'Work on implementation of data pipelines/data warehouses/data marts/ODSs/Lakehouses', 'Collaborate and work on integration of data storage solutions', 'Focus on performance tuning, improvement, balancing, usability and automation'], 'Benefits': ['We offer highly competitive benefits, including medical, dental and vision insurance, a 401(k) plan, tuition reimbursement, and a work culture focused on innovation and creation of lasting value for our clients and employees']}",Data engineer,en,15113200,4,,541613,Marketing Consulting Services
t_bwv82knGAAAAAAAAAAAA==,CTG,https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRMA_-RRfem6FTx7bf27YkAaVBdXBLZdJXlPOgn&s=0,,,Nexxt,FULLTIME,Data Engineer - Legacy Data Conversion,https://www.nexxt.com/jobs/data-engineer-legacy-data-conversion-dallas-tx-2545869795-job.html?aff=2ED44C72-8FD2-4B5D-BC54-2F623E88BE26,False,0.4993,"Data Engineer - Legacy Data Conversion

United States

New

Healthcare IT

Jul 13, 2023Post Date

23200980Requisition #

Apply for JobShare this JobSign Up for Job Alerts

CTG is seeking an experienced Data Engineer for a remote opportunity!

Job responsibilities will include
• Develop and maintain data extracts and data models
• Tools used include SSMS SSAS / SSMS SSIS, ETL and ELT processes
• On-call rotations exist for this team, and would be every 3-4 weeks.

After an initial Knowledge Transfer period of 2 to 4 weeks at the client site (tentative), work will be performed remotely, with the exception of a major outage.

REQUIRED SKILLS (primary and nice-to-have): (Required means that the client only wants to see candidates who have these skills).

3-5 years’ experience in SSIS, ETL and ELT processes are required.

3-5 years’ experience in understanding data models and extracts

Understanding in the construct of data cubes

Familiarity with Data Lineage and Data Governance

Optional/Preferred experience:

exposure to healthcare and systems, preferably Epic or Cerner

exposure to Dimensional Insights

would also be familiarity working in healthcare IT database systems

working with Cerner Millennium data

troubleshooting Tableau Dashboards

familiarity with Star Schema database design

familiarity with python scripting

HealthCatalyst

Dimensional Insights

Please email ~~~ if interested

CTG is a leading provider of digital transformation solutions and services that accelerate clients' project momentum and achievement of their desired IT and business outcomes. Our vision is to be an indispensable partner to our clients and the preferred career destination for digital and technology experts. CTG has operations in North America, South America, Western Europe, and India. For more information, visit ~~~.

Our culture is a direct result of the people who work at CTG, the values we hold, and the actions we take. In other words, our people are the culture. It's a living, breathing thing that is renewed every day through the ways we engage with each other, our clients, and our communities. Part of our mission is to cultivate a workplace that attracts and develops the best people, reflected by our recognition as a Great Place to Work-certified company across many of our global operations.

CTG will consider for employment all qualified applicants including those with criminal histories in a manner consistent with the requirements of all applicable local, state, and federal laws.

CTG is an Equal Opportunity and Affirmative Action Employer. CTG will assure equal opportunity and consideration to all applicants and employees in recruitment, selection, placement, training, benefits, compensation, promotion, transfer, and release of individuals without regard to race, creed, religion, color, national origin, sex, sexual orientation, gender identity and gender expression, age, disability, marital or veteran status, citizenship status, or any other discriminatory factors as required by law. Our Affirmative Action program serves to promote occupational equality and diversity through good faith efforts. CTG is fully committed to promoting employment opportunities for members of protected classes.

Additional Information
• Job Function: Application Management & Support
• Education Level: Bachelor's Degree (±16 years)
• Work Remote: Yes
• Travel: Yes, 5 % of the Time",False,1689356309,2023-07-14T17:38:29.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=60&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=t_bwv82knGAAAAAAAAAAAA%3D%3D",,,"{'no_experience_required': False, 'required_experience_in_months': 36, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['REQUIRED SKILLS (primary and nice-to-have): (Required means that the client only wants to see candidates who have these skills)', '3-5 years’ experience in SSIS, ETL and ELT processes are required', '3-5 years’ experience in understanding data models and extracts', 'Understanding in the construct of data cubes', 'Familiarity with Data Lineage and Data Governance', 'exposure to healthcare and systems, preferably Epic or Cerner', 'exposure to Dimensional Insights', 'would also be familiarity working in healthcare IT database systems', 'working with Cerner Millennium data', 'familiarity with Star Schema database design', 'familiarity with python scripting', ""Education Level: Bachelor's Degree (±16 years)""], 'Responsibilities': ['Develop and maintain data extracts and data models', 'Tools used include SSMS SSAS / SSMS SSIS, ETL and ELT processes', 'On-call rotations exist for this team, and would be every 3-4 weeks', 'After an initial Knowledge Transfer period of 2 to 4 weeks at the client site (tentative), work will be performed remotely, with the exception of a major outage', 'troubleshooting Tableau Dashboards']}",Data engineer,en,15113200,4,,,
BTtXgAW3LgEAAAAAAAAAAA==,Anblicks,,,,ZipRecruiter,FULLTIME,Data Engineer,"https://www.ziprecruiter.com/c/Anblicks/Job/Data-Engineer/-in-Dallas,TX?jid=6f97aba4bed93265",False,0.7224,"Data Engineer

Design and develop data pipeline models to extract, transform and load data from heterogenous source systems onto common data repository/data lake for provisioning data to various downstream teams to help them build their reports and dashboards for various analytics purposes and derive key business insights to enhance the user/customer satisfaction. Use Python, PySpark, Hive QL, Spark, Snowflake, BitBucket, Autosys, Jenkins CI/CD, Tableau, JuPyter, and ShellScripting to design, develop, extract, load, build, and code data models and frameworks. Gather requirements from stakeholders and identify the source data systems that provide transactional data. Build reusable framework and code scripts using python, spark, shell and yaml to automate data pipelines on top of distributed Hadoop cluster. Perform unit and regression testing to make sure developed data pipeline framework meets data quality and integrity standards. Generate key performance indicators metrics from data stored on reporting layer which is built by creating views on top of data objects in data lake and communicate with business teams in regular intervals when any deviations observed in data. May require travel/relocation to unanticipated work locations within the USA.

Require Master of Science in Computer Science/Engineering, computer/management Information Systems/Technology, or related field and 1 year of experience in the job offered, software engineer/developer, data architect/engineer, Hadoop developer/associate/consultant, or related field.

Please mail your resume to Maruthi Technologies, Inc, 14911 Quorum Drive, Suite 390, Dallas, TX 75254

Employment Type: FULL_TIME",False,1690441200,2023-07-27T07:00:00.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=70&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=BTtXgAW3LgEAAAAAAAAAAA%3D%3D",2023-08-27T00:00:00.000Z,1693094400.0,"{'no_experience_required': False, 'required_experience_in_months': 12, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['May require travel/relocation to unanticipated work locations within the USA', 'Require Master of Science in Computer Science/Engineering, computer/management Information Systems/Technology, or related field and 1 year of experience in the job offered, software engineer/developer, data architect/engineer, Hadoop developer/associate/consultant, or related field'], 'Responsibilities': ['Design and develop data pipeline models to extract, transform and load data from heterogenous source systems onto common data repository/data lake for provisioning data to various downstream teams to help them build their reports and dashboards for various analytics purposes and derive key business insights to enhance the user/customer satisfaction', 'Use Python, PySpark, Hive QL, Spark, Snowflake, BitBucket, Autosys, Jenkins CI/CD, Tableau, JuPyter, and ShellScripting to design, develop, extract, load, build, and code data models and frameworks', 'Gather requirements from stakeholders and identify the source data systems that provide transactional data', 'Build reusable framework and code scripts using python, spark, shell and yaml to automate data pipelines on top of distributed Hadoop cluster', 'Perform unit and regression testing to make sure developed data pipeline framework meets data quality and integrity standards', 'Generate key performance indicators metrics from data stored on reporting layer which is built by creating views on top of data objects in data lake and communicate with business teams in regular intervals when any deviations observed in data']}",Data engineer,en,15113200,4,['15-2041.00: Statisticians'],,
YWCs__E_bzUAAAAAAAAAAA==,"Amazon.com Services, Inc.",,,,"Dallas, TX - Geebo",FULLTIME,Senior Data Engineer,https://dallas-tx.geebo.com/jobs-online/view/id/761054315-senior-data-engineer-/,True,0.4224,"Are you interested in innovating to deliver a world-class level of service to Amazon's Vendors and Selling Partners?We are looking for a talented Senior Data Engineer to help build/enhance the data landscape that shapes decision making and recommendations driving further value for our Customers, Vendors, and Selling Partners.
You will help drive data architecture across many large datasets, perform exploratory data analysis, implement new data pipelines that feed into or from critical data systems at Amazon, and your insights will impact millions of Customers, Vendors and Sellers who communicate with each other for mission-critical use cases every day.
As a Senior Data Engineer, you will develop new data engineering patterns that leverage new cloud architectures, and will extend or migrate existing data pipelines to the architectures as needed.
You will also be assisting with integrating the Redshift platform as our primary processing platform to create the curated Amazon.
com data model for the enterprise to leverage.
You will be responsible for designing and implementing the complex ETL pipelines in data warehouse platform and other BI solutions to support the rapidly growing and dynamic business demand for data, and use it to deliver the data as service which will have an immediate influence on day-to-day decision making at Amazon.
com.
Estimated Salary: $20 to $28 per hour based on qualifications.",False,1690416000,2023-07-27T00:00:00.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=70&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=YWCs__E_bzUAAAAAAAAAAA%3D%3D",2023-08-03T00:00:00.000Z,1691020800.0,"{'no_experience_required': False, 'required_experience_in_months': None, 'experience_mentioned': False, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': False, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,20.0,28.0,USD,HOUR,"{'Responsibilities': ['You will help drive data architecture across many large datasets, perform exploratory data analysis, implement new data pipelines that feed into or from critical data systems at Amazon, and your insights will impact millions of Customers, Vendors and Sellers who communicate with each other for mission-critical use cases every day', 'As a Senior Data Engineer, you will develop new data engineering patterns that leverage new cloud architectures, and will extend or migrate existing data pipelines to the architectures as needed', 'You will also be assisting with integrating the Redshift platform as our primary processing platform to create the curated Amazon'], 'Benefits': ['Estimated Salary: $20 to $28 per hour based on qualifications']}",Data engineer,en,15113200,4,,,
mOyDU6ACctkAAAAAAAAAAA==,JPMorgan Chase,https://lookaside.fbsbx.com/lookaside/crawler/media/?media_id=11465191261,http://www.jpmorganchase.com,Finance,Built In,FULLTIME,"Senior Data Engineer- AWS (Dallas, TX)",https://builtin.com/job/data/senior-data-engineer-aws/1898846,False,0.6987,"Job Description
If you're interested in making significant contributions to your team and business, you're heading the right direction, but even more so- with our Data & Analytics team, the difference we make is to help provide tools and resources that give senior management what they need to make decisions that will keep JP Morgan Chase ahead of the competition through leveraging data across Chase to build advantages for the businesses while providing value and protection for customers.
Job summary
The Data Analytics and Reporting (DART) team's mission is to provide high-quality dashboards & insights that executive leadership will use to monitor KPIs, steer the business, and make investment decisions. This team will constantly balance the need for speed with the importance of providing accurate results, to enable leadership to make informed decisions with agility & precision. The position will be part of a team that will take a loosely-defined idea or problem statement, find & acquire the relevant data, design & build the dashboards, develop the automated workflows, and document the details. You will also help to develop frameworks to ensure cross-platform data & logic consistency and optimization. They will write code to enrich and transform data sets to produce output that will help to advance the DART teams objectives and impact to the broader organization.
Job responsibilities
• Perform user acceptance testing and deliver demos to stakeholders by SQL queries or Python scripts.
• Perform data analysis to define / support model development including metadata and data dictionary documentation that will enable data analysis and analytical exploration
• Participate in strategic projects and provide ideas and inputs on ways to leverage quantitative analytics to generate actionable business insights and/or solutions to influence business strategies and identify opportunities to grow
• Partners closely with business partners to identify impactful projects, influence key decisions with data, and ensure client satisfaction

Required qualifications, capabilities, and skills
• Scripting skills e.g. Python, R and experience with tools such as Alteryx or similar tool
• Strong understanding of data and database methodologies as well as hands on Oracle and/or AWS Cloud experience
• Bachelor's degree in a relevant quantitative field (e.g. Statistics, Economics, Finance, Business Analytics, Mathematics, Engineering, Computer Science, Information Technology)
• 5+ years of industry experience in business analytics roles (e.g., marketing analytics, product analytics, business insights)
• 5+ years of work experience across broad range of analytics platforms, languages, and tools (SAS, SQL, Spark and Python, Unix, Excel Pivot etc.); hands-on experience using big data platform required
• Strong understanding of CI/CD Pipelines in a globally distributed environment using Git, Bit-Bucket, Jenkins, Spinnaker, etc.
• Experience with the entire Software Development Life Cycle (SDLC) including planning, analysis, development and testing of new applications and enhancements to existing application.

Preferred qualifications, capabilities, and skills
• Master's degree or Bachelor degree with 5+ years experience in a relevant quantitative field (e.g. Statistics, Economics, Finance, Business Analytics, Mathematics, Engineering, Computer Science or any related fields involving significant quantitative research & data analytics)
• Strong communicator who's able to convey complex information in an understandable, compelling, and persuasive manner to business partners
• Results-oriented with a strong attention to details
• Strong knowledge in quantitative methods for business analytics; proficiency in critical thinking and problem solving

About Us
Chase is a leading financial services firm, helping nearly half of America's households and small businesses achieve their financial goals through a broad range of financial products. Our mission is to create engaged, lifelong relationships and put our customers at the heart of everything we do. We also help small businesses, nonprofits and cities grow, delivering solutions to solve all their financial needs.
We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants' and employees' religious practices and beliefs, as well as any mental health or physical disability needs.
The health and safety of our colleagues, candidates, clients and communities has been a top priority in light of the COVID-19 pandemic. JPMorgan Chase was awarded the ""WELL Health-Safety Rating"" for all of our 6,200 locations globally based on our operational policies, maintenance protocols, stakeholder engagement and emergency plans to address a post-COVID-19 environment.
As a part of our commitment to health and safety, we have implemented various COVID-related health and safety requirements for our workforce. Employees are expected to follow the Firm's current COVID-19 or other infectious disease health and safety requirements, including local requirements. Requirements include sharing information including your vaccine card in the firm's vaccine record tool, and may include mask wearing. Requirements may change in the future with the evolving public health landscape. JPMorgan Chase will consider accommodation requests as required by applicable law.
We offer a competitive total rewards package including base salary determined based on the role, experience, skill set, and location. For those in eligible roles, discretionary incentive compensation which may be awarded in recognition of individual achievements and contributions. We also offer a range of benefits and programs to meet employee needs, based on eligibility. These benefits include comprehensive health care coverage, on-site health and wellness centers, a retirement savings plan, backup childcare, tuition reimbursement, mental health support, financial coaching and more. Additional details about total compensation and benefits will be provided during the hiring process.
Equal Opportunity Employer/Disability/Veterans
About the Team
Our Consumer & Community Banking division serves our Chase customers through a range of financial services, including personal banking, credit cards, mortgages, auto financing, investment advice, small business loans and payment processing. We're proud to lead the U.S. in credit card sales and deposit growth and have the most-used digital solutions - all while ranking first in customer satisfaction.",False,1688270440,2023-07-02T04:00:40.000Z,Dallas,TX,US,32.776665,-96.79699,"['health_insurance', 'retirement_savings', 'dental_coverage']","https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=70&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=mOyDU6ACctkAAAAAAAAAAA%3D%3D",,,"{'no_experience_required': False, 'required_experience_in_months': 60, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': True, 'degree_mentioned': True, 'degree_preferred': True, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['Scripting skills e.g. Python, R and experience with tools such as Alteryx or similar tool', 'Strong understanding of data and database methodologies as well as hands on Oracle and/or AWS Cloud experience', ""Bachelor's degree in a relevant quantitative field (e.g. Statistics, Economics, Finance, Business Analytics, Mathematics, Engineering, Computer Science, Information Technology)"", '5+ years of industry experience in business analytics roles (e.g., marketing analytics, product analytics, business insights)', '5+ years of work experience across broad range of analytics platforms, languages, and tools (SAS, SQL, Spark and Python, Unix, Excel Pivot etc.); hands-on experience using big data platform required', 'Strong understanding of CI/CD Pipelines in a globally distributed environment using Git, Bit-Bucket, Jenkins, Spinnaker, etc', 'Experience with the entire Software Development Life Cycle (SDLC) including planning, analysis, development and testing of new applications and enhancements to existing application'], 'Responsibilities': [""The Data Analytics and Reporting (DART) team's mission is to provide high-quality dashboards & insights that executive leadership will use to monitor KPIs, steer the business, and make investment decisions"", 'This team will constantly balance the need for speed with the importance of providing accurate results, to enable leadership to make informed decisions with agility & precision', 'The position will be part of a team that will take a loosely-defined idea or problem statement, find & acquire the relevant data, design & build the dashboards, develop the automated workflows, and document the details', 'You will also help to develop frameworks to ensure cross-platform data & logic consistency and optimization', 'They will write code to enrich and transform data sets to produce output that will help to advance the DART teams objectives and impact to the broader organization', 'Perform user acceptance testing and deliver demos to stakeholders by SQL queries or Python scripts', 'Perform data analysis to define / support model development including metadata and data dictionary documentation that will enable data analysis and analytical exploration', 'Participate in strategic projects and provide ideas and inputs on ways to leverage quantitative analytics to generate actionable business insights and/or solutions to influence business strategies and identify opportunities to grow', 'Partners closely with business partners to identify impactful projects, influence key decisions with data, and ensure client satisfaction'], 'Benefits': ['We offer a competitive total rewards package including base salary determined based on the role, experience, skill set, and location', 'For those in eligible roles, discretionary incentive compensation which may be awarded in recognition of individual achievements and contributions', 'We also offer a range of benefits and programs to meet employee needs, based on eligibility', 'These benefits include comprehensive health care coverage, on-site health and wellness centers, a retirement savings plan, backup childcare, tuition reimbursement, mental health support, financial coaching and more']}",Data engineer,en,15113200,4,,523920,Portfolio Management
B9mwS3vp2lgAAAAAAAAAAA==,Ad Hoc Team,https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTLqIeSWzqeEd9GPo6i2Vz7XXH8GRDbuUwF3NLz&s=0,,,Glassdoor,FULLTIME,Data Engineer (Remote),"https://www.glassdoor.com/job-listing/data-engineer-remote-ad-hoc-dc-JV_IC1139977_KO0,20_KE21,30.htm?jl=1008732513836",True,0.573,"This is a fully remote position.

Work on things that matter

Ad Hoc is a digital services company that helps the federal government better serve people. Our teams use modern, agile methods to design and engineer government systems that connect Veterans with services, bring affordable health care to millions of people, and support important programs like Head Start. And as we work to make critical government services intuitive, accessible, and human-centered, we're also changing how the government thinks about and uses technology. If you thrive on change, want to help close the gap between consumer expectations and government services, and can see the possibilities in ambiguity, then we want you here with us.

What matters most

Ad Hoc operates according to our commitment to inclusivity, acceptance, accountability, and humility. We aren't heroes. We believe in missions larger than our individual selves and leave our egos at the door, learn from our mistakes, and iterate in order to better serve the people in our country. We prioritize building teams that represent the diversity of the people our government serves. We love the challenge of government-size projects. We want to bring skills to federal agencies, help them better meet the needs of their users, and close the gap between consumer expectations and government.

Built for a remote life

Ad Hoc is remote-first and remote-always. We've designed our culture, communications, and tools to support a nationwide distributed team since the beginning. Being remote by design allows Ad Hoc to be thoughtful and intentional about creating diverse teams and supporting them with a work environment that fits their lives. With a generous PTO policy and Slack channels for every interest (from bird watching to space nerds to parenting) our culture embraces the things happening in your life. Maybe you need to adjust your schedule to care for your family or take a bike ride. At Ad Hoc, that's embraced.

What you'll do

Data Engineers are responsible for working with the systems and infrastructure that enable data storage, processing, and analysis. They work closely with data scientists and analysts to ensure that data is properly collected, organized, enriched, refined, and available for analysis. They are the critical connectors between the teams that maintain existing legacy systems, and the data analysts and data scientists that will use aggregated data for analysis, reporting, and predictive analytics.
• Shipping software that impacts the lives of millions of people
• Using modern programming languages and frameworks to build scalable services that gracefully integrate with legacy systems
• Building and working with APIs to support both the digital services we deliver as well as third-party usage
• Helping us continuously, iteratively improve

What we hope you'll bring
• A minimum of four (4) years of professional software development experience
• AWS experience
• Understanding of ETL/ELT processes and tooling
• Understanding of database technologies - setup/ maintenance / data loads / etc. (not data modeling)
• Redshift experience preferred
• Understand system security
• API design and implementation
• GIT and DevOps release process
• Python or Scala, Python is preferred for ETL
• Some experience with older file systems / file based processes such as MOVEit
• Some experience with Mulesoft
• Experience with agile software development practices emphasizing agility, flexibility, and iterative development

More than that, our ideal candidate wants to contribute to work that is bigger than themselves and wants to make a difference collaborating with their team. They care deeply about building better products, better relationships, and better trust in each interaction people have with their government. They believe in intuitive, easy-to-use government services. They collaborate well with designers, stakeholders, and other teams. They mentor and guide more junior engineers. They're human-centered.

And if you don't check every box on the list? That doesn't mean you can't help us in our mission to deliver critical government services. Talk to us!

Some basic requirements
• All work must be conducted within the U.S., excluding U.S. territories. Some federal contracts require U.S. citizenship to be eligible for employment.
• You must be legally authorized to work in the U.S now and in the future without sponsorship.
• As a government contractor, you may be required to obtain a public trust security clearance.
• Bachelor's Degree in a technical field is preferred
• 4 years of professional software development
• Our technical screening involves completing a homework assignment that is then graded blind to remove bias. We do not do tricky, unreliable whiteboarding tests. You can read more about our homework here.

Learn more about engineering at Ad Hoc.

Benefits
• Company-subsidized Health, Dental, and Vision Insurance
• Use What You Need Vacation Policy
• 401K with employer match
• Paid parental leave after one year of service

Ad Hoc LLC is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, national origin, ancestry, sex, sexual orientation, gender identity or expression, religion, age, pregnancy, disability, work-related injury, covered veteran status, political ideology, marital status, or any other factor that the law protects from employment discrimination.

In support of the Colorado Equal Pay Transparency Act, and others like it across the country, Ad Hoc job descriptions feature the starting range we reasonably expect to pay to candidates who would join our team with little to no need for training on the responsibilities we've outlined above. Actual compensation is influenced by a wide range of factors including but not limited to skill set, level of experience, and responsibility. The range of starting pay for this role is $101,570 - $136,994 and information on benefits offered is here. Our recruiters will be happy to answer any questions you may have, and we look forward to learning more about your salary requirements.

job reference: 2015",True,1688083200,2023-06-30T00:00:00.000Z,Dallas,TX,US,32.776665,-96.79699,"['paid_time_off', 'dental_coverage', 'health_insurance', 'retirement_savings']","https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=70&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=B9mwS3vp2lgAAAAAAAAAAA%3D%3D",,,"{'no_experience_required': False, 'required_experience_in_months': 48, 'experience_mentioned': True, 'experience_preferred': True}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': True, 'professional_certification_mentioned': False}",False,101570.0,136994.0,USD,YEAR,"{'Qualifications': ['We want to bring skills to federal agencies, help them better meet the needs of their users, and close the gap between consumer expectations and government', 'A minimum of four (4) years of professional software development experience', 'AWS experience', 'Understanding of ETL/ELT processes and tooling', 'Understanding of database technologies - setup/ maintenance / data loads / etc', '(not data modeling)', 'Understand system security', 'Some experience with older file systems / file based processes such as MOVEit', 'Some experience with Mulesoft', 'Experience with agile software development practices emphasizing agility, flexibility, and iterative development', 'All work must be conducted within the U.S., excluding U.S. territories', 'Some federal contracts require U.S. citizenship to be eligible for employment', 'You must be legally authorized to work in the U.S now and in the future without sponsorship', 'As a government contractor, you may be required to obtain a public trust security clearance'], 'Responsibilities': ['Data Engineers are responsible for working with the systems and infrastructure that enable data storage, processing, and analysis', 'They work closely with data scientists and analysts to ensure that data is properly collected, organized, enriched, refined, and available for analysis', 'They are the critical connectors between the teams that maintain existing legacy systems, and the data analysts and data scientists that will use aggregated data for analysis, reporting, and predictive analytics', 'Shipping software that impacts the lives of millions of people', 'Using modern programming languages and frameworks to build scalable services that gracefully integrate with legacy systems', 'Building and working with APIs to support both the digital services we deliver as well as third-party usage', 'Helping us continuously, iteratively improve'], 'Benefits': ['Company-subsidized Health, Dental, and Vision Insurance', 'Use What You Need Vacation Policy', '401K with employer match', 'Paid parental leave after one year of service', 'The range of starting pay for this role is $101,570 - $136,994 and information on benefits offered is here']}",Data engineer,en,15113200,4,,,
4cTj1j-ZIEwAAAAAAAAAAA==,McKinsey & Company,https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTe9SJcOULyOseFld0yxO8Tun4CwnLPCamc7rqf&s=0,,Consulting,JobzMall,FULLTIME,Data Engineer,https://www.jobzmall.com/mckinsey-company/job/data-engineer-113,True,0.5696,"Your main expertise and responsibility will be data identification and extraction. Leveraging proprietary and third-party data-extraction tools (e.g. Snaplogic), you will identify spend relevant data from general ledger, purchase order, material & supplier master and other relevant tables within ERP or data/business warehouse applications. You will conduct data assessment, perform data quality checks, transform and load raw data using SQL and ETL tools. With your experience in data engineering and data models, you will build sustainable data pipelines and adjust them for special needs. You will conduct data assessment, perform data quality checks, transform and load raw data using SQL and ETL tools. With your experience in data engineering and data models, you will build sustainable data pipelines and adjust them for special needs.

McKinsey & Company is an Equal Opportunity Employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. We do not discriminate based upon race, religion, color, national origin, sex, sexual orientation, gender identity, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.",False,1610146599,2021-01-08T22:56:39.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=70&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=4cTj1j-ZIEwAAAAAAAAAAA%3D%3D",2023-08-26T23:59:59.000Z,1693094399.0,"{'no_experience_required': False, 'required_experience_in_months': None, 'experience_mentioned': True, 'experience_preferred': False}",['Java <br>Time Management <br>Process Improvement <br>Verbal communication <br>VBA <br>Tableau <br>Alteryx <br>Macros <br>PowerShell <br>Detail Oriented <br>Prioritizing skills <br>written communication <br>Adaptability <br>Spend analysis <br>Data visualization and reporting toolsProcess Improvement <br>Verbal communication <br>Detail Oriented <br>Prioritizing skills <br>written communication <br>Adaptability'],"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': True, 'degree_mentioned': False, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,,,,,"{'Responsibilities': ['Your main expertise and responsibility will be data identification and extraction', 'Leveraging proprietary and third-party data-extraction tools (e.g. Snaplogic), you will identify spend relevant data from general ledger, purchase order, material & supplier master and other relevant tables within ERP or data/business warehouse applications', 'You will conduct data assessment, perform data quality checks, transform and load raw data using SQL and ETL tools', 'With your experience in data engineering and data models, you will build sustainable data pipelines and adjust them for special needs']}",Data engineer,en,15113200,4,,54161,Management Consulting Services
vQeezN_YDuwAAAAAAAAAAA==,The Beneficient Company Group USA LLC,https://www.mg21.com/wp-content/uploads/2022/09/The-Beneficient-Company-Group.png,,,Lensa,FULLTIME,Data Engineer/Analyst,https://lensa.com/data-engineeranalyst-jobs/dallas/jd/d9df6f49861354a487aa4b420188497a,False,0.4711,"Position Summary:

Ben’s Data Engineer/Analyst will be responsible for designing and implementing ETL, Storage, and Reporting solutions. Ben requires a technical background working with regulated environments, demonstrated Data Management skills, and a self-motivated attitude.

Essential Functions:
• Manage data design and the creation of database architecture and data repositories
• Facilitate Data ETL for customer facing and internal processes
• Work with departments throughout Ben that are creating data or ingesting data to build and maintain a documented set of information life cycles; serve as a knowledge resource, it must have a clear understanding of our processes and the resulting data
• Ensure that data projects and milestones are met
• Follow PMO/Release/Change Management policies/procedures
• Follow and participate in all IT projects and initiatives to effectively develop and maintain an understanding of existing and new data flows
• Interface with Project Managers, Developers, and Production support to keep processes, databases, and reports kept up to date with all changes
• Engage stakeholders to understand and document business requirements, translate them into technical requirements, and then deliver the solution
• Install processes for auditing data warehouse transfers, storage, and data quality
• In-depth understanding of Python programming/objects
• Work with stakeholders across the company that are responsible for data governance and drive the business to consensus.
• Support release management in deployment efforts
• Develop data flow diagrams (technical and functional)
• Single source of truth analysis
Knowledge, Skills, Abilities and Competencies:
• Experience with various ETL tools in an audited environment.
• Experience working with source control (git)
• Experience with Data Warehouse technologies
• Experience with enterprise reporting packages
• Technical bachelor’s degree or equivalent experience required
• 5+ years of IT industry experience required
• 5+ years of database (SQL) experience required
• 4+ year of ETL experience required
• 3+ years of Python experience required
Qualifications:
• 2+ years Snowflake experience preferred
• 3+ years of reporting experience preferred (Tableau)
• 1+ years cloud experience (AWS Lambda, S3, SQS, CloudFormation preferred)
• Matillion experience preferred
• Experience with CI/CD Pipelines preferred
• Experience with monitoring and audit tools preferred

Ideal Candidate Skills:

SQL, ETL, Python, Snowflake, Matillion, Tableau, AWS Lambda, AWS S3, AWS SQS, AWS CloudFormation

Work Model:

At present, the Ben I.T. Application Development Team has a hybrid work model that includes 2 in-office days and 3 work-from-home days per week as the rule, with rare exceptions announced in advance.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, disability, sexual orientation, national origin or any other category protected by law.",False,1688343552,2023-07-03T00:19:12.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=70&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=vQeezN_YDuwAAAAAAAAAAA%3D%3D",2023-08-02T00:19:12.000Z,1690935552.0,"{'no_experience_required': False, 'required_experience_in_months': 60, 'experience_mentioned': True, 'experience_preferred': True}","['Reading Comprehension', 'Active Listening', 'Writing', 'Speaking', 'Critical Thinking', 'Active Learning', 'Monitoring', 'Social Perceptiveness', 'Coordination', 'Complex Problem Solving', 'Programming', 'Judgment and Decision Making', 'Systems Analysis', 'Systems Evaluation']","{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['Ben requires a technical background working with regulated environments, demonstrated Data Management skills, and a self-motivated attitude', 'Experience with various ETL tools in an audited environment', 'Experience working with source control (git)', 'Experience with Data Warehouse technologies', 'Experience with enterprise reporting packages', 'Technical bachelor’s degree or equivalent experience required', '5+ years of database (SQL) experience required', '4+ year of ETL experience required', '3+ years of Python experience required', 'SQL, ETL, Python, Snowflake, Matillion, Tableau, AWS Lambda, AWS S3, AWS SQS, AWS CloudFormation'], 'Responsibilities': ['Ben’s Data Engineer/Analyst will be responsible for designing and implementing ETL, Storage, and Reporting solutions', 'Manage data design and the creation of database architecture and data repositories', 'Facilitate Data ETL for customer facing and internal processes', 'Work with departments throughout Ben that are creating data or ingesting data to build and maintain a documented set of information life cycles; serve as a knowledge resource, it must have a clear understanding of our processes and the resulting data', 'Ensure that data projects and milestones are met', 'Follow PMO/Release/Change Management policies/procedures', 'Follow and participate in all IT projects and initiatives to effectively develop and maintain an understanding of existing and new data flows', 'Interface with Project Managers, Developers, and Production support to keep processes, databases, and reports kept up to date with all changes', 'Engage stakeholders to understand and document business requirements, translate them into technical requirements, and then deliver the solution', 'Install processes for auditing data warehouse transfers, storage, and data quality', 'In-depth understanding of Python programming/objects', 'Work with stakeholders across the company that are responsible for data governance and drive the business to consensus', 'Support release management in deployment efforts', 'Develop data flow diagrams (technical and functional)', 'Single source of truth analysis']}",,en,43911100,4,['15-1199.06 Database Architects'],,
rLA-OhanVgEAAAAAAAAAAA==,H-E-B,https://www.heb.com/img/header/logo.png,http://www.heb.com,Retail,Talent.com,FULLTIME,Senior data engineer,https://www.talent.com/view?id=d7d2d7817df4,False,0.5006,"Overview

H-E-B is one of the largest, independently owned food retailers in the nation operating over 420+ stores throughout Texas and Mexico, with annual sales generating over $34 billion.

Described by industry experts as a daring innovator and smart competitor, H-E-B has led the way with creative new concepts, outstanding service and a commitment to diversity in our workforce, workplace and marketplace.

H-E-B offers a wealth of career opportunities to our 145,000+ Partners (employees), competitive compensation and benefits program and comprehensive training that lead to successful careers.

Responsibilities

Since H-E-B Digital Technology's inception, we've been investing heavily in our customers' digital experience, reinventing how they find inspiration from food, how they make food decisions, and how they ultimately get food into their homes.

This is an exciting time to join H-E-B Digital we're using the best available technologies to deliver modern, engaging, reliable, and scalable experiences to meet the needs of our growing audience.

If you enjoy taking on new challenges, working in a rapidly changing environment, learning new skills, and applying it all to solve large and impactful business problems, we want you as part of our team.

Our team is made up of data engineers with various levels of experience. The primary focus is current customer data which our team consolidates, cleanses, formats and validates for various stakeholders within our Digital team.

As a Data Engineer you'll :

Design and build a modern data warehouse in the cloud

Enhance data collection procedures to build analytic systems.

Work as an Agile partner and participate in back log refinement, sprint planning, review, and retrospective.

Coach and mentor junior engineers in engineering techniques, processes, and new technologies; enable others to succeed.

Contribute to overall system design, architecture, security, scalability, reliability, and performance of applications.

Support the build and deployment pipeline and when necessary, both diagnose and solve production support issues.

Work with Product, Design, and QA to deliver world-class digital experiences.

Get the opportunity to stay ahead of new technologies with an eye to evaluating and potentially incorporating them into your team's architecture.

Who You Are :

3-5+ years of experience with ETL, Data Modeling, Data Warehousing, and working with large-scale datasets (enterprise experience is a plus!)

3-5+ years of hands-on experience in multiple modern programming languages such as Python or Java

2+ years of experience leveraging DevOps principals such as CI / CD and using tools like Git, Jenkins, etc.

Strong working knowledge of Data Engineering and associated tools and technologies like Apache, Spark, Databricks, Python, SQL, and data lake concepts.

Experience with Argo Informatica

Working experience with AWS services such as Lambda, RDS, ECS, DynamoDB, API Gateway, S3, etc.

Bachelor’s degree in Computer Engineering, Computer Science or related discipline, Master’s Degree preferred

An equivalent combination of education and experience may be accepted as a satisfactory substitute for the specific education and experience listed above.

It’s a Plus if you have :

Experience working with other public cloud technologies AWS, GCP

Hands on experience with data virtualization technologies : CIS (Tibco), Denodo, or SQL 2019 Virtualization

Experience building test automation to ensure data quality and accuracy

Proficient in data modeling (specifically RDS, PostgreSQL, Oracle)

DATA3232

Options

Last updated : 2023-07-24",False,1690156800,2023-07-24T00:00:00.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=70&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=rLA-OhanVgEAAAAAAAAAAA%3D%3D",2023-08-16T00:00:00.000Z,1692144000.0,"{'no_experience_required': False, 'required_experience_in_months': 36, 'experience_mentioned': True, 'experience_preferred': True}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': True, 'degree_mentioned': True, 'degree_preferred': True, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['3-5+ years of hands-on experience in multiple modern programming languages such as Python or Java', '2+ years of experience leveraging DevOps principals such as CI / CD and using tools like Git, Jenkins, etc', 'Strong working knowledge of Data Engineering and associated tools and technologies like Apache, Spark, Databricks, Python, SQL, and data lake concepts', 'Experience with Argo Informatica', 'Working experience with AWS services such as Lambda, RDS, ECS, DynamoDB, API Gateway, S3, etc', 'An equivalent combination of education and experience may be accepted as a satisfactory substitute for the specific education and experience listed above', 'Experience working with other public cloud technologies AWS, GCP', 'Hands on experience with data virtualization technologies : CIS (Tibco), Denodo, or SQL 2019 Virtualization', 'Experience building test automation to ensure data quality and accuracy', 'Proficient in data modeling (specifically RDS, PostgreSQL, Oracle)'], 'Responsibilities': ['Design and build a modern data warehouse in the cloud', 'Enhance data collection procedures to build analytic systems', 'Work as an Agile partner and participate in back log refinement, sprint planning, review, and retrospective', 'Coach and mentor junior engineers in engineering techniques, processes, and new technologies; enable others to succeed', 'Contribute to overall system design, architecture, security, scalability, reliability, and performance of applications', 'Support the build and deployment pipeline and when necessary, both diagnose and solve production support issues', 'Work with Product, Design, and QA to deliver world-class digital experiences']}",Data engineer,en,15113200,4,['15-1243.00'],445110,Supermarkets and Other Grocery (except Convenience) Stores
U3j2JDYImI0AAAAAAAAAAA==,"Logic20/20, Inc.","https://res.cloudinary.com/crunchbase-production/image/upload/c_lpad,f_auto,q_auto:eco,dpr_1/ffwrq37xnvyhjt1nwrdm",http://www.logic2020.com,,LinkedIn,FULLTIME,Cloud Data Engineer,https://www.linkedin.com/jobs/view/cloud-data-engineer-at-logic20-20-inc-3676014190,False,0.5875,"Company Description

Logic20/20 invests in being a “Best Company to Work For,” where talented people come together to deliver exceptional solutions. We bring clarity, insights, and optimization to enterprise organizations spanning technology, telecommunications, utilities, healthcare, and more.

We thrive as One Team, built on values:
• We Foster a Culture of We by prioritizing connection and collaboration.
• We Drive toward Excellence by investing in professional growth and cultivating thought leadership.
• We Act with Integrity by doing the right thing and bringing our best selves to the table.

To make it all possible, we’ve created programs, resources, and benefits that promote connection and help you evolve your career.

Job Description

As a senior or lead Data Engineer joining Logic20/20's Advanced Analytics practice, you'll be supporting a team at one of the largest utility companies in California creating data pipelines to land data in an AWS data lake, and working with data transformation and integration to support future analytics. You will improve risk modeling that will allow the client to better understand the integrity of their pipelines for improved customer safety.

Hear more about these efforts as Jeff Lovington shares his experience working in Data Science and Machine Learning for the Energy & Utilities sector.

About The Team

The Logic20/20 Advanced Analytics team is where skilled professionals in data engineering, data science, and visual analytics join forces to build simple solutions for complex data problems. We make it look like magic, but for us, it’s all in a day’s work. As part of our team, you’ll collaborate on projects that help clients spin their data into a high-performance asset, all while enjoying the company of kindred spirits who are as committed to your success as you are. And when you’re ready to level up in your career, you’ll have access to the training, the project opportunities, and the mentorship to get you where you want to go.

“We build an environment where we really operate as one team, building up each other’s careers and capabilities.” – Adam Cornille, Senior Director, Advanced Analytics

Qualifications

Must have:
• 5+ years of cloud data engineering experience
• Strong experience designing and developing cloud ELT and data pipelines with AWS, Python, SQL, Athena
• Must also have experience with the following technology: CLI, Glue, RDS, Pandas, KMS, S3
• Experience with developing and operating CI/CD pipelines and other DataOps fundamentals
• Strong understanding of data modeling, data pipelines, data lakes
• Excellent foundation of consulting skills: analytical, written and verbal communication, and presentation skills
• Demonstrated ability to identify business and technical impacts of user requirements and incorporate them into the project schedule 
• Bachelor's degree in Computer Science, Engineering, or a related field

Preferred:
• Experience with creating custom-built apps on a large scale
• Experience working in the utility industry

Additional Information

All your information will be kept confidential according to EEO guidelines.

Compensation range for senior data engineer: $125,000 - $175,000 annually

Compensation range for lead data engineer: $145,000 - $195,000 annually

About Logic20/20

To learn more about Logic20/20, please visit: https://www.logic2020.com/careers/life-at-logic

Core Values

At Logic20/20, we are guided by three core values: Drive toward Excellence, Act with Integrity & Foster a Culture of We. These values were generated and agreed upon by our employees—and they help us pursue our goal of being one of the best companies to work for and to work with. Learn more at https://www.logic2020.com/company/our-values.

Logic20/20 Benefits

Why Logic20/20? It’s our goal to be one of the best companies to work for. One piece of the puzzle is an evolving set of benefits that extend past medical, dental, and 401(k).

You will have
• Career Development – A built-in program from day 1, providing a mentor and individually-directed training opportunities, plus access to leaders across the company
• PTO, Paid Holidays, & Voluntary Leave – Worry-free time off to recharge and pursue your personal goals
• Community & Committees – As part of our “Culture of We,” Logic20/20 invests in providing many social, interest, and learning opportunities
• Recognition – From peer recognition, swag, and the chance to win a once-in-a-lifetime type of award, we make your Logic20/20 journey stand out
• Referral Programs & Bonuses – Employee, project, and sales referral programs with paid incentives

Equal Opportunity Statement

We believe that people should be celebrated: for their talents, ideas, and skills, but most of all, for what makes them unique. We prohibit harassment and/or discrimination based on age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status, or any other basis as protected by federal, state, or local law.

To learn more about our DE&I initiatives, please visit: https://www.logic2020.com/company/diversity-equity-inclusion

Privacy Policy

During the recruitment and hiring process, we gather, process, and store some of your personal data. We consider data privacy a priority. For further information, please view our company privacy policy.",False,1690329600,2023-07-26T00:00:00.000Z,Dallas,TX,US,32.776665,-96.79699,"['retirement_savings', 'paid_time_off', 'dental_coverage', 'health_insurance']","https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=70&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=U3j2JDYImI0AAAAAAAAAAA%3D%3D",2023-08-25T22:19:11.000Z,1693001951.0,"{'no_experience_required': False, 'required_experience_in_months': 60, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': True, 'degree_mentioned': True, 'degree_preferred': True, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['5+ years of cloud data engineering experience', 'Strong experience designing and developing cloud ELT and data pipelines with AWS, Python, SQL, Athena', 'Must also have experience with the following technology: CLI, Glue, RDS, Pandas, KMS, S3', 'Experience with developing and operating CI/CD pipelines and other DataOps fundamentals', 'Strong understanding of data modeling, data pipelines, data lakes', 'Excellent foundation of consulting skills: analytical, written and verbal communication, and presentation skills', 'Demonstrated ability to identify business and technical impacts of user requirements and incorporate them into the project schedule\u202f', ""Bachelor's degree in Computer Science, Engineering, or a related field""], 'Responsibilities': ['You will improve risk modeling that will allow the client to better understand the integrity of their pipelines for improved customer safety'], 'Benefits': ['Compensation range for senior data engineer: $125,000 - $175,000 annually', 'Compensation range for lead data engineer: $145,000 - $195,000 annually', 'Career Development – A built-in program from day 1, providing a mentor and individually-directed training opportunities, plus access to leaders across the company', 'PTO, Paid Holidays, & Voluntary Leave – Worry-free time off to recharge and pursue your personal goals', 'Community & Committees – As part of our “Culture of We,” Logic20/20 invests in providing many social, interest, and learning opportunities', 'Recognition – From peer recognition, swag, and the chance to win a once-in-a-lifetime type of award, we make your Logic20/20 journey stand out', 'Referral Programs & Bonuses – Employee, project, and sales referral programs with paid incentives']}",Data engineer,en,15113200,4,,,
ggGlVmkBy6AAAAAAAAAAAA==,Seamless.AI,,,,WAVY Jobs,FULLTIME,Vice President of Data Engineering,https://jobs.wavy.com/jobs/vice-president-of-data-engineering-dallas-texas/1073551209-2/,False,0.5612,"The Opportunity

We are seeking a highly experienced and talented Vice President of Data Engineering to join our fast-growing SaaS company. The ideal candidate will have a proven track record in building robust data pipelines and processes, along with a strong background in AWS, Python, and data consolidation techniques. Reporting directly to the CTO, this strategic role requires excellent communication and organization skills, as well as the ability to lead and mentor a team. The Vice President of Data Engineering will play a crucial role in driving our companys growth and scalability by managing budgets, reporting on ROI, and analyzing team and individual metrics.

Role Responsibilities
• Lead the design, development, implementation, and maintenance of scalable data pipelines and processes to support our rapidly growing SaaS platform.
• Oversee the consolidation, validation, and transformation of data from various sources into a unified and reliable format.
• Collaborate closely with cross-functional teams to understand business requirements and provide data solutions that meet their needs.
• Manage and mentor a team of data engineers, fostering a collaborative and high-performance work environment.
• Develop and enforce best practices for data engineering, including coding standards, documentation, and quality assurance processes.
• Stay up-to-date with industry trends, emerging technologies, and advancements in data engineering techniques, and assess their potential impact on our business.
• Effectively communicate complex technical concepts to non-technical stakeholders, including executives and other department heads.
• Take ownership of the data engineering budget, including resource allocation, vendor management, and cost optimization.
• Analyze and report on the ROI of data engineering initiatives, identifying areas for improvement and recommending actionable strategies.
• Track team and individual performance metrics, providing constructive feedback and implementing performance improvement plans as necessary.

Candidate Requirements
• Bachelors or masters degree in computer science, engineering, or a related field.
• Proven experience in a similar role, preferably in a fast-growing SaaS company.
• Strong expertise in building scalable data pipelines using AWS services such as S3, Glue, Redshift, and Lambda.
• Proficiency in Python programming and related frameworks/libraries for data engineering tasks.
• Solid understanding of data consolidation and validation techniques, including data cleansing, deduplication, and data integrity checks.
• Excellent communication and interpersonal skills, with the ability to collaborate effectively with both technical and non-technical stakeholders.
• Strong organizational skills and the ability to manage multiple priorities in a fast-paced environment.
• Demonstrated leadership experience, with the ability to mentor and develop a high-performing team.
• Analytical mindset with a focus on data-driven decision-making.
• Experience managing budgets and reporting on financial and performance metrics.
• Strong business acumen and the ability to align data engineering strategies with company goals and objectives.

Seamless.AI has been delivering the worlds best sales leads since 2015. Our product is the first real time, B2B search engine helping sales teams maximize revenue, increase sales, and easily acquire their total addressable market using artificial intelligence. We have been recognized as one of Ohio's fastest growing companies and won 2020 Best Places to Work and LinkedIn's Top 50 Tech Startups in 2020 and 2022. We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. Visa Sponsorship is not included in our hiring package. Applicants will need to be authorized to work in the U.S.",False,1690295159,2023-07-25T14:25:59.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=70&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=ggGlVmkBy6AAAAAAAAAAAA%3D%3D",,,"{'no_experience_required': False, 'required_experience_in_months': None, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': True, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['The ideal candidate will have a proven track record in building robust data pipelines and processes, along with a strong background in AWS, Python, and data consolidation techniques', 'Bachelors or masters degree in computer science, engineering, or a related field', 'Proven experience in a similar role, preferably in a fast-growing SaaS company', 'Strong expertise in building scalable data pipelines using AWS services such as S3, Glue, Redshift, and Lambda', 'Proficiency in Python programming and related frameworks/libraries for data engineering tasks', 'Solid understanding of data consolidation and validation techniques, including data cleansing, deduplication, and data integrity checks', 'Excellent communication and interpersonal skills, with the ability to collaborate effectively with both technical and non-technical stakeholders', 'Strong organizational skills and the ability to manage multiple priorities in a fast-paced environment', 'Demonstrated leadership experience, with the ability to mentor and develop a high-performing team', 'Analytical mindset with a focus on data-driven decision-making', 'Experience managing budgets and reporting on financial and performance metrics', 'Strong business acumen and the ability to align data engineering strategies with company goals and objectives'], 'Responsibilities': ['Reporting directly to the CTO, this strategic role requires excellent communication and organization skills, as well as the ability to lead and mentor a team', 'The Vice President of Data Engineering will play a crucial role in driving our companys growth and scalability by managing budgets, reporting on ROI, and analyzing team and individual metrics', 'Lead the design, development, implementation, and maintenance of scalable data pipelines and processes to support our rapidly growing SaaS platform', 'Oversee the consolidation, validation, and transformation of data from various sources into a unified and reliable format', 'Collaborate closely with cross-functional teams to understand business requirements and provide data solutions that meet their needs', 'Manage and mentor a team of data engineers, fostering a collaborative and high-performance work environment', 'Develop and enforce best practices for data engineering, including coding standards, documentation, and quality assurance processes', 'Stay up-to-date with industry trends, emerging technologies, and advancements in data engineering techniques, and assess their potential impact on our business', 'Effectively communicate complex technical concepts to non-technical stakeholders, including executives and other department heads', 'Take ownership of the data engineering budget, including resource allocation, vendor management, and cost optimization', 'Analyze and report on the ROI of data engineering initiatives, identifying areas for improvement and recommending actionable strategies', 'Track team and individual performance metrics, providing constructive feedback and implementing performance improvement plans as necessary']}",Data engineering,en,11302100,4,,,
gEFo3LqOIkEAAAAAAAAAAA==,Parkland Health and Hospital System,,,,ZipRecruiter,FULLTIME,Data Engineer - PCHP,"https://www.ziprecruiter.com/c/Parkland-Health-and-Hospital-System/Job/Data-Engineer-PCHP/-in-Dallas,TX?jid=8029868922761f0f",False,0.7163,"Interested in a career with both meaning and growth? Whether your abilities are in direct patient care or one of the many other areas of healthcare administration and support, everyone at Parkland works together to fulfill our mission: the health and well-being of individuals and communities entrusted to our care. By joining Parkland, you become part of a diverse healthcare legacy that's served our community for more than 125 years. Put your skills to work with us, seek opportunities to learn and join a talented team where patient care is more than a job. It's our passion.

Primary Purpose

The Parkland Community Health Plan's (PCHP's) Data Engineer is responsible for maintaining the data systems including business intelligence, ETL, and supporting backup strategies in order to provide PCHP with secure, dependable, and accurate data including data transfer, data integrity, and data storage responsibilities. The Data Engineer will collaborate with Database Administrators, server team, storage team, and other teams to plan maintenance activities and with PHCP's analytics team for report or universe deployments. The Data Engineer will also be involved in dashboard and report development activities.

Minimum Specifications

Education
• Bachelor's degree in computer science, management information systems, information technology, statistics, mathematics, or related discipline.

Experience
• Seven years of experience in maintaining business intelligence, data warehouse solutions, or ETL in a Run or Production environment.
• Six years of experience troubleshooting ETL load related issues (SSIS or Data Solutions).
• Six years of experience with ETL development and maintenance experience in a data warehouse environment.
• Experience with systems engineering (hardware / software) capacity.
• Experience with database or report portal tool administration is preferred.
• Experience at a healthcare or managed care organization is preferred.

Equivalent Education and/or Experience
• Five (5) years of experience with healthcare data management in a health plan or managed care organization may be considered in lieu of a degree.

Certification/Registration/Licensure
• System Administration or Reporting Tool Administrative Certification is preferred. (i.e. Epic Cogito or Clarity, SAP Business Objects, Tibco Composite, Microsoft Certified Solutions Engineer (MCSE), Oracle Certified Professional (OCP), etc.)
• PMP or other project management certificate or training is preferred.

Skills or Special Abilities
• Proficiency with ETL tool Build or Run activities.
• Ability to create reports and/or build virtual data environments.
• Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.
• Proficiency with Microsoft Office Excel, Word and Outlook is required; Access and PowerPoint are preferred.
• Demonstrated critical thinking and troubleshooting skills accompanied by a high level of detail.
• Demonstrated ability to plan and manage multiple processes and projects simultaneously.
• High level of attention to detail.
• Strong verbal and written communication skills.
• Demonstrated ability to collaborate effectively and work as part of a team.
• Independent worker and self-starter, having the ability to provide internal motivation and drive.
• Proficiency with server or application patching, backups, scripting is preferred.
• Understanding of SSIS and Apache NiFi is preferred.
• Proficiency with Business Objects Administration is preferred.

Responsibilities
• Implements and maintains high-value business intelligence environments.
• Maintains the data systems including business intelligence, ETL, and supporting backup strategies.
• Has a strong understanding of all the tools within the environment, regardless of vendor, and quickly and efficiently triages, troubleshoots, and restores services during outages or service degradation.
• Responsible for being on-call for Business Intelligence and ETL cycles.
• Works with the Database Analyst and storage teams to ensure proper backups are taken, test back-ups periodically, and ensures that the system can be restored in the time of a disaster.
• Proactively identifies areas for improvement in our Business Intelligence environment.
• Documents all routine processes and cross-trains other team members.
• Improves function, speed, and accuracy of data distribution methods.
• Develops automated reports and dashboards.

Job Accountabilities
• Identifies ways to improve work processes and improve customer satisfaction. Makes recommendations to supervisor, implements, and monitors results as appropriate in support of the overall goals of PCHP.
• Stays abreast of the latest developments, advancements, and trends in the field by attending seminars/workshops, reading professional journals, actively participating in professional organizations, and/or maintaining certification or licensure. Integrates knowledge gained into current work practices.
• Maintains knowledge of applicable rules, regulations, policies, laws, and guidelines that impact the area. Develops effective internal controls designed to promote adherence with applicable laws, accreditation agency requirements, and customer requirements. Seeks advice and guidance as needed to ensure proper understanding.

Parkland Health and Hospital System prohibits discrimination based on age (40 or over), race, color, religion, sex (including pregnancy), sexual orientation, gender identity, gender expression, genetic information, disability, national origin, marital status, political belief, or veteran status. As part of our commitment to our patients and employees' wellness, Parkland Health is a tobacco and smoke-free campus.",True,1689724800,2023-07-19T00:00:00.000Z,Dallas,TX,US,32.776665,-96.79699,['retirement_savings'],"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=80&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=gEFo3LqOIkEAAAAAAAAAAA%3D%3D",2023-08-26T00:00:00.000Z,1693008000.0,"{'no_experience_required': False, 'required_experience_in_months': 84, 'experience_mentioned': True, 'experience_preferred': True}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': True, 'professional_certification_mentioned': True}",False,,,,,"{'Qualifications': [""Bachelor's degree in computer science, management information systems, information technology, statistics, mathematics, or related discipline"", 'Seven years of experience in maintaining business intelligence, data warehouse solutions, or ETL in a Run or Production environment', 'Six years of experience troubleshooting ETL load related issues (SSIS or Data Solutions)', 'Six years of experience with ETL development and maintenance experience in a data warehouse environment', 'Experience with systems engineering (hardware / software) capacity', 'Equivalent Education and/or Experience', 'Five (5) years of experience with healthcare data management in a health plan or managed care organization may be considered in lieu of a degree', 'Epic Cogito or Clarity, SAP Business Objects, Tibco Composite, Microsoft Certified Solutions Engineer (MCSE), Oracle Certified Professional (OCP), etc.)', 'Proficiency with ETL tool Build or Run activities', 'Ability to create reports and/or build virtual data environments', 'Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy', 'Demonstrated critical thinking and troubleshooting skills accompanied by a high level of detail', 'Demonstrated ability to plan and manage multiple processes and projects simultaneously', 'High level of attention to detail', 'Strong verbal and written communication skills', 'Demonstrated ability to collaborate effectively and work as part of a team', 'Independent worker and self-starter, having the ability to provide internal motivation and drive'], 'Responsibilities': [""The Parkland Community Health Plan's (PCHP's) Data Engineer is responsible for maintaining the data systems including business intelligence, ETL, and supporting backup strategies in order to provide PCHP with secure, dependable, and accurate data including data transfer, data integrity, and data storage responsibilities"", ""The Data Engineer will collaborate with Database Administrators, server team, storage team, and other teams to plan maintenance activities and with PHCP's analytics team for report or universe deployments"", 'The Data Engineer will also be involved in dashboard and report development activities', 'Implements and maintains high-value business intelligence environments', 'Has a strong understanding of all the tools within the environment, regardless of vendor, and quickly and efficiently triages, troubleshoots, and restores services during outages or service degradation', 'Responsible for being on-call for Business Intelligence and ETL cycles', 'Works with the Database Analyst and storage teams to ensure proper backups are taken, test back-ups periodically, and ensures that the system can be restored in the time of a disaster', 'Proactively identifies areas for improvement in our Business Intelligence environment', 'Documents all routine processes and cross-trains other team members', 'Improves function, speed, and accuracy of data distribution methods', 'Develops automated reports and dashboards', 'Identifies ways to improve work processes and improve customer satisfaction', 'Makes recommendations to supervisor, implements, and monitors results as appropriate in support of the overall goals of PCHP', 'Stays abreast of the latest developments, advancements, and trends in the field by attending seminars/workshops, reading professional journals, actively participating in professional organizations, and/or maintaining certification or licensure', 'Maintains knowledge of applicable rules, regulations, policies, laws, and guidelines that impact the area', 'Develops effective internal controls designed to promote adherence with applicable laws, accreditation agency requirements, and customer requirements', 'Seeks advice and guidance as needed to ensure proper understanding']}",Data engineer,en,15113200,4,['15-2041.00: Statisticians'],,
VEeZH6OmNmcAAAAAAAAAAA==,"InnoCore Solutions, Inc.",https://media.licdn.com/dms/image/C4E0BAQFf1XwUvZbQ-g/company-logo_200_200/0/1548364987002?e=2147483647&v=beta&t=t_toT-cPqBtXgu6AeDd8iCaKvZwqKgEFADBR8TlzNZE,,,Dice.com,CONTRACTOR,Sr. ETL Migration Data Engineer,https://www.dice.com/job-detail/e4fea931-6de0-41bf-8fd6-df33a15a3e9a,True,0.6635,"Responsibilities:
• Responsible for migrating an on-premises ETL(IBM DataStage) to Azure Databricks
• Implement data privacy and data engineering solutions using Azure products and services: (Azure Data Lake Storage, Azure Data Factory, Azure Functions, Event Hub, Azure Stream Analytics, Azure Databricks, etc.) and traditional data warehouse tools
• Perform multiple aspects involved in the development lifecycle design, cloud engineering (infrastructure, network, security, and administration)
• Implement batch and streaming data pipelines using cloud technologies
• Develop and support data privacy and governance related frameworks and help other teams implement them for compliance

Requirements:
• 8 years of software solution development using Agile, and DevOps, operating in a product model that includes designing, developing, and implementing large-scale applications or data engineering solutions
• 2 years of cloud development and data lake experience including Azure EventHub, Azure Data Factory, Azure Databricks, Azure DevOps, Azure Blob Storage, Azure Data Lake, Azure Power Apps, and Power BI
• 5 years of experience with Python, PySpark, Spark, Unix, SQL
• Data Platforms: Teradata, Cassandra, MongoDB, Oracle, SQL Server, ADLS, Snowflake
• Tools: DataStage, Informatica EDC/Axon, BigID
• Expertise with the Azure Technology stack for data management, data ingestion, capture, processing, curation and creating consumption layers

Education:
• Bachelor's degree in Computer Science/Engineering or related field",False,1688390886,2023-07-03T13:28:06.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=80&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=VEeZH6OmNmcAAAAAAAAAAA%3D%3D",2023-08-27T15:29:20.000Z,1693150160.0,"{'no_experience_required': False, 'required_experience_in_months': 60, 'experience_mentioned': True, 'experience_preferred': False}","['Azure EventHub', 'Azure Data Factory', 'Azure Databricks', 'Azure DevOps', 'Azure Blob Storage', 'Azure Data Lake', 'Azure Power Apps', 'Power BI', 'SQL', 'DataStage']","{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': True, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['8 years of software solution development using Agile, and DevOps, operating in a product model that includes designing, developing, and implementing large-scale applications or data engineering solutions', '2 years of cloud development and data lake experience including Azure EventHub, Azure Data Factory, Azure Databricks, Azure DevOps, Azure Blob Storage, Azure Data Lake, Azure Power Apps, and Power BI', '5 years of experience with Python, PySpark, Spark, Unix, SQL', 'Data Platforms: Teradata, Cassandra, MongoDB, Oracle, SQL Server, ADLS, Snowflake', 'Tools: DataStage, Informatica EDC/Axon, BigID', 'Expertise with the Azure Technology stack for data management, data ingestion, capture, processing, curation and creating consumption layers', ""Bachelor's degree in Computer Science/Engineering or related field""], 'Responsibilities': ['Responsible for migrating an on-premises ETL(IBM DataStage) to Azure Databricks', 'Implement data privacy and data engineering solutions using Azure products and services: (Azure Data Lake Storage, Azure Data Factory, Azure Functions, Event Hub, Azure Stream Analytics, Azure Databricks, etc.) and traditional data warehouse tools', 'Perform multiple aspects involved in the development lifecycle design, cloud engineering (infrastructure, network, security, and administration)', 'Implement batch and streaming data pipelines using cloud technologies', 'Develop and support data privacy and governance related frameworks and help other teams implement them for compliance']}",Data engineer,en,15113300,4,,,
yMUxVNy49foAAAAAAAAAAA==,Sogeti,https://www.sogeti.be/Static/img/sogeti-logo.svg,http://www.sogeti.com,Consulting,Built In,FULLTIME,"Remote Data Engineer (Dallas, TX)",https://builtin.com/job/data/remote-data-engineer/162680,False,0.6028,"Sogeti is a leading provider of professional technology services, specializing in Application Management, Infrastructure Management and High-Tech Engineering. Sogeti offers cutting-edge solutions around Testing, Business Intelligence, Mobility, Cloud and Security, combining world class methodologies and the global delivery model, Rightshore®. Sogeti brings together more than 20,000 professionals in 15 countries and is present in over 100 locations in Europe, the US and India. Sogeti is a wholly-owned subsidiary of Cap Gemini S.A., listed on the Paris Stock Exchange.

At Sogeti USA, we are committed to building a long and enduring relationship with our employees and to creating an environment that rewards and empowers. Our mission is to constantly exceed our employees' expectations in the same way that we strive to exceed our clients' expectations. We offer an environment that celebrates innovation and helps you to achieve a good balance between your professional and personal life. We strive to be an employer of choice!

What You'll Do
• Build well-managed data solutions, tools, and capabilities to enable self-service frameworks for data consumers.
• Understand, facilitate, and influence domain-driven design processes.
• Recommend improvements to data architectures to maximize business capabilities.
• Build data pipelines andservices for AWS, Azure, Kafka.
• Develop deploymentpackages and automate testing (Jenkins, Git).
• Work collaboratively with others within and outside of the engineering function to achieve goals, improve processes, and optimize system design (Agile, Scrum team).
Minimum education qualification
• Bachelor's Degree in Computer Science, Computer Engineering, MIS or related field.
The ideal candidate will have:
• Bachelor of Science in Computer Science or technical equivalent; Master's preferred
• Knowledge of industry leading data management practices
• Knowledge of cloudplatforms such as Azure, AWS
• 5+ years using modern BItools (Power BI, Tableau, Qlik, MicroStrategy)
• Experience with ETL/ELTtools (Informatica, Talend)
• 5 years of experiencewith modern, various databases & data store tools (Snowflake, AWS Redshift,RDS, DocumentDB, S3)
• Strong experience withApache Kafka, Kubernetes, Terraform
• Experience with corecompetencies in Data Structures, Rest/SOAP APIs, JSON.
• High degree of initiative and capacity to lead multiple priorities of significant scope in a fast-paced environment
• Knowledge of various data architecture and technology solutions
• Expert level in SQL
• Experience with commonsoftware engineering tools (e.g., Git, JIRA, Confluence)
• Strong experience withdata modeling, data lineage, data warehousing and data marts
• Additional skillsinclude: Matillion, Azure Data Factory, Azure Synapse, AWS Lambda, S3, Glue,EMR, Redshift, Dynamo DB, Aurora, Athena, and Hadoop

The benefits our employees enjoy:
• 401(k) Savings Plan- Matched 150% up to 6%. (Our 401k is in the top 1% of 401(k) plans offered in the US!)
• Medical/Prescription/Dental/Vision Coverage!
• Low-premium and deductible. Plan with free preventive care.
• $12,000 in Tuition Reimbursement
• 100% Company-paid mobile phone plan
• Personal Time Off (PTO)- Ensuring a balance of work and home life",False,1629846938,2021-08-24T23:15:38.000Z,,TX,US,32.707874,-96.92091,"['retirement_savings', 'dental_coverage', 'health_insurance', 'paid_time_off']","https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=80&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=yMUxVNy49foAAAAAAAAAAA%3D%3D",,,"{'no_experience_required': False, 'required_experience_in_months': 60, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': True, 'degree_mentioned': True, 'degree_preferred': True, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': [""Bachelor's Degree in Computer Science, Computer Engineering, MIS or related field"", 'Knowledge of industry leading data management practices', 'Knowledge of cloudplatforms such as Azure, AWS', '5+ years using modern BItools (Power BI, Tableau, Qlik, MicroStrategy)', 'Experience with ETL/ELTtools (Informatica, Talend)', '5 years of experiencewith modern, various databases & data store tools (Snowflake, AWS Redshift,RDS, DocumentDB, S3)', 'Apache Kafka, Kubernetes, Terraform', 'Experience with corecompetencies in Data Structures, Rest/SOAP APIs, JSON', 'High degree of initiative and capacity to lead multiple priorities of significant scope in a fast-paced environment', 'Knowledge of various data architecture and technology solutions', 'Expert level in SQL', 'Experience with commonsoftware engineering tools (e.g., Git, JIRA, Confluence)', 'Strong experience withdata modeling, data lineage, data warehousing and data marts'], 'Responsibilities': ['Build well-managed data solutions, tools, and capabilities to enable self-service frameworks for data consumers', 'Understand, facilitate, and influence domain-driven design processes', 'Recommend improvements to data architectures to maximize business capabilities', 'Build data pipelines andservices for AWS, Azure, Kafka', 'Develop deploymentpackages and automate testing (Jenkins, Git)', 'Work collaboratively with others within and outside of the engineering function to achieve goals, improve processes, and optimize system design (Agile, Scrum team)'], 'Benefits': ['401(k) Savings Plan- Matched 150% up to 6%', '(Our 401k is in the top 1% of 401(k) plans offered in the US!)', 'Medical/Prescription/Dental/Vision Coverage!', 'Low-premium and deductible', 'Plan with free preventive care', '$12,000 in Tuition Reimbursement', '100% Company-paid mobile phone plan', 'Personal Time Off (PTO)- Ensuring a balance of work and home life']}",Data engineer,en,15113200,4,,541613,Marketing Consulting Services
248UdFpME3EAAAAAAAAAAA==,RIT solutions Inc,https://upload.wikimedia.org/wikipedia/commons/4/49/Rochester_Institute_of_Technology_Seal_%282018%29.svg,http://www.rit.edu,Education,Techfetch,CONTRACTOR,Sr Data Engineer,https://www.techfetch.com/job-description/sr-data-engineer-dallas-tx-j3576490,False,0.4578,"Duration: 12+ month
Visa: GC/USC
Must have a valid Linkedin profile...
Must be based in Dallas or Raleigh- (travel on-site one week per quarter)
- Oracle - experience writing SQL queries in Oracle
- 10+ years in Database Development
- Experience with Informatica or similar ETL tool
- Hands-on experience with AWS
- Experience with Python or similar scripting language",False,1676937600,2023-02-21T00:00:00.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=80&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=248UdFpME3EAAAAAAAAAAA%3D%3D",2024-02-21T00:00:00.000Z,1708473600.0,"{'no_experience_required': False, 'required_experience_in_months': 120, 'experience_mentioned': True, 'experience_preferred': False}","['Oracle', 'Data Engineer', 'ETL', 'Informatica', 'Python', 'SQL']","{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': False, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['Must have a valid Linkedin profile..', 'Must be based in Dallas or Raleigh- (travel on-site one week per quarter)', '10+ years in Database Development', 'Experience with Informatica or similar ETL tool', 'Hands-on experience with AWS', 'Experience with Python or similar scripting language']}",Data engineer,en,15113200,4,,61,Education
LWxudsMKTTMAAAAAAAAAAA==,Docyt,"https://res.cloudinary.com/crunchbase-production/image/upload/c_lpad,f_auto,q_auto:eco,dpr_1/v1464377633/hffpio7eh8djgtpcteyg.png",http://docyt.com,,Glassdoor,FULLTIME,Big Data Engineer,"https://www.glassdoor.com/job-listing/big-data-engineer-docyt-JV_IC1139977_KO0,17_KE18,23.htm?jl=1008768999974",True,0.573,"Docyt, a fast-growing FinTech startup based in Silicon Valley, is seeking a highly motivated Big Data Engineer to join our team. The ideal candidate will be responsible for maintaining our data processing infrastructure and optimizing our data architecture, as well as contributing to the development and implementation of new data-driven solutions. At Docyt, we are passionate about empowering businesses to take control of their financial data using an AI-driven super app, and we're looking for a skilled engineer to help us continue to innovate in this exciting space.

Responsibilities
• Develop and manage data pipelines, ensuring the smooth flow of data from various sources to our data warehouse
• Monitor and optimize data processing infrastructure, ensuring fast and reliable ETL pipelines
• Contribute to the design and implementation of new data-driven solutions, using cutting-edge machine learning and artificial intelligence techniques
• Collaborate with other members of the engineering team, sharing knowledge and best practices to continuously improve our data processing capabilities
• Build and maintain data models and ensure data accuracy and consistency
• Implement and manage data security measures, including backups and access controls
• Participate in code reviews, providing constructive feedback to ensure code quality

Requirements
• Bachelor's degree in Computer Science, Engineering, or related field
• At least 3 years of experience in big data engineering or related field
• Strong understanding of data processing fundamentals, including ETL pipelines, data warehousing, and data modeling
• Proficient in at least one programming language, such as Python or Java
• Experience with SQL and NoSQL databases
• Familiarity with distributed computing frameworks, such as Hadoop or Spark
• Understanding of data security and access control best practices
• Strong problem-solving skills and ability to work independently and in a team environment
• Excellent verbal and written communication skills
• Self-motivated with a strong desire to learn and stay up-to-date with new technologies in the field
• Experience with AWS and Docker is a plus.

Benefits
• Great growth potential at a fast-growing startup, we want you to grow with us!
• Company-provided laptop and necessary hardware to ensure your setup for success.
• Comprehensive health, dental and vision coverage.
• Company-sponsored 401(k)
• Inclusive and motivating work culture that values team collaboration.

About Us

Docyt, pronounced “docket”, is a FinTech startup headquartered in Silicon Valley, that is passionately focused on giving businesses control of their financial data. While great strides have been made in sending and receiving payments, businesses still struggle to aggregate all their financial data, understand it, and use it to make well-informed, timely decisions. Docyt brings order to data chaos.

Docyt is a super app that applies AI (artificial intelligence) across the entire accounting tech stack. Docyt digitizes financial data, automates both income and expense workflows, continuously reconciles QuickBooks®, and generates real-time financial statements. That explains what we do, but here’s why it’s important. A complete, accurate, real-time financial picture empowers businesses to make timely and smart decisions so their business can thrive.",True,1689811200,2023-07-20T00:00:00.000Z,Dallas,TX,US,32.776665,-96.79699,"['dental_coverage', 'retirement_savings', 'health_insurance']","https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=80&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=LWxudsMKTTMAAAAAAAAAAA%3D%3D",,,"{'no_experience_required': False, 'required_experience_in_months': 36, 'experience_mentioned': True, 'experience_preferred': True}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': True, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': [""Bachelor's degree in Computer Science, Engineering, or related field"", 'At least 3 years of experience in big data engineering or related field', 'Strong understanding of data processing fundamentals, including ETL pipelines, data warehousing, and data modeling', 'Proficient in at least one programming language, such as Python or Java', 'Experience with SQL and NoSQL databases', 'Familiarity with distributed computing frameworks, such as Hadoop or Spark', 'Understanding of data security and access control best practices', 'Strong problem-solving skills and ability to work independently and in a team environment', 'Excellent verbal and written communication skills', 'Self-motivated with a strong desire to learn and stay up-to-date with new technologies in the field'], 'Responsibilities': ['Develop and manage data pipelines, ensuring the smooth flow of data from various sources to our data warehouse', 'Monitor and optimize data processing infrastructure, ensuring fast and reliable ETL pipelines', 'Contribute to the design and implementation of new data-driven solutions, using cutting-edge machine learning and artificial intelligence techniques', 'Collaborate with other members of the engineering team, sharing knowledge and best practices to continuously improve our data processing capabilities', 'Build and maintain data models and ensure data accuracy and consistency', 'Implement and manage data security measures, including backups and access controls', 'Participate in code reviews, providing constructive feedback to ensure code quality'], 'Benefits': ['Great growth potential at a fast-growing startup, we want you to grow with us!', 'Company-provided laptop and necessary hardware to ensure your setup for success', 'Comprehensive health, dental and vision coverage', 'Company-sponsored 401(k)', 'Inclusive and motivating work culture that values team collaboration']}",Data engineer,en,15113200,4,,,
Z3RRrMfrr9IAAAAAAAAAAA==,"ClifyX, INC",,http://www.clifyx.com,,Jobrapido.com,FULLTIME,Data Engineer,https://us.jobrapido.com/jobpreview/2926831096,False,0.4464,"Job Description
1. (Data Engineer) - 1 open position
Job Requirements: ETL/ AWS Glue
Rates : $85/hour
Location: Dallas, TX (Onsite)
Fulltime (Permanent) /Contract (SC)
Responsibilities
•5 years of experience in support, development, design, and implementation of technology solutions on large Data engineering initiatives - preferably in Financial Services
•Expertise in batch and file-based integrations Experience of performing ETL ELT processes from multiple sources
•Hands-on experience of working in AWS cloud environment and using AWS Glue for data integrations
•Experience of integrating with Snowflake eco-system and using of tools such as SnowSQL, SnowPipe etc
•Demonstrated application of skills and knowledge across digital technologies (AWS, Cloud, Data, App Architectures (APIs, Event Streaming), Automation) and with Agile delivery methods (Scrum, Kanban, DevOps)
•Strong Database and SQL Sk ills Required
•Strong Object-oriented programming Skills Required
•Strong knowledge in backend frameworks like Spring boot is Required
•Experience with some backend languages (Java, Python) Experience Required
•Experience with DevSecOps tools for CI CD Required
•Experience with Source Code management tools like Git Required
•Excellent communication skills Required
•Experience with using Message Queue and Kafka Preferred
•Experience with SRE Concepts & Tools Preferred
•Working in banking domain (Retail commercial) is Preferred",False,1686787200,2023-06-15T00:00:00.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=80&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=Z3RRrMfrr9IAAAAAAAAAAA%3D%3D",,,"{'no_experience_required': False, 'required_experience_in_months': 60, 'experience_mentioned': True, 'experience_preferred': True}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': False, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['Expertise in batch and file-based integrations Experience of performing ETL ELT processes from multiple sources', 'Demonstrated application of skills and knowledge across digital technologies (AWS, Cloud, Data, App Architectures (APIs, Event Streaming), Automation) and with Agile delivery methods (Scrum, Kanban, DevOps)', 'Strong Database and SQL Sk ills Required', 'Strong Object-oriented programming Skills Required', 'Strong knowledge in backend frameworks like Spring boot is Required', 'Experience with some backend languages (Java, Python) Experience Required', 'Experience with DevSecOps tools for CI CD Required', 'Experience with Source Code management tools like Git Required', 'Excellent communication skills Required'], 'Responsibilities': ['(Data Engineer) - 1 open position']}",Data engineer,en,15113200,4,,,
0OPIQUWCXxMAAAAAAAAAAA==,Advaana Staffing,https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTPd-hps7yHu6ZmQPwa8QzKacpqKLbzwCNNoBVY&s=0,,,OPTnation,CONTRACTOR,Data Engineer,https://www.optnation.com/data-engineer-job-in-dallas-tx-view-jobid-28150,False,0.6919,"Position Data Engineer

Location Dallas TX & NY.

Duration 12+ Months

Must Have Firmwide x 2 OR Data x 3

Job Description Design and develop data ingest and transform processes Develop data models to provide standardized reporting solutions to the firm Develop automation governance and reporting solutions to provide firm and regulatory mandated controls Work as part of a global team using Agile software methodologies Partner with Marcus risk product acquisition and servicing teams Use Marcus data to drive change throughout the Marcus business Minimum 3 years of relevant professional experience Experience with SQL and relational databases Self-starter motivated and good communication skills Strong sense of ownership and driven to manage tasks to completion

Thanks & Regards

--

Sandhya Sales Recruiter Direct +1 973 259 6437 Sandhya@advaana.com advaana.com

Advaana Inc. 12 Daniel Rd STE 314 Fairfield NJ 07004",False,1677196800,2023-02-24T00:00:00.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=80&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=0OPIQUWCXxMAAAAAAAAAAA%3D%3D",,,"{'no_experience_required': False, 'required_experience_in_months': 36, 'experience_mentioned': True, 'experience_preferred': False}",['Data Engineer'],"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': False, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,50000.0,140000.0,USD,YEAR,"{'Qualifications': ['Must Have Firmwide x 2 OR Data x 3', 'Job Description Design and develop data ingest and transform processes Develop data models to provide standardized reporting solutions to the firm Develop automation governance and reporting solutions to provide firm and regulatory mandated controls Work as part of a global team using Agile software methodologies Partner with Marcus risk product acquisition and servicing teams Use Marcus data to drive change throughout the Marcus business Minimum 3 years of relevant professional experience Experience with SQL and relational databases Self-starter motivated and good communication skills Strong sense of ownership and driven to manage tasks to completion']}",Data engineer,en,15113200,4,,,
VxiGjPFk0QAAAAAAAAAAAA==,NFI,https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSqLoFpJateFKTAzYd2qBNoTh34L-AdTefNEqjD&s=0,,,BeBee,FULLTIME,Data Engineer II,https://us.bebee.com/job/20230723-1100a4a283b734c77bfe515ca2401cf7,False,0.5,"At NFI, we offer innovative, integrated, and customized solutions that span the entire supply chain. Whatever our customer's challenge is, we have the knowledge, technology, scale, and commitment to help them solve it. It's simply what we do.

The NFI Data and Analytics team is looking for an enthusiastic Data Engineer to join our dynamic and growing team. As a Data Engineer, you will be responsible for developing and maintaining the data architecture and infrastructure that support our data-driven applications and processes. You will work closely with our data engineering team, IT Ops team, and business partners to ensure that data is appropriately collected, stored, processed, and analyzed. Guided by NFI's shared values, we work in an environment where collaboration, teamwork, respect, and openness are highly valued.

Essential Duties & Responsibilities:
• Develop and maintain scalable and efficient data pipelines, data warehouses, and databases.
• Build large-scale batch and real-time data pipelines using state-of-the-art cloud technologies, such as Google Cloud, Azure, or AWS.
• Build and manage data infrastructure, including data ingestion, processing, and storage.
• Collaborate with cross-functional teams to ensure the quality and integrity of the data.
• Implement data governance, security, and privacy measures.
• Continuously optimize the data infrastructure to improve performance, reliability, and scalability
• Conduct data modeling, profiling, and validation to ensure data accuracy and consistency.
• Develop and maintain documentation on the data infrastructure, including data flow diagrams, architecture, and technical specifications.
• Participate in code reviews and collaborate with other data engineers to maintain code quality and best practices.

Job-Specific Requirements:
• Bachelor's Degree in Computer Science, Information Systems, or a related discipline.
• At least 3 years of experience as a Data Engineer or related role
• Strong experience with database environments and (T) SQL.
• Strong programming skills in languages such as Python, PySpark, and/or Java.
• Experience with ETL tools and processes, such as SSIS or Azure Data Factory
• Proficiency in data warehousing and data modeling
• Solid understanding of data management principles, data quality, and data governance
• Strong problem-solving skills and attention to detail
• Experience with cloud computing platforms such as Google Cloud Platform, Azure, or AWS is a strong plus.

Expected Competencies:

Functional Expertise: Possesses the skills and knowledge to perform essential functions efficiently and effectively.
• Communication and Collaboration: Communicates openly and honestly. Follows through on commitments. Takes ownership and does not misrepresent information. Supports colleagues and team efforts.
• Development: Takes an active role in self-development, seeking to grow job-related knowledge and skills. Empowers and challenges team members to reach their full potential.
• Analysis and Decision Making: Uses all available resources to make good decisions. Knows when and how to partner with others when facing a problem.
• Results Focus: Action-oriented. Assumes an appropriate level of accountability for goals, critical issues, and performance.
• Managing Change and Continuous Improvement: Demonstrates an entrepreneurial mindset towards change. Takes risks, and creates new, and better ways for the organization to be successful.

Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities

The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor's legal duty to furnish information. 41 CFR",False,1690073488,2023-07-23T00:51:28.000Z,Dallas,TX,US,32.776665,-96.79699,,"https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=80&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=VxiGjPFk0QAAAAAAAAAAAA%3D%3D",2023-07-31T00:00:00.000Z,1690761600.0,"{'no_experience_required': False, 'required_experience_in_months': 36, 'experience_mentioned': True, 'experience_preferred': True}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': True, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': [""Bachelor's Degree in Computer Science, Information Systems, or a related discipline"", 'At least 3 years of experience as a Data Engineer or related role', 'Strong experience with database environments and (T) SQL', 'Strong programming skills in languages such as Python, PySpark, and/or Java', 'Experience with ETL tools and processes, such as SSIS or Azure Data Factory', 'Proficiency in data warehousing and data modeling', 'Solid understanding of data management principles, data quality, and data governance', 'Strong problem-solving skills and attention to detail', 'Experience with cloud computing platforms such as Google Cloud Platform, Azure, or AWS is a strong plus', 'Functional Expertise: Possesses the skills and knowledge to perform essential functions efficiently and effectively'], 'Responsibilities': ['As a Data Engineer, you will be responsible for developing and maintaining the data architecture and infrastructure that support our data-driven applications and processes', 'You will work closely with our data engineering team, IT Ops team, and business partners to ensure that data is appropriately collected, stored, processed, and analyzed', 'Develop and maintain scalable and efficient data pipelines, data warehouses, and databases', 'Build large-scale batch and real-time data pipelines using state-of-the-art cloud technologies, such as Google Cloud, Azure, or AWS', 'Build and manage data infrastructure, including data ingestion, processing, and storage', 'Collaborate with cross-functional teams to ensure the quality and integrity of the data', 'Implement data governance, security, and privacy measures', 'Continuously optimize the data infrastructure to improve performance, reliability, and scalability', 'Conduct data modeling, profiling, and validation to ensure data accuracy and consistency', 'Develop and maintain documentation on the data infrastructure, including data flow diagrams, architecture, and technical specifications', 'Participate in code reviews and collaborate with other data engineers to maintain code quality and best practices', 'Takes ownership and does not misrepresent information', 'Supports colleagues and team efforts', 'Development: Takes an active role in self-development, seeking to grow job-related knowledge and skills', 'Empowers and challenges team members to reach their full potential', 'Analysis and Decision Making: Uses all available resources to make good decisions', 'Managing Change and Continuous Improvement: Demonstrates an entrepreneurial mindset towards change']}",Data engineer,en,15113200,4,,,
82l-Phq5MLUAAAAAAAAAAA==,"Greystar Worldwide, LLC",https://mma.prnewswire.com/media/1761396/greystar_Logo.jpg?p=facebook,https://www.greystar.com,Real Estate,CareerBuilder,FULLTIME,Data Engineer,https://www.careerbuilder.com/job/J3Q6GK6SQ68MDBSDJ23,False,0.5483,"At Greystar, we've launched a program aimed at bringing the real estate leasing experience for residents into the digital era.

As a data engineer, you will join the global Enterprise Data Organization and Apex Organization, which builds a resident-centric ecosystem of products that enable a 360 view of the prospect/resident to improve operational efficiency and resident satisfaction.

You will provide data capabilities and build out a common data model that supports 360 view of our prospect/resident powered by Azure SQL, Synapse data warehouse, and Microsoft Customer Insights. You will also work and support our industry-changing products and features designed to make shopping for an apartment more streamlined, e-commerce friendly, and efficient.

With your help, we will improve our customer's apartment shopping journey and enable business intelligence to help us personalize the apartment shopping experience for our residents.

The successful candidate will have a strong sense of teamwork, personal integrity, accountability, and the ability to understand business functions and requirements, translating to innovative working applications while navigating competing priority tradeoffs.

JOB DESCRIPTION

What You Will do
• 100% hands-on development - develop and unit test database code, including but not limited to T-SQL, stored procedures, functions and views.
• Create and maintain database structures
• As part of the Scrum team, you will work with BAs, Scrum Master, Leads and engineers to provide data support to our products and build creative solutions and features to move our product roadmap forward.
• Participate in the design of databases, using first, second or third normalized form as needed to support business requirements.
• Create and deploy ADF pipelines, adhering to Greystar's standards and documented best practices.
• Perform analysis of complex data and document findings.
• Prepare data for prescriptive and predictive modeling.
• Combine raw data from different external sources.
• Collaborate with data scientists and architects.
• Play a direct role in the maintenance, technical support, documentation, and administration of databases.

Who You Are
• Strong problem solver with excellent communication skills
• Have a growth mindset with a desire to learn and embrace challenges.
• Innovative and passionate about your work
• ""Self-starter"" attitude and the ability to make decisions independently.

What You Have
• Minimum of 3 years of relevant experience in database design and development
• Minimum of 2 years of relevant experience in working with Azure PaaS databases
• Minimum of 1 year of relevant experience working with Azure Data Factory.
• Minimum of 1 year of relevant experience working with Azure Data Lakes Gen 2.
• Working knowledge of Azure Synapse.
• Preferred: Experience with Customer Insights and/or Dataverse.
• Preferred: Experience with Power BI.
• Bachelor's in Computer Science, related field, or equivalent work experience

Technical Pre-screening test will be required for all candidates

What the Right Candidate will Enjoy!
• 100% Remote flexibility!
• Competitive pay, benefits, and overall compensation packages.
• The chance to be part of a technology team for a thriving organization that prioritizes accountability, respect, and operational excellence!
• The opportunity to join a thriving, highly visible organization during its technology transformation!

The base compensation rate will vary based on education, experience, skills, and geographic location, as applicable.

Greystar seeks to attract, recruit, advance and retain top talent. Greystar's compensation strategy is tailored to appropriately reward the skillset and experience that a team member will bring to the organization.

Depending on the position offered, regular full-time and part-time team members may be eligible to participate in a bonus program in addition to their salary. Team members may also participate in the 401k plan, once eligible. Regular, full-time team members are offered a range of medical, financial, and other benefits from which to choose.

For Union and Prevailing Wage roles compensation and benefits may vary from the listed information above due to Collective Bargaining Agreements and/or local governing authority.

Greystar will consider for employment qualified applicants with arrest and conviction records.",True,1689897600,2023-07-21T00:00:00.000Z,Dallas,TX,US,32.776665,-96.79699,"['retirement_savings', 'health_insurance']","https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=80&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=82l-Phq5MLUAAAAAAAAAAA%3D%3D",2023-08-20T00:00:00.000Z,1692489600.0,"{'no_experience_required': False, 'required_experience_in_months': 36, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': True, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['Strong problem solver with excellent communication skills', 'Have a growth mindset with a desire to learn and embrace challenges', 'Innovative and passionate about your work', '""Self-starter"" attitude and the ability to make decisions independently', 'Minimum of 3 years of relevant experience in database design and development', 'Minimum of 2 years of relevant experience in working with Azure PaaS databases', 'Minimum of 1 year of relevant experience working with Azure Data Lakes Gen 2', 'Working knowledge of Azure Synapse', ""Bachelor's in Computer Science, related field, or equivalent work experience"", 'Technical Pre-screening test will be required for all candidates', 'The chance to be part of a technology team for a thriving organization that prioritizes accountability, respect, and operational excellence!', 'The opportunity to join a thriving, highly visible organization during its technology transformation!'], 'Responsibilities': ['You will provide data capabilities and build out a common data model that supports 360 view of our prospect/resident powered by Azure SQL, Synapse data warehouse, and Microsoft Customer Insights', '100% hands-on development - develop and unit test database code, including but not limited to T-SQL, stored procedures, functions and views', 'Create and maintain database structures', 'As part of the Scrum team, you will work with BAs, Scrum Master, Leads and engineers to provide data support to our products and build creative solutions and features to move our product roadmap forward', 'Participate in the design of databases, using first, second or third normalized form as needed to support business requirements', ""Create and deploy ADF pipelines, adhering to Greystar's standards and documented best practices"", 'Perform analysis of complex data and document findings', 'Prepare data for prescriptive and predictive modeling', 'Combine raw data from different external sources', 'Collaborate with data scientists and architects', 'Play a direct role in the maintenance, technical support, documentation, and administration of databases'], 'Benefits': ['Competitive pay, benefits, and overall compensation packages', 'Depending on the position offered, regular full-time and part-time team members may be eligible to participate in a bonus program in addition to their salary', 'Team members may also participate in the 401k plan, once eligible', 'Regular, full-time team members are offered a range of medical, financial, and other benefits from which to choose', 'For Union and Prevailing Wage roles compensation and benefits may vary from the listed information above due to Collective Bargaining Agreements and/or local governing authority']}",Data engineer,en,15113200,4,"['15-1132.00', 'Software Developers, Applications']",531110,Lessors of Residential Buildings and Dwellings
K6j7paZxOOEAAAAAAAAAAA==,CyberCoders,,,,Jooble,FULLTIME,Data Engineer,https://jooble.org/jdp/7261413729125393764/Data-Engineer-Dallas%2C-TX,False,0.5112,"We are looking for an experienced Data Engineer to join our Accounting - Finance team. You will be responsible for designing, implementing, and building data acquisition and data applied models. You should have experience with data analysis, data analytics, Excel, HubSpot, CRM, and Redis. If you are interested in being part of a collaborative team, working on innovative and challenging projects, then this is the job for you.

Top Reasons to Work with Us

We offer a great environment that encourages collaboration, creativity, and innovation. We are always working on challenging and exciting projects that push the envelope. We also provide competitive compensation packages, flexible hours, and generous benefits.

What You Will Be Doing

As a Data Engineer, you will be responsible for developing, implementing, and managing data acquisition and data applied models. You will also be involved in data analysis and data analytics. You will be expected to collaborate with other teams to ensure projects are completed on time and with the highest quality.

What You Need for this Position

To qualify for this position, you should have more than 5 years of experience with data analysis, data analytics, Excel, HubSpot, CRM, and Redis. You should also have excellent problem-solving and communication skills.

What's In It for You

This position pays between 90000 - 140000 annually. In addition to a competitive salary, we offer vacation/PTO, medical, dental, vision, bonus, and 401k.

So, if you are a Data Engineer with experience, please apply today! - View email address on jobs.institutedata.com

Email Your Resume In Word To

Looking forward to receiving your resume through our website and going over the position with you. Clicking apply is the best way to apply, but you may also:

View email address on jobs.institutedata.com
• Please do NOT change the email subject line in any way. You must keep the JobID: linkedin : CG12-1754728 -- in the email subject line for your application to be considered.***

Casey Glad - Executive Recruiter - CyberCoders

Applicants must be authorized to work in the U.S.

CyberCoders is proud to be an Equal Opportunity Employer

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.

Your Right to Work – In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.

CyberCoders will consider for Employment in the City of Los Angeles qualified Applicants with Criminal Histories in a manner consistent with the requirements of the Los Angeles Fair Chance Initiative for Hiring (Ban the Box) Ordinance.",False,1689999466,2023-07-22T04:17:46.000Z,Dallas,TX,US,32.776665,-96.79699,"['retirement_savings', 'health_insurance', 'dental_coverage', 'paid_time_off']","https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer+in+dallas,tx&start=80&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer+in+dallas,tx&htidocid=K6j7paZxOOEAAAAAAAAAAA%3D%3D",,,"{'no_experience_required': False, 'required_experience_in_months': 60, 'experience_mentioned': True, 'experience_preferred': False}",,"{'postgraduate_degree': False, 'professional_certification': False, 'high_school': False, 'associates_degree': False, 'bachelors_degree': False, 'degree_mentioned': False, 'degree_preferred': False, 'professional_certification_mentioned': False}",False,,,,,"{'Qualifications': ['If you are interested in being part of a collaborative team, working on innovative and challenging projects, then this is the job for you', 'To qualify for this position, you should have more than 5 years of experience with data analysis, data analytics, Excel, HubSpot, CRM, and Redis', 'You should also have excellent problem-solving and communication skills', 'Applicants must be authorized to work in the U.S'], 'Responsibilities': ['As a Data Engineer, you will be responsible for developing, implementing, and managing data acquisition and data applied models', 'You will also be involved in data analysis and data analytics', 'You will be expected to collaborate with other teams to ensure projects are completed on time and with the highest quality'], 'Benefits': ['We also provide competitive compensation packages, flexible hours, and generous benefits', 'This position pays between 90000 - 140000 annually', 'In addition to a competitive salary, we offer vacation/PTO, medical, dental, vision, bonus, and 401k']}",Data engineer,en,15113200,4,,,
